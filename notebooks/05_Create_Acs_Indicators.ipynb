{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04_Create_Acs_Indicators.ipynb","provenance":[],"collapsed_sections":["kfctZ0YgWjQI","yKAUCASnZzze"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"cMo4IRjn0UBN"},"source":["# default_exp create"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kfctZ0YgWjQI"},"source":["# Creating BNIA Indictors"]},{"cell_type":"markdown","metadata":{"id":"PSqXAwQ1WjQJ"},"source":["Awesome! \n","\n","By this point you should be able to download a dataset, and crosswalk new columns onto it by matching on 'tract'\n","\n","What we are going to do now is perform calculations using these newly created datasets.\n","\n","Run the next few cells to create our calculatory functions"]},{"cell_type":"code","metadata":{"id":"WuC7KC8OWjQJ","cellView":"form"},"source":["#@title Run This Cell: Misc Function Declarations\n","# These functions right here are used in the calculations below.\n","# Finds a column matchings a substring\n","def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0] \n","def getColByName (df, col): return df[getColName(df, col)]\n","\n","# Pulls a column from one dataset into a new dataset. \n","# This is not a crosswalk. calls getColByName() \n","def addKey(df, fi, col):\n","    key = getColName(df, col)\n","    val = getColByName(df, col)\n","    fi[key] = val\n","    return fi\n","# Return 0 if two specified columns are equal.\n","def nullIfEqual(df, c1, c2): \n","    return df.apply(lambda x: \n","        x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n","# I'm thinking this doesnt need to be a function..\n","def sumInts(df): return df.sum(numeric_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S9NQS1_bWjQK","cellView":"form"},"source":["# @title Run This Cell : Create MHHI\n","\n","#File: mhhi.py\n","#Author: Charles Karpati\n","#Date: 1/24/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description: \n","# Uses ACS Table B19001 - HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2016 INFLATION-ADJUSTED DOLLARS)\n","# Universe: Households\n","# Table Creates: hh25 hh40 hh60 hh75 hhm75, mhhi\n","#purpose: Produce Sustainability - Percent of Population that Walks to Work Indicator\n","#input:\n","#output:\n","import pandas as pd\n","import glob\n","\n","def mhhi( df, columnsToInclude = [] ):\n","  #~~~~~~~~~~~~~~~\n","  # Step 2)\n","  # Prepare the columns\n","  #~~~~~~~~~~~~~~~ \n","  info = pd.DataFrame(\n","      [\n","          ['B19001_002E', 0, 10000],\n","          ['B19001_003E', 10000, 4999 ],\n","          ['B19001_004E', 15000, 4999 ],\n","          ['B19001_005E', 20000, 4999 ],\n","          ['B19001_006E', 25000, 4999 ],\n","          ['B19001_007E', 30000, 4999],\n","          ['B19001_008E', 35000, 4999 ],\n","          ['B19001_009E', 40000, 4999 ],\n","          ['B19001_010E', 45000, 4999 ],\n","          ['B19001_011E', 50000, 9999 ],\n","          ['B19001_012E', 60000, 14999],\n","          ['B19001_013E', 75000, 24999 ],\n","          ['B19001_014E', 100000, 24999 ],\n","          ['B19001_015E', 125000, 24999 ],\n","          ['B19001_016E', 150000, 49000 ],\n","          ['B19001_017E', 200000, 1000000000000000000000000 ],\n","\n","      ], \n","      columns=['variable', 'lower', 'range']\n","  )\n","\n","  # Final Dataframe  \n","  data_table = pd.DataFrame()\n","  for index, row in info.iterrows():\n","      data_table = addKey(df, data_table, row['variable'])\n","\n","  # Accumulate totals accross the columns.\n","  # Midpoint: Divide column index 16 (the last column) of the cumulative totals\n","  temp_table = data_table.cumsum(axis=1)\n","  temp_table['midpoint'] = (temp_table.iloc[ : , -1 :] /2) # V3\n","  temp_table['midpoint_index'] = False\n","  temp_table['midpoint_index_value'] = False # Z3\n","  temp_table['midpoint_index_lower'] = False # W3 \n","  temp_table['midpoint_index_range'] = False # X3\n","  temp_table['midpoint_index_minus_one_cumulative_sum'] = False #Y3\n","  # step 3 - csa_agg3: get the midpoint index by \"when midpoint > agg[1] and midpoint <= agg[2] then 2\"\n","\n","  # Get CSA Midpoint Index using the breakpoints in our info table.\n","  for index, row in temp_table.iterrows():\n","      # Get the index of the first column where our midpoint is greater than the columns value.\n","      midpoint = row['midpoint']\n","      midpoint_index = 0\n","      # For each column (except the 6 columns we just created)\n","\n","      # The tracts midpoint was < than the first tracts value at column 'B19001_002E_Total_Less_than_$10,000'\n","      if( midpoint < int(row[0]) or row[-6] == False ):\n","        temp_table.loc[ index, 'midpoint_index' ] = 0\n","      else:\n","        for column in row.iloc[:-6]:\n","            # set midpoint index to the column with the highest value possible that is under midpoint          \n","            if( midpoint >= int(column) ):\n","                if midpoint==False: print (str(column) + ' - ' + str(midpoint))\n","                temp_table.loc[ index, 'midpoint_index' ] = midpoint_index +1\n","            midpoint_index += 1\n","\n","  # temp_table = temp_table.drop('Unassigned--Jail')\n","  for index, row in temp_table.iterrows(): \n","    temp_table.loc[ index, 'midpoint_index_value' ] = data_table.loc[ index, data_table.columns[row['midpoint_index']] ]\n","    temp_table.loc[ index, 'midpoint_index_lower' ] = info.loc[ row['midpoint_index'] ]['lower']     \n","    temp_table.loc[ index, 'midpoint_index_range' ] = info.loc[ row['midpoint_index'] ]['range']\n","    temp_table.loc[ index, 'midpoint_index_minus_one_cumulative_sum'] = row[ row['midpoint_index']-1 ]\n","\n","  # This is our denominator, which cant be negative.\n","  for index, row in temp_table.iterrows():\n","    if row['midpoint_index_value']==False: \n","      temp_table.at[index, 'midpoint_index_value']=1;\n","      \n","  #~~~~~~~~~~~~~~~\n","  # Step 3)\n","  # Run the Calculation \n","  # Calculation = (midpoint_lower::numeric + (midpoint_range::numeric * ( (midpoint - midpoint_upto_agg) / nullif(midpoint_total,0)\n","  # Calculation = W3+X3*((V3-Y3)/Z3)\n","\n","  # v3 -> 1 - midpoint of households  == sum / 2\n","  # w3 -> 2 - lower limit of the income range containing the midpoint of the housing total == row[lower]\n","  # x3 -> width of the interval containing the medium == row[range]\n","  # z3 -> number of hhs within the interval containing the median == row[total] \n","  # y3 -> 4 - cumulative frequency up to, but no==NOT including the median interval\n","  #~~~~~~~~~~~~~~~\n","\n","  def finalCalc(x):\n","    return ( x['midpoint_index_lower']+ x['midpoint_index_range']*(\n","      ( x['midpoint']-x['midpoint_index_minus_one_cumulative_sum'])/ x['midpoint_index_value'] ) \n","    )\n","\n","  temp_table['final'] = temp_table.apply(lambda x: finalCalc(x), axis=1)\n","  \n","  \n","  columnsToInclude.append('tract')\n","  print ('INCLUDING COLUMN(s):' + str(columnsToInclude))\n","  temp_table[columnsToInclude] = df[columnsToInclude]\n","  #~~~~~~~~~~~~~~~\n","  # Step 4)\n","  # Add Special Baltimore City Data\n","  #~~~~~~~~~~~~~~~  \n","  # url = 'https://api.census.gov/data/20'+str(year)+'/acs/acs5/subject?get=NAME,S1901_C01_012E&for=county%3A510&in=state%3A24&key=829bf6f2e037372acbba32ba5731647c5127fdb0'\n","  # table = pd.read_json(url, orient='records')\n","  # temp_table['final']['Baltimore City'] = float(table.loc[1, table.columns[1]])\n","    \n","  return temp_table"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"PeqketMgWjQO"},"source":["#@title Run This Cell: Create trav45\n","\n","#File: trav45.py\n","#Author: Charles Karpati\n","#Date: 1/17/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description: \n","# Uses ACS Table B08303 - TRAVEL TIME TO WORK,\n","# (Universe: Workers 16 years and over who did not work at home) \n","# Table Creates: trav14, trav29, trav44, trav45\n","#purpose: Produce Sustainability - Percent of Employed Population with Travel Time to Work of 45 Minutes and Over Indicator\n","#input: \n","#output: \n","\n","import pandas as pd\n","import glob\n","def trav45(df, columnsToInclude = [] ):\n","    #~~~~~~~~~~~~~~~\n","    # Step 2)\n","    # Prepare the columns\n","    #~~~~~~~~~~~~~~~ \n","\n","    # Final Dataframe  \n","    fi = pd.DataFrame()\n","    columns = ['B08303_011E','B08303_012E','B08303_013E','B08303_001E', 'tract'] \n","    columns.extend(columnsToInclude)\n","    for col in columns:\n","        fi = addKey(df, fi, col)\n","\n","    # Numerators \n","    numerators = pd.DataFrame()\n","    columns = ['B08303_011E','B08303_012E','B08303_013E']\n","    for col in columns:\n","        numerators = addKey(df, numerators, col)\n","    \n","    # Denominators\n","    denominators = pd.DataFrame()\n","    columns = ['B08303_001E']\n","    for col in columns:\n","        denominators = addKey(df, denominators, col)\n","    # construct the denominator, returns 0 iff the other two rows are equal.\n","\n","    #~~~~~~~~~~~~~~~\n","    # Step 3)\n","    # Run the Calculation \n","# ( (value[1] + value[2] + value[3] ) / nullif(value[4],0) )*100\n","    #~~~~~~~~~~~~~~~\n","    fi['numerator'] = numerators.sum(axis=1)\n","    fi['denominator'] = denominators.sum(axis=1)\n","    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n","    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n","    \n","    return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8du9-KdlWjQQ","cellView":"form"},"source":["#@title Run This Cell: Create trav44\n","\n","#File: trav44.py\n","#Author: Charles Karpati\n","#Date: 1/17/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description: \n","# Uses ACS Table B08303 - TRAVEL TIME TO WORK,\n","# (Universe: Workers 16 years and over who did not work at home)\n","# Table Creates: trav14, trav29, trav44, trav45\n","#purpose: Produce Sustainability - Percent of Employed Population with Travel Time to Work of 30-44 Minutes Indicator\n","#input: \n","#output: \n","\n","import pandas as pd\n","import glob\n","def trav44( df, columnsToInclude = [] ):\n","    #~~~~~~~~~~~~~~~\n","    # Step 2)\n","    # Prepare the columns\n","    #~~~~~~~~~~~~~~~ \n","\n","    # Final Dataframe  \n","    fi = pd.DataFrame()\n","    columns = ['B08303_008E','B08303_009E','B08303_010E','B08303_001E', 'tract'] \n","    columns.extend(columnsToInclude) \n","    for col in columns:\n","        fi = addKey(df, fi, col)\n","\n","    # Numerators \n","    numerators = pd.DataFrame()\n","    columns = ['B08303_008E','B08303_009E','B08303_010E']\n","    for col in columns:\n","        numerators = addKey(df, numerators, col)\n","    \n","    # Denominators\n","    denominators = pd.DataFrame()\n","    columns = ['B08303_001E']\n","    for col in columns:\n","        denominators = addKey(df, denominators, col)\n","    # construct the denominator, returns 0 iff the other two rows are equal.\n","\n","    #~~~~~~~~~~~~~~~\n","    # Step 3)\n","    # Run the Calculation \n","    # ( (value[1] + value[2] + value[3] ) / nullif(value[4],0) )*100\n","    #~~~~~~~~~~~~~~~\n","    fi['numerator'] = numerators.sum(axis=1)\n","    fi['denominator'] = denominators.sum(axis=1)\n","    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n","    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n","    \n","    return fi\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"B3BwK9RxWjQR"},"source":["#@title Run This Cell: Create affordr\n","\n","#File: affordr.py\n","#Author: Charles Karpati\n","#Date: 1/17/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description: \n","# Uses ACS Table B25070 - GROSS RENT AS A PERCENTAGE OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS \n","# Universe: Renter-occupied housing units\n","#purpose: Produce Housing and Community Development - Affordability Index - Rent Indicator\n","#input: \n","#output: \n","\n","import pandas as pd\n","import glob\n","def affordr( df, columnsToInclude ):    \n","    #~~~~~~~~~~~~~~~\n","    # Step 2)\n","    # Prepare the columns\n","    #~~~~~~~~~~~~~~~ \n","\n","    # Final Dataframe  \n","    fi = pd.DataFrame()\n","    columns = ['B25070_007E','B25070_008E','B25070_009E','B25070_010E','B25070_001E', 'tract'] \n","    columns.extend(columnsToInclude) \n","    for col in columns:\n","        fi = addKey(df, fi, col)\n","\n","    # Numerators \n","    numerators = pd.DataFrame()\n","    columns = ['B25070_007E','B25070_008E','B25070_009E','B25070_010E']\n","    for col in columns:\n","        numerators = addKey(df, numerators, col)\n","    \n","    # Denominators\n","    denominators = pd.DataFrame()\n","    columns = ['B25070_001E']\n","    for col in columns:\n","        denominators = addKey(df, denominators, col)\n","    # construct the denominator, returns 0 iff the other two rows are equal.\n","\n","    #~~~~~~~~~~~~~~~\n","    # Step 3)\n","    # Run the Calculation \n","    # ( (value[1]+value[2]+value[3]+value[4]) / nullif(value[5],0) )*100\n","    #~~~~~~~~~~~~~~~\n","    fi['numerator'] = numerators.sum(axis=1)\n","    fi['denominator'] = denominators.sum(axis=1)\n","    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n","    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n","    \n","    return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7I6_sIJkWjQS","cellView":"form"},"source":["#@title Run This Cell: Create affordm\n","\n","#File: affordm.py\n","#Author: Charles Karpati\n","#Date: 1/25/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description: \n","# Uses ACS Table B25091 - MORTGAGE STATUS BY SELECTED MONTHLY OWNER COSTS AS A PERCENTAGE OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS\n","# Universe: Owner-occupied housing units\n","# Table Creates: \n","#purpose: Produce Housing and Community Development - Affordability Index - Mortgage Indicator\n","#input: \n","#output: \n","\n","import pandas as pd\n","import glob\n","def affordm( df, columnsToInclude ):  \n","    #~~~~~~~~~~~~~~~\n","    # Step 1)\n","    # Prepare the columns\n","    #~~~~~~~~~~~~~~~ \n","\n","    # Final Dataframe  \n","    fi = pd.DataFrame()\n","    columns = ['B25091_008E','B25091_009E','B25091_010E','B25091_011E','B25091_002E', 'tract'] \n","    columns.extend(columnsToInclude) \n","    for col in columns:\n","        fi = addKey(df, fi, col)\n","\n","    # Numerators \n","    numerators = pd.DataFrame()\n","    columns = ['B25091_008E','B25091_009E','B25091_010E','B25091_011E']\n","    for col in columns:\n","        numerators = addKey(df, numerators, col)\n","    \n","    # Denominators\n","    denominators = pd.DataFrame()\n","    columns = ['B25091_002E']\n","    for col in columns:\n","        denominators = addKey(df, denominators, col)\n","    # construct the denominator, returns 0 iff the other two rows are equal.\n","\n","    #~~~~~~~~~~~~~~~\n","    # Step 3)\n","    # Run the Calculation \n","    # ( (value[1]+value[2]+value[3]+value[4]) / nullif(value[5],0) )*100\n","    #~~~~~~~~~~~~~~~\n","    fi['numerator'] = numerators.sum(axis=1)\n","    fi['denominator'] = denominators.sum(axis=1)\n","    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n","    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n","    \n","    return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"0xC8JGi1WjQS"},"source":["#@title Run This Cell: Create age5\n","\n","#File: age5.py\n","#Author: Charles Karpati\n","#Date: 4/16/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description: \n","# Uses ACS Table B01001 - SEX BY AGE\n","# Universe: Total population\n","# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n","#purpose: \n","#input: #output: \n","\n","import pandas as pd\n","import glob\n","def age5( df, columnsToInclude ):\n","\n","  #~~~~~~~~~~~~~~~\n","    # Step 1)\n","    # Prepare the columns\n","    #~~~~~~~~~~~~~~~\n","    # Final Dataframe  \n","    fi = pd.DataFrame()\n","    columns = ['B01001_027E_Total_Female_Under_5_years',\n","               'B01001_003E_Total_Male_Under_5_years', \n","               'B01001_001E_Total' , 'tract'] \n","    columns.extend(columnsToInclude) \n","    for col in columns:\n","        fi = addKey(df, fi, col)\n","\n","    # Under 5\n","    fi['final']  = ( df[ 'B01001_003E_Total_Male_Under_5_years' ] \n","               + df[ 'B01001_027E_Total_Female_Under_5_years' ] \n","    ) / df['B01001_001E_Total'] * 100\n","\n","    return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jwtX-burcfko","cellView":"form"},"source":["#@title Run This Cell: age65\n","\n","import pandas as pd\n","import glob\n","def age65( df, columnsToInclude ): \n","  #~~~~~~~~~~~~~~~\n","  # Step 1)\n","  # Prepare the columns\n","  #~~~~~~~~~~~~~~~\n","  # Final Dataframe  \n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|020E|021E|022E|023E|024E|025E|044E|045E|046E|047E|048E|049E').columns.values  \n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col) \n","\n","#  print('COLS ')\n","#  print(df.columns)\n","  print(' ')\n","  # over 65\n","  fi['age65']  = ( df.filter(regex='020E|021E|022E|023E|024E|025E|044E|045E|046E|047E|048E|049E').sum(axis=1)\n",") / df['B01001_001E_Total:'] * 100 \n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OKnNsJGJbsnX","cellView":"form"},"source":["#@title Run This Cell: age18\n","\n","#File: age18.py\n","#Author: Charles Karpati\n","#Date: 4/16/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description: \n","# Uses ACS Table B01001 - SEX BY AGE\n","# Universe: Total population\n","# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n","#purpose: \n","#input: #output: \n","\n","import pandas as pd\n","import glob\n","def age18( df, columnsToInclude ):\n","  print(df.columns)\n","  #~~~~~~~~~~~~~~~\n","  # Step 1)\n","  # Prepare the columns\n","  #~~~~~~~~~~~~~~~\n","  # Final Dataframe  \n","  fi = pd.DataFrame()\n","\n","  columns = ['B01001_001E_Total',\n","            'B01001_004E_Total_Male_5_to_9_years', \n","            'B01001_005E_Total_Male_10_to_14_years' , \n","            'B01001_006E_Total_Male_15_to_17_years',\n","            'B01001_028E_Total_Female_5_to_9_years', \n","            'B01001_029E_Total_Female_10_to_14_years' , \n","             'B01001_030E_Total_Female_15_to_17_years'] \n","  columns = df.filter(regex='001E|004E|005E|006E|028E|029E|030E').columns.values  \n","  columns = numpy.append(columns, columnsToInclude)\n","  for col in columns: \n","      fi = addKey(df, fi, col)\n","      print(' ')\n","\n","  # Under 5\n","  fi['age18']  = ( df.filter(regex='004E|005E|006E|028E|029E|030E').sum(axis=1)\n",") / df['B01001_001E_Total:'] * 100 \n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbB11uoNtrWU","cellView":"form"},"source":["#@title Run This Cell: paa\n","\n","import pandas as pd\n","import glob\n","def paa( df, columnsToInclude ):\n","  print(df.columns)\n","  #~~~~~~~~~~~~~~~\n","  # Step 1)\n","  # Prepare the columns\n","  #~~~~~~~~~~~~~~~\n","  # Final Dataframe  \n","  fi = pd.DataFrame()\n","\n","  columns = ['B03002_001E_Total:',\n","             'B03002_004E_Total_Not_Hispanic_or_Latino_Black_or_African_American_alone'] \n","  columns = df.filter(regex='001E|004E').columns.values \n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      print('addKey df',df.columns,'fi',fi.columns,'col: ', col)\n","      fi = addKey(df, fi, col)\n","      print(' ')\n","\n","  # Calculate\n","  fi['paa']  = ( df.filter(regex='004E').sum(axis=1)\n",") / df['B03002_001E_Total:'] * 100 \n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcuKChg9xpO6","cellView":"form"},"source":["#@title Run This Cell:  hisp\n","\n","import pandas as pd\n","import glob\n","def hisp( df, columnsToInclude ):\n","  print(df.columns)\n","  #~~~~~~~~~~~~~~~\n","  # Step 1)\n","  # Prepare the columns\n","  #~~~~~~~~~~~~~~~\n","  # Final Dataframe  \n","  fi = pd.DataFrame() \n","\n","  columns = ['B03002_001E_Total',\n","             'B03002_012E_Total_Hispanic_or_Latino'] \n","  columns = df.filter(regex='001E|012E').columns.values \n","  columns = numpy.append(columns, columnsToInclude)\n","  for col in columns:\n","      print('addKey df',df.columns,'fi',fi.columns,'col: ', col)\n","      fi = addKey(df, fi, col)\n","      print(' ')\n","\n","  # Calculate\n","  fi['hisp']  = ( df.filter(regex='012E').sum(axis=1)\n",") / df['B03002_001E_Total:'] * 100 \n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gytgEUQfx5ff","cellView":"form"},"source":["#@title Run This Cell: pwhite\n","\n","import pandas as pd\n","import glob\n","def pwhite( df, columnsToInclude ):\n","  print(df.columns)\n","  #~~~~~~~~~~~~~~~\n","  # Step 1)\n","  # Prepare the columns\n","  #~~~~~~~~~~~~~~~\n","  # Final Dataframe  \n","  fi = pd.DataFrame()\n","  columns = ['B03002_001E_Total',\n","             'B03002_003E_Total_Not_Hispanic_or_Latino_White_alone'] \n","  columns = df.filter(regex='001E|003E').columns.values \n","  columns = numpy.append(columns, columnsToInclude)\n","  for col in columns:\n","      print('addKey df',df.columns,'fi',fi.columns,'col: ', col)\n","      fi = addKey(df, fi, col)\n","      print(' ')\n","\n","  # Calculate\n","  fi['pwhite']  = ( df.filter(regex='003E').sum(axis=1)\n",") / df['B03002_001E_Total:'] * 100 \n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6GZA8dfg2k8X","cellView":"form"},"source":["#@title Run This Cell: hh25inc\n","\n","import pandas as pd\n","import glob\n","def hh25inc( df, columnsToInclude ):\n","  # df.columns = df.columns.str.replace(r\"[,]\", \"\")\n","  df.columns = df.columns.str.replace(r\"[$]\", \"\")\n","  print(df.columns)\n","  #~~~~~~~~~~~~~~~\n","  # Step 1)\n","  # Prepare the columns\n","  #~~~~~~~~~~~~~~~\n","  # Final Dataframe  \n","  fi = pd.DataFrame()\n","  columns = ['B19001_001E_Total', \n","       \"B19001_002E_Total_Less_than_10,000\",\n","       \"B19001_003E_Total_10,000_to_14,999\",\n","       \"B19001_004E_Total_15,000_to_19,999\",\n","       \"B19001_005E_Total_20,000_to_24,999\"] \n","  columns = df.filter(regex='002E|003E|004E|005E|001E').columns.values \n","  columns = numpy.append(columns, columnsToInclude)\n","  for col in columns:\n","      print('addKey col: ', col, df.columns)\n","      fi = addKey(df, fi, col)\n","\n","  # Calculate\n","  fi['hh25inc']  = ( df.filter(regex='002E|003E|004E|005E').sum(axis=1)\n",") / df['B19001_001E_Total:'] * 100 \n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdM07mBxFp5G","cellView":"form"},"source":["#@title Run This Cell: novhcl\n","\n","import pandas as pd\n","import glob\n","def novhcl( df, columnsToInclude ):\n","  print(df.columns)\n","  #~~~~~~~~~~~~~~~\n","  # Step 1)\n","  # Prepare the columns\n","  #~~~~~~~~~~~~~~~\n","  # Final Dataframe  \n","  fi = pd.DataFrame()\n","\n","  columns = ['B08201_002E_Total_No_vehicle_available','B08201_001E_Total'] \n","  columns = df.filter(regex='002E|003E|004E|005E|001E').columns.values \n","  columns = numpy.append(columns, columnsToInclude)\n","  for col in columns:\n","      print('addKey df',df.columns,'fi',fi.columns,'col: ', col)\n","      fi = addKey(df, fi, col)\n","      print(' ')\n","\n","  # Calculate\n","  fi['novhcl']  = ( df.filter(regex='002E').sum(axis=1)\n",") / df['B08201_001E_Total:'] * 100 \n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PccycL_8JlEI","cellView":"form"},"source":["#@title Run This Cell: nohhint\n","\n","import pandas as pd\n","import glob\n","def nohhint( df, columnsToInclude ):\n","  print(df.columns)\n","  #~~~~~~~~~~~~~~~\n","  # Step 1)\n","  # Prepare the columns\n","  #~~~~~~~~~~~~~~~\n","  # Final Dataframe  \n","  fi = pd.DataFrame()\n"," \n","  columns = ['B28011_001E_Total',\n","       'B28011_002E_Total_With_an_Internet_subscription',\n","       'B28011_003E_Total_With_an_Internet_subscription_Dial-up_alone',\n","       'B28011_004E_Total_With_an_Internet_subscription_Broadband_such_as_cable,_fiber_optic,_or_DSL',\n","       'B28011_005E_Total_With_an_Internet_subscription_Satellite_Internet_service',\n","       'B28011_006E_Total_With_an_Internet_subscription_Other_service',\n","       'B28011_007E_Total_Internet_access_without_a_subscription',\n","       'B28011_008E_Total_No_Internet_access']\n","  columns = df.filter(regex='008E|001E').columns.values \n","  columns = numpy.append(columns, columnsToInclude)\n","  for col in columns:\n","      print('addKey df',df.columns,'col: ', col)\n","      fi = addKey(df, fi, col)\n","      print(' ') \n","\n","  # Calculate\n","  fi['nohhint']  = ( df.filter(regex='008E').sum(axis=1)\n",") / df['B28011_001E_Total:'] * 100 \n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VHxedLQBWjQT"},"source":["Now that our calculations have been created, lets: \n","- create a final function that will download our data, \n","- optionally crosswalk and \n","- optionally aggregate it, and then \n","- run/return the appropriate calculation. "]},{"cell_type":"code","metadata":{"id":"bOjL2YPUW3qV"},"source":["%%capture\n","!pip install geopandas"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hCeX2tdwWjQT","cellView":"form"},"source":["# export\n","#@title Run This Cell: Create createIndicator()\n","import geopandas as gpd\n","import numpy as np\n","import pandas as pd\n","def createAcsIndicator(state, county, tract, year, tableId, saveAcs,\n","                    cwUrl, cw_left_col, cw_right_col, merge_how,\n","                    saveCrosswalked, saveCrosswalkedFileName, groupBy,\n","                    aggMethod, method, columnsToInclude, finalFileName=False):\n","\n","  # Pull the data\n","  df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)\n","  print('Table: ' + tableId + ', Year: ' + year + ' imported.')\n","\n","  # Get the crosswalk\n","  if cwUrl:\n","    right_ds = pd.read_csv( cwUrl )\n","    print('Tract-ACS Crosswalk file imported')\n","    # Merge crosswalk with the data\n","    df = mergeDatasets( left_ds=df, right_ds=right_ds,\n","                  left_col=cw_left_col, right_col=cw_right_col,\n","                  merge_how=merge_how, interactive=False )\n","\n","    print('Both are now merged.')\n","\n","  # Group and Aggregate\n","  if groupBy:\n","    df = df.groupby(groupBy)\n","    print('Aggregating...')\n","    if aggMethod == 'sum':\n","      df = sumInts(df)\n","    else:\n","      df = sumInts(df)\n","    print('Aggregated')\n","\n","  # Create the indicator\n","  print('Creating Indicator')\n","  resp = method( df, columnsToInclude)\n","  print('Indicator Created')\n","  if finalFileName:\n","    resp.to_csv(finalFileName, quoting=csv.QUOTE_ALL)\n","    print('Indicator Saved')\n","\n","\n","\n","  return resp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yKAUCASnZzze"},"source":["## Run Em"]},{"cell_type":"code","metadata":{"id":"uHt-pWlwWjQU"},"source":["# Create the indicator\n","ind1 = createIndicator(state, county, tract, year, tableId, saveAcs, \n","                       cwUrl, cw_left_col, cw_right_col, right_col, saveCrosswalked, crosswalkedFileName, \n","                       groupBy, aggMethod, method, columnsToInclude, finalFileName)\n","columnsToInclude = [columnsToInclude[0]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XiMOXDpoWjQU"},"source":["# Create the trav45 Indicator\n","tableId = 'B08303'\n","finalFileName = './trav45_20'+year+'_tracts_26July2019.csv'\n","method = trav45\n","ind2 = createIndicator(state, county, tract, year, tableId, saveAcs, cwUrl, \n","                       local_match_col, foreign_match_col, foreign_wanted_col, saveCrosswalked, \n","                       crosswalkedFileName, groupBy, aggMethod, method, columnsToInclude, finalFileName)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JTgWLnKBWjQV"},"source":["# Create the trav44 Indicator\n","tableId = 'B08303'\n","finalFileName = './trav44_20'+year+'_tracts_26July2019.csv'\n","method = trav44\n","ind3 = createIndicator(state, county, tract, year, tableId, saveAcs, cwUrl, \n","                       local_match_col, foreign_match_col, foreign_wanted_col, saveCrosswalked,\n","                       crosswalkedFileName, groupBy, aggMethod, method, columnsToInclude, finalFileName)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tobWhJw_WjQV"},"source":["# Create the affordr Indicator\n","tableId = 'B25070'\n","finalFileName = './affordr_20'+year+'_tracts_26July2019.csv'\n","method = affordr\n","ind4 = createIndicator(state, county, tract, year, tableId, saveAcs, cwUrl, \n","                       local_match_col, foreign_match_col, foreign_wanted_col, saveCrosswalked, \n","                       crosswalkedFileName, groupBy, aggMethod, method, columnsToInclude, finalFileName)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DdBnYy7xWjQW"},"source":["# Create the affordm Indicator. Only at the Tract Level this time\n","tableId = 'B25091'\n","finalFileName = './affordm_20'+year+'_tracts_26July2019.csv'\n","method = affordm\n","ind5 = createIndicator(state, county, tract, year, tableId, saveAcs, cwUrl, \n","                       local_match_col, foreign_match_col, foreign_wanted_col, saveCrosswalked, \n","                       crosswalkedFileName, groupBy, aggMethod, method, columnsToInclude, finalFileName)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"elbeMCQvWjQW"},"source":["# Create the age5 Indicator. Only at the Tract Level this time\n","tableId = 'B01001'\n","finalFileName = './age5_20'+year+'_communities_9Sept2019.csv'\n","method = age5\n","groupBy = 'CSA2010'\n","columnsToInclude = []\n","ind5 = createIndicator(state, county, tract, year, tableId, saveAcs, cwUrl, \n","                       local_match_col, foreign_match_col, foreign_wanted_col, saveCrosswalked, \n","                       crosswalkedFileName, groupBy, aggMethod, method, columnsToInclude, finalFileName)\n","ind5.head()"],"execution_count":null,"outputs":[]}]}