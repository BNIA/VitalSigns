{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04_Create_Acs_Indicators.ipynb","provenance":[],"collapsed_sections":["yKAUCASnZzze"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"cMo4IRjn0UBN"},"source":["# default_exp create"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hzlqInyBR3rs"},"source":["!pip install VitalSigns dataplay geopandas"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BpDyH_KW1hI7","colab":{"base_uri":"https://localhost:8080/","height":78},"executionInfo":{"status":"ok","timestamp":1631923102375,"user_tz":240,"elapsed":92,"user":{"displayName":"Baltimore Neighborhood Indicators Alliance","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-q3A7kTIHf7wESw989OAOaJeUYKXGEdoA4M3NTA=s64","userId":"16379023391965073054"}},"outputId":"972dc6fc-97a0-4df6-ee75-4bbfb2b94caa"},"source":["import pandas as pd\n","inst = pd.read_csv('ACS_Processing.csv')\n","inst.head(1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Shortname</th>\n","      <th>tables</th>\n","      <th>Numerator</th>\n","      <th>Denominators</th>\n","      <th>Special Table</th>\n","      <th>Operation</th>\n","      <th>Percent</th>\n","      <th>Come Back To</th>\n","      <th>Unnamed: 8</th>\n","      <th>Unnamed: 9</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>racdiv</td>\n","      <td>B02001</td>\n","      <td>002E|003E|04E|005E|006E|012E|001E</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>Complex</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Shortname  tables  ... Unnamed: 8 Unnamed: 9\n","0    racdiv  B02001  ...        NaN        NaN\n","\n","[1 rows x 10 columns]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"WuC7KC8OWjQJ","cellView":"form"},"source":["#export \n","\n","#@title Run This Cell: Misc Function Declarations\n","# These functions right here are used in the calculations below.\n","# Finds a column matchings a substring\n","def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n","def getColByName (df, col): return df[getColName(df, col)]\n","\n","# Pulls a column from one dataset into a new dataset.\n","# This is not a crosswalk. calls getColByName()\n","def addKey(df, fi, col):\n","    key = getColName(df, col)\n","    val = getColByName(df, col)\n","    fi[key] = val\n","    return fi\n","# Return 0 if two specified columns are equal.\n","def nullIfEqual(df, c1, c2):\n","    return df.apply(lambda x:\n","        x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n","# I'm thinking this doesnt need to be a function..\n","def sumInts(df): return df.sum(numeric_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J4wGfVlaDaWu","executionInfo":{"status":"ok","timestamp":1631924021560,"user_tz":240,"elapsed":74021,"user":{"displayName":"Baltimore Neighborhood Indicators Alliance","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-q3A7kTIHf7wESw989OAOaJeUYKXGEdoA4M3NTA=s64","userId":"16379023391965073054"}},"outputId":"cb862799-1bf3-44b7-c46b-b73e3f2af18e"},"source":["from VitalSigns.acsDownload import retrieve_acs_data\n","from dataplay.merge import mergeDatasets\n","from dataplay.intaker import Intake \n","import numpy as np\n","import csv\n","from IPython.display import clear_output\n","import geopandas as gpd\n","def calculateSimpleIndicator( shortname, tableId, numerators, denominators, aggregateTableId, operations, percent, specialNote, \n","                             state='24', county='510', tract='*', year='19', saveAcs=False, columnsToInclude = '',\n","                             mergeUrl = 'https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv',\n","                             merge_left_col = 'tract', merge_right_col= 'TRACTCE10', merge_how = 'outer', groupBy = 'CSA2010'):\n","  # clear_output(wait=True)\n","  if shortname[0:3] in ['age', 'tra', 'biz', 'mor']: shortname = shortname+'_'\n","  lbl = shortname+'_'+year\n","  # print('\\n ~~~~~~~~~~~~~~~~~~~~ Creating:', lbl, '~~~~~~~~~~~~~~~~~~~~');\n","\n","  # Pull the data\n","  df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)\n","\n","  # Get the crosswalk\n","  if mergeUrl:\n","    right_ds = Intake.getData( mergeUrl ) \n","    df = mergeDatasets( left_ds=df, right_ds=right_ds, left_col=merge_left_col, right_col=merge_right_col, merge_how=merge_how, interactive=False )\n","\n","  # Group and Aggregate\n","  if groupBy:\n","    df = df.groupby(groupBy)\n","    if operations == 'sum':\n","      df = sumInts(df)\n","    else:\n","      df = sumInts(df) \n","    # print('Aggregated ACS on Crosswalk.')\n","\n","  # Create the indicator\n","  columns = numerators + '|' + denominators; \n","  if (columnsToInclude): columns = columns + '|'+ columnsToInclude\n","  fi = df.filter( regex = columns ).copy()\n","  fi[lbl]  = ( df.filter(regex=numerators).sum(axis=1) ) / df.filter(regex=denominators).sum(axis=1) * 100\n","\n","  filename = \"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/\"+shortname+\"/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\"\n","  print(filename)\n","  compareYears = gpd.read_file(filename);\n","  goback = 0\n","  prevYear = shortname+ str( int(year) - goback )\n","  if prevYear in compareYears.columns:\n","    fi = fi.merge( compareYears[['CSA2010', prevYear]], left_on='CSA2010', right_on='CSA2010', how='outer' )\n","    print(fi.columns)\n","    fi['change'] = fi[lbl] - fi[ prevYear ]\n","    fi['percentChange'] = fi['change' ] / fi[ prevYear ] * 100\n","    fi['change'] = fi['change'].apply(lambda x: \"{:.2f}\".format(x) )\n","\n","  if shortname:\n","    fi.to_csv(lbl+'.csv', quoting=csv.QUOTE_ALL)\n","    # print('Indicator Saved')\n","\n","for index, row in inst[:].iterrows():\n","  if (row['Come Back To'] == '-'): calculateSimpleIndicator( row['Shortname'], row['tables'], row['Numerator'], row['Denominators'], row['Special Table'], row['Operation'], row['Percent'], row['Come Back To'])\n","  else: print('\\r\\n --> ',row['Shortname'], '-->', row['Come Back To'])\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r\n"," -->  racdiv --> Complex\n","\r\n"," -->  othrcom --> 100 - ( walked + drvalone + carpool + pubtran + workfromhome )\n","\r\n"," -->  hhpov --> Null if Equal\n","Number of Columns 21\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/pasi/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B03002_001E_Total:',\n","       'B03002_006E_Total:_Not_Hispanic_or_Latino:_Asian_alone', 'pasi_19',\n","       'pasi19'],\n","      dtype='object')\n","\n"," -->  elheat --> nullif\n","\n"," -->  empl --> nullif\n","\n"," -->  fam --> df[df.index != 'Unassigned--Jail']\n","Number of Columns 49\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/female/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Number of Columns 19\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/femhhs/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010',\n","       'B11005_002E_Total:_Households_with_one_or_more_people_under_18_years:',\n","       'B11005_007E_Total:_Households_with_one_or_more_people_under_18_years:_Family_households:_Other_family:_Female_householder,_no_spouse_present',\n","       'femhhs_19', 'femhhs19'],\n","      dtype='object')\n","\n"," -->  heatgas --> nullif\n","\n"," -->  hh40inc --> nullif\n","\n"," -->  hh60inc --> nullif\n","\n"," -->  hh75inc --> nullif\n","Number of Columns 59\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010',\n","       'B17001_004E_Total:_Income_in_the_past_12_months_below_poverty_level:_Male:_Under_5_years',\n","       'B17001_005E_Total:_Income_in_the_past_12_months_below_poverty_level:_Male:_5_years',\n","       'B17001_006E_Total:_Income_in_the_past_12_months_below_poverty_level:_Male:_6_to_11_years',\n","       'B17001_007E_Total:_Income_in_the_past_12_months_below_poverty_level:_Male:_12_to_14_years',\n","       'B17001_008E_Total:_Income_in_the_past_12_months_below_poverty_level:_Male:_15_years',\n","       'B17001_009E_Total:_Income_in_the_past_12_months_below_poverty_level:_Male:_16_and_17_years',\n","       'B17001_018E_Total:_Income_in_the_past_12_months_below_poverty_level:_Female:_Under_5_years',\n","       'B17001_019E_Total:_Income_in_the_past_12_months_below_poverty_level:_Female:_5_years',\n","       'B17001_020E_Total:_Income_in_the_past_12_months_below_poverty_level:_Female:_6_to_11_years',\n","       'B17001_021E_Total:_Income_in_the_past_12_months_below_poverty_level:_Female:_12_to_14_years',\n","       'B17001_022E_Total:_Income_in_the_past_12_months_below_poverty_level:_Female:_15_years',\n","       'B17001_023E_Total:_Income_in_the_past_12_months_below_poverty_level:_Female:_16_and_17_years',\n","       'B17001_033E_Total:_Income_in_the_past_12_months_at_or_above_poverty_level:_Male:_Under_5_years',\n","       'B17001_034E_Total:_Income_in_the_past_12_months_at_or_above_poverty_level:_Male:_5_years',\n","       'B17001_035E_Total:_Income_in_the_past_12_months_at_or_above_poverty_level:_Male:_6_to_11_years',\n","       'B17001_036E_Total:_Income_in_the_past_12_months_at_or_above_poverty_level:_Male:_12_to_14_years',\n","       'B17001_037E_Total:_Income_in_the_past_12_months_at_or_above_poverty_level:_Male:_15_years',\n","       'B17001_038E_Total:_Income_in_the_past_12_months_at_or_above_poverty_level:_Male:_16_and_17_years',\n","       'B17001_047E_Total:_Income_in_the_past_12_months_at_or_above_poverty_level:_Female:_Under_5_years',\n","       'B17001_048E_Total:_Income_in_the_past_12_months_at_or_above_poverty_level:_Female:_5_years',\n","       'B17001_049E_Total:_Income_in_the_past_12_months_at_or_above_poverty_level:_Female:_6_to_11_years',\n","       'B17001_050E_Total:_Income_in_the_past_12_months_at_or_above_poverty_level:_Female:_12_to_14_years',\n","       'B17001_051E_Total:_Income_in_the_past_12_months_at_or_above_poverty_level:_Female:_15_years',\n","       'B17001_052E_Total:_Income_in_the_past_12_months_at_or_above_poverty_level:_Female:_16_and_17_years',\n","       'hhchpov_19', 'hhchpov19'],\n","      dtype='object')\n","Number of Columns 17\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/hhm75/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B19001_001E_Total:', 'B19001_002E_Total:_Less_than_$10,000',\n","       'B19001_003E_Total:_$10,000_to_$14,999',\n","       'B19001_004E_Total:_$15,000_to_$19,999',\n","       'B19001_005E_Total:_$20,000_to_$24,999',\n","       'B19001_006E_Total:_$25,000_to_$29,999',\n","       'B19001_007E_Total:_$30,000_to_$34,999',\n","       'B19001_008E_Total:_$35,000_to_$39,999',\n","       'B19001_009E_Total:_$40,000_to_$44,999',\n","       'B19001_010E_Total:_$45,000_to_$49,999',\n","       'B19001_011E_Total:_$50,000_to_$59,999',\n","       'B19001_012E_Total:_$60,000_to_$74,999', 'hhm75_19', 'hhm7519'],\n","      dtype='object')\n","Number of Columns 19\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/hhs/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B11005_001E_Total:',\n","       'B11005_004E_Total:_Households_with_one_or_more_people_under_18_years:_Family_households:_Married-couple_family',\n","       'B11005_013E_Total:_Households_with_no_people_under_18_years:_Family_households:_Married-couple_family',\n","       'hhs_19', 'hhs19'],\n","      dtype='object')\n","\n"," -->  hsdipl --> nullif\n","\n"," -->  lesshs --> nullif\n","\n"," -->  male --> nan\n","\n"," -->  nilf --> nullif\n","\n"," -->  p2more --> nan\n","\n"," -->  pubtran --> ( value[3] / nullif((value[1]-value[2]),0) )*100\n","Number of Columns 49\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/age5_/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B01001_001E_Total:', 'age5__19', 'age5_19'], dtype='object')\n","Number of Columns 49\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/age18_/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B01001_001E_Total:',\n","       'B01001_004E_Total:_Male:_5_to_9_years',\n","       'B01001_005E_Total:_Male:_10_to_14_years',\n","       'B01001_006E_Total:_Male:_15_to_17_years',\n","       'B01001_028E_Total:_Female:_5_to_9_years',\n","       'B01001_029E_Total:_Female:_10_to_14_years',\n","       'B01001_030E_Total:_Female:_15_to_17_years', 'age18__19', 'age18_19'],\n","      dtype='object')\n","Number of Columns 49\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/age24_/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B01001_001E_Total:', 'age24__19', 'age24_19'], dtype='object')\n","Number of Columns 49\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/age64_/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B01001_001E_Total:',\n","       'B01001_011E_Total:_Male:_25_to_29_years',\n","       'B01001_012E_Total:_Male:_30_to_34_years',\n","       'B01001_013E_Total:_Male:_35_to_39_years',\n","       'B01001_014E_Total:_Male:_40_to_44_years',\n","       'B01001_015E_Total:_Male:_45_to_49_years',\n","       'B01001_016E_Total:_Male:_50_to_54_years',\n","       'B01001_017E_Total:_Male:_55_to_59_years',\n","       'B01001_018E_Total:_Male:_60_and_61_years',\n","       'B01001_019E_Total:_Male:_62_to_64_years',\n","       'B01001_035E_Total:_Female:_25_to_29_years',\n","       'B01001_036E_Total:_Female:_30_to_34_years',\n","       'B01001_037E_Total:_Female:_35_to_39_years',\n","       'B01001_038E_Total:_Female:_40_to_44_years',\n","       'B01001_039E_Total:_Female:_45_to_49_years',\n","       'B01001_040E_Total:_Female:_50_to_54_years',\n","       'B01001_041E_Total:_Female:_55_to_59_years',\n","       'B01001_042E_Total:_Female:_60_and_61_years',\n","       'B01001_043E_Total:_Female:_62_to_64_years', 'age64__19', 'age64_19'],\n","      dtype='object')\n","Number of Columns 49\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/age65_/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B01001_001E_Total:',\n","       'B01001_020E_Total:_Male:_65_and_66_years',\n","       'B01001_021E_Total:_Male:_67_to_69_years',\n","       'B01001_022E_Total:_Male:_70_to_74_years',\n","       'B01001_023E_Total:_Male:_75_to_79_years',\n","       'B01001_024E_Total:_Male:_80_to_84_years',\n","       'B01001_025E_Total:_Male:_85_years_and_over',\n","       'B01001_044E_Total:_Female:_65_and_66_years',\n","       'B01001_045E_Total:_Female:_67_to_69_years',\n","       'B01001_046E_Total:_Female:_70_to_74_years',\n","       'B01001_047E_Total:_Female:_75_to_79_years',\n","       'B01001_048E_Total:_Female:_80_to_84_years',\n","       'B01001_049E_Total:_Female:_85_years_and_over', 'age65__19',\n","       'age65_19'],\n","      dtype='object')\n","\n"," -->  affordm --> nullif\n","\n"," -->  affordr --> nullif\n","\n"," -->  bahigher --> nullif\n","\n"," -->  carpool --> ( value[3] / nullif((value[1]-value[2]),0) )*100\n","\n"," -->  drvalone --> ( value[3] / nullif((value[1]-value[2]),0) )*100\n","\n"," -->  hh25inc --> nullif\n","\n"," -->  mhhi --> Complex Calculation\n","\n"," -->  nohhint --> nullif\n","\n"," -->  novhcl --> nullif\n","Number of Columns 21\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/paa/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B03002_001E_Total:',\n","       'B03002_004E_Total:_Not_Hispanic_or_Latino:_Black_or_African_American_alone',\n","       'paa_19', 'paa19'],\n","      dtype='object')\n","Number of Columns 21\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/ppac/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B03002_001E_Total:', 'ppac_19', 'ppac19'], dtype='object')\n","Number of Columns 21\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/phisp/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B03002_001E_Total:',\n","       'B03002_012E_Total:_Hispanic_or_Latino:', 'phisp_19', 'phisp19'],\n","      dtype='object')\n","Number of Columns 21\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/pwhite/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B03002_001E_Total:',\n","       'B03002_003E_Total:_Not_Hispanic_or_Latino:_White_alone', 'pwhite_19',\n","       'pwhite19'],\n","      dtype='object')\n","\n"," -->  sclemp --> nullif\n","Number of Columns 49\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/tpop/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","\n"," -->  trav14 --> nullif\n","\n"," -->  trav29 --> nullif\n","\n"," -->  trav44 --> nullif\n","\n"," -->  trav45 --> nullif\n","Number of Columns 173\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/unempl/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010', 'B23001_003E_Total:_Male:_16_to_19_years:',\n","       'B23001_008E_Total:_Male:_16_to_19_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_010E_Total:_Male:_20_and_21_years:',\n","       'B23001_015E_Total:_Male:_20_and_21_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_017E_Total:_Male:_22_to_24_years:',\n","       'B23001_022E_Total:_Male:_22_to_24_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_024E_Total:_Male:_25_to_29_years:',\n","       'B23001_029E_Total:_Male:_25_to_29_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_031E_Total:_Male:_30_to_34_years:',\n","       'B23001_036E_Total:_Male:_30_to_34_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_038E_Total:_Male:_35_to_44_years:',\n","       'B23001_043E_Total:_Male:_35_to_44_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_045E_Total:_Male:_45_to_54_years:',\n","       'B23001_050E_Total:_Male:_45_to_54_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_052E_Total:_Male:_55_to_59_years:',\n","       'B23001_057E_Total:_Male:_55_to_59_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_059E_Total:_Male:_60_and_61_years:',\n","       'B23001_064E_Total:_Male:_60_and_61_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_066E_Total:_Male:_62_to_64_years:',\n","       'B23001_071E_Total:_Male:_62_to_64_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_089E_Total:_Female:_16_to_19_years:',\n","       'B23001_094E_Total:_Female:_16_to_19_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_096E_Total:_Female:_20_and_21_years:',\n","       'B23001_101E_Total:_Female:_20_and_21_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_103E_Total:_Female:_22_to_24_years:',\n","       'B23001_108E_Total:_Female:_22_to_24_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_110E_Total:_Female:_25_to_29_years:',\n","       'B23001_115E_Total:_Female:_25_to_29_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_117E_Total:_Female:_30_to_34_years:',\n","       'B23001_122E_Total:_Female:_30_to_34_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_124E_Total:_Female:_35_to_44_years:',\n","       'B23001_129E_Total:_Female:_35_to_44_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_131E_Total:_Female:_45_to_54_years:',\n","       'B23001_136E_Total:_Female:_45_to_54_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_138E_Total:_Female:_55_to_59_years:',\n","       'B23001_143E_Total:_Female:_55_to_59_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_145E_Total:_Female:_60_and_61_years:',\n","       'B23001_150E_Total:_Female:_60_and_61_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_152E_Total:_Female:_62_to_64_years:',\n","       'B23001_157E_Total:_Female:_62_to_64_years:_In_labor_force:_Civilian:_Unemployed',\n","       'unempl_19', 'unempl19'],\n","      dtype='object')\n","Number of Columns 173\n","https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/unempr/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\n","Index(['CSA2010',\n","       'B23001_006E_Total:_Male:_16_to_19_years:_In_labor_force:_Civilian:',\n","       'B23001_008E_Total:_Male:_16_to_19_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_013E_Total:_Male:_20_and_21_years:_In_labor_force:_Civilian:',\n","       'B23001_015E_Total:_Male:_20_and_21_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_020E_Total:_Male:_22_to_24_years:_In_labor_force:_Civilian:',\n","       'B23001_022E_Total:_Male:_22_to_24_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_027E_Total:_Male:_25_to_29_years:_In_labor_force:_Civilian:',\n","       'B23001_029E_Total:_Male:_25_to_29_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_034E_Total:_Male:_30_to_34_years:_In_labor_force:_Civilian:',\n","       'B23001_036E_Total:_Male:_30_to_34_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_041E_Total:_Male:_35_to_44_years:_In_labor_force:_Civilian:',\n","       'B23001_043E_Total:_Male:_35_to_44_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_048E_Total:_Male:_45_to_54_years:_In_labor_force:_Civilian:',\n","       'B23001_050E_Total:_Male:_45_to_54_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_055E_Total:_Male:_55_to_59_years:_In_labor_force:_Civilian:',\n","       'B23001_057E_Total:_Male:_55_to_59_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_062E_Total:_Male:_60_and_61_years:_In_labor_force:_Civilian:',\n","       'B23001_064E_Total:_Male:_60_and_61_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_069E_Total:_Male:_62_to_64_years:_In_labor_force:_Civilian:',\n","       'B23001_071E_Total:_Male:_62_to_64_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_092E_Total:_Female:_16_to_19_years:_In_labor_force:_Civilian:',\n","       'B23001_094E_Total:_Female:_16_to_19_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_099E_Total:_Female:_20_and_21_years:_In_labor_force:_Civilian:',\n","       'B23001_101E_Total:_Female:_20_and_21_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_106E_Total:_Female:_22_to_24_years:_In_labor_force:_Civilian:',\n","       'B23001_108E_Total:_Female:_22_to_24_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_113E_Total:_Female:_25_to_29_years:_In_labor_force:_Civilian:',\n","       'B23001_115E_Total:_Female:_25_to_29_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_120E_Total:_Female:_30_to_34_years:_In_labor_force:_Civilian:',\n","       'B23001_122E_Total:_Female:_30_to_34_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_127E_Total:_Female:_35_to_44_years:_In_labor_force:_Civilian:',\n","       'B23001_129E_Total:_Female:_35_to_44_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_134E_Total:_Female:_45_to_54_years:_In_labor_force:_Civilian:',\n","       'B23001_136E_Total:_Female:_45_to_54_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_141E_Total:_Female:_55_to_59_years:_In_labor_force:_Civilian:',\n","       'B23001_143E_Total:_Female:_55_to_59_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_148E_Total:_Female:_60_and_61_years:_In_labor_force:_Civilian:',\n","       'B23001_150E_Total:_Female:_60_and_61_years:_In_labor_force:_Civilian:_Unemployed',\n","       'B23001_155E_Total:_Female:_62_to_64_years:_In_labor_force:_Civilian:',\n","       'B23001_157E_Total:_Female:_62_to_64_years:_In_labor_force:_Civilian:_Unemployed',\n","       'unempr_19', 'unempr19'],\n","      dtype='object')\n","\n"," -->  walked --> ( value[3] / nullif((value[1]-value[2]),0) )*100\n","\n"," -->  nan --> nan\n"]}]},{"cell_type":"markdown","metadata":{"id":"kfctZ0YgWjQI"},"source":["# Creating BNIA Indictors"]},{"cell_type":"markdown","metadata":{"id":"K4Jf1e56Kill"},"source":["IMPORT THE MODULES FROM THE OTHER LIBRARY USING PIP"]},{"cell_type":"markdown","metadata":{"id":"PSqXAwQ1WjQJ"},"source":["Awesome! \n","\n","By this point you should be able to download a dataset, and crosswalk new columns onto it by matching on 'tract'\n","\n","What we are going to do now is perform calculations using these newly created datasets.\n","\n","Run the next few cells to create our calculatory functions"]},{"cell_type":"code","metadata":{"cellView":"form","id":"B3BwK9RxWjQR"},"source":["#@title Run This Cell: Create affordr\n","\n","#File: affordr.py\n","#Author: Charles Karpati\n","#Date: 1/17/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description: \n","# Uses ACS Table B25070 - GROSS RENT AS A PERCENTAGE OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS \n","# Universe: Renter-occupied housing units\n","#purpose: Produce Housing and Community Development - Affordability Index - Rent Indicator\n","#input: \n","#output: \n","\n","import pandas as pd\n","import glob\n","def affordr( df, columnsToInclude ):    \n","    #~~~~~~~~~~~~~~~\n","    # Step 2)\n","    # Prepare the columns\n","    #~~~~~~~~~~~~~~~ \n","\n","    # Final Dataframe  \n","    fi = pd.DataFrame()\n","    columns = ['B25070_007E','B25070_008E','B25070_009E','B25070_010E','B25070_001E', 'tract'] \n","    columns.extend(columnsToInclude) \n","    for col in columns:\n","        fi = addKey(df, fi, col)\n","\n","    # Numerators \n","    numerators = pd.DataFrame()\n","    columns = ['B25070_007E','B25070_008E','B25070_009E','B25070_010E']\n","    for col in columns:\n","        numerators = addKey(df, numerators, col)\n","    \n","    # Denominators\n","    denominators = pd.DataFrame()\n","    columns = ['B25070_001E']\n","    for col in columns:\n","        denominators = addKey(df, denominators, col)\n","    # construct the denominator, returns 0 iff the other two rows are equal.\n","\n","    #~~~~~~~~~~~~~~~\n","    # Step 3)\n","    # Run the Calculation \n","    # ( (value[1]+value[2]+value[3]+value[4]) / nullif(value[5],0) )*100\n","    #~~~~~~~~~~~~~~~\n","    fi['numerator'] = numerators.sum(axis=1)\n","    fi['denominator'] = denominators.sum(axis=1)\n","    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n","    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n","    \n","    return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"7I6_sIJkWjQS"},"source":["#@title Run This Cell: Create affordm\n","\n","#File: affordm.py\n","#Author: Charles Karpati\n","#Date: 1/25/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description: \n","# Uses ACS Table B25091 - MORTGAGE STATUS BY SELECTED MONTHLY OWNER COSTS AS A PERCENTAGE OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS\n","# Universe: Owner-occupied housing units\n","# Table Creates: \n","#purpose: Produce Housing and Community Development - Affordability Index - Mortgage Indicator\n","#input: \n","#output: \n","\n","import pandas as pd\n","import glob\n","def affordm( df, columnsToInclude ):  \n","    #~~~~~~~~~~~~~~~\n","    # Step 1)\n","    # Prepare the columns\n","    #~~~~~~~~~~~~~~~ \n","\n","    # Final Dataframe  \n","    fi = pd.DataFrame()\n","    columns = ['B25091_008E','B25091_009E','B25091_010E','B25091_011E','B25091_002E', 'tract'] \n","    columns.extend(columnsToInclude) \n","    for col in columns:\n","        fi = addKey(df, fi, col)\n","\n","    # Numerators \n","    numerators = pd.DataFrame()\n","    columns = ['B25091_008E','B25091_009E','B25091_010E','B25091_011E']\n","    for col in columns:\n","        numerators = addKey(df, numerators, col)\n","    \n","    # Denominators\n","    denominators = pd.DataFrame()\n","    columns = ['B25091_002E']\n","    for col in columns:\n","        denominators = addKey(df, denominators, col)\n","    # construct the denominator, returns 0 iff the other two rows are equal.\n","\n","    #~~~~~~~~~~~~~~~\n","    # Step 3)\n","    # Run the Calculation \n","    # ( (value[1]+value[2]+value[3]+value[4]) / nullif(value[5],0) )*100\n","    #~~~~~~~~~~~~~~~\n","    fi['numerator'] = numerators.sum(axis=1)\n","    fi['denominator'] = denominators.sum(axis=1)\n","    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n","    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n","    \n","    return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xC8JGi1WjQS","cellView":"form"},"source":["#export \n","#@title Run This Cell: Create age5\n","\n","#File: age5.py\n","#Author: Charles Karpati\n","#Date: 4/16/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description:\n","# Uses ACS Table B01001 - SEX BY AGE\n","# Universe: Total population\n","# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n","#purpose:\n","#input: #output:\n","\n","import pandas as pd\n","import glob\n","def age5( df, columnsToInclude ):\n","    fi = pd.DataFrame()\n","    columns = ['B01001_027E_Total_Female_Under_5_years',\n","               'B01001_003E_Total_Male_Under_5_years',\n","               'B01001_001E_Total' , 'tract']\n","    columns.extend(columnsToInclude)\n","    for col in columns:\n","        fi = addKey(df, fi, col)\n","\n","    fi['final']  = ( df[ 'B01001_003E_Total_Male_Under_5_years' ]\n","               + df[ 'B01001_027E_Total_Female_Under_5_years' ]\n","    ) / df['B01001_001E_Total'] * 100\n","\n","    return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"OKnNsJGJbsnX"},"source":["#export \n","#@title Run This Cell: age18\n","\n","#File: age18.py\n","#Author: Charles Karpati\n","#Date: 4/16/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description:\n","# Uses ACS Table B01001 - SEX BY AGE\n","# Universe: Total population\n","# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n","#purpose:\n","#input: #output:\n","\n","import pandas as pd\n","import glob\n","def age18( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = ['B01001_001E_Total',\n","            'B01001_004E_Total_Male_5_to_9_years',\n","            'B01001_005E_Total_Male_10_to_14_years' ,\n","            'B01001_006E_Total_Male_15_to_17_years',\n","            'B01001_028E_Total_Female_5_to_9_years',\n","            'B01001_029E_Total_Female_10_to_14_years' ,\n","             'B01001_030E_Total_Female_15_to_17_years']\n","  columns = df.filter(regex='001E|004E|005E|006E|028E|029E|030E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='004E|005E|006E|028E|029E|030E').sum(axis=1)\n",") / df['B01001_001E_Total:'] * 100\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"4pnUuLX_BmoH"},"source":["#export \n","#@title Run This Cell: Create age24\n","\n","#File: age24.py\n","#Author: Charles Karpati\n","#Date: 9/8/21\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description:\n","# Uses ACS Table B01001 - SEX BY AGE\n","# Universe: Total population\n","# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n","#purpose:\n","#input: #output:\n","\n","import pandas as pd\n","import glob\n","def age24( df, columnsToInclude ):\n","    fi = pd.DataFrame()\n","    columns = ['B01001_007E_Total_Male_18_and_19_years',\n","               'B01001_008E_Total_Male_20_years',\n","               'B01001_009E_Total_Male_21_years' ,\n","               'B01001_010E_Total_Male_22_to_24_years' ,\n","               'B01001_031E_Total_Female_18_and_19_years' ,\n","               'B01001_032E_Total_Female_20_years' ,\n","               'B01001_033E_Total_Female_21_years' ,\n","               'B01001_034E_Total_Female_22_to_24_years',\n","               'tract']\n","    columns.extend(columnsToInclude)\n","    for col in columns:\n","        fi = addKey(df, fi, col)\n","\n","    fi['final']  = ( df[ 'B01001_007E_Total_Male_18_and_19_years' ]\n","               + df[ 'B01001_008E_Total_Male_20_years' ]\n","               + df[ 'B01001_009E_Total_Male_21_years' ]\n","               + df[ 'B01001_010E_Total_Male_22_to_24_years' ]\n","               + df[ 'B01001_031E_Total_Female_18_and_19_years' ]\n","               + df[ 'B01001_032E_Total_Female_20_years' ]\n","               + df[ 'B01001_033E_Total_Female_21_years' ]\n","               + df[ 'B01001_034E_Total_Female_22_to_24_years' ]\n","    ) / df['B01001_001E_Total'] * 100\n","\n","    return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BNIl2bhoDIJU","cellView":"form"},"source":["#export \n","#@title Run This Cell: age64\n","\n","import pandas as pd\n","import glob\n","def age64( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='012E|013E|014E|015E|016E|017E|018E|019E|036E|037E|038E|039E|040E|041E|042E|043E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='012E|013E|014E|015E|016E|017E|018E|019E|036E|037E|038E|039E|040E|041E|042E|043E').sum(axis=1)\n",") / df['B01001_001E_Total:'] * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"jwtX-burcfko"},"source":["#export \n","#@title Run This Cell: age65\n","\n","import pandas as pd\n","import glob\n","def age65( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|020E|021E|022E|023E|024E|025E|044E|045E|046E|047E|048E|049E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='020E|021E|022E|023E|024E|025E|044E|045E|046E|047E|048E|049E').sum(axis=1)\n",") / df['B01001_001E_Total:'] * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"37C9__NrF-MO"},"source":["#export \n","#@title Run This Cell: bahigher\n","\n","import pandas as pd\n","import glob\n","def bahigher( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='005E|006E|001E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='005E|006E').sum(axis=1)\n",") / df['B06009_001E'] * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"XpHqsc9nGTYT"},"source":["#export \n","#@title Run This Cell: - carpool\n","\n","import pandas as pd\n","import glob\n","def carpool( df, columnsToInclude ):\n","  # Final Dataframe\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|017E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='B08101_017E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"6Fo2Sr-9HLlY"},"source":["#export \n","#@title Run This Cell: - drvalone\n","\n","import pandas as pd\n","import glob\n","def drvalone( df, columnsToInclude ):\n","  # Final Dataframe\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SGDC7LNXJl26"},"source":["#export \n","#@ title Run This Cell: -elheat\n","\n","import pandas as pd\n","import glob\n","def elheat( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='B25040_004E|B25040_001E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['final']  = ( df.filter(regex='B25040_004E').sum(axis=1)\n",") / ( df.filter(regex='B25040_001E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"han08mJmJpas"},"source":["#export \n","#@ title Run This Cell: -empl\n","\n","import pandas as pd\n","import glob\n","def empl( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ektnGeZTJr3L"},"source":["#export \n","#@ title Run This Cell: -fam\n","\n","import pandas as pd\n","import glob\n","def fam( df, columnsToInclude ):\n","    \n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TQn1KAIjJtI8"},"source":["#export \n","#@ title Run This Cell: -female\n","\n","import pandas as pd\n","import glob\n","def female( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['female']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIEaYLESJuRz"},"source":["#export \n","#@ title Run This Cell: -femhhs\n","\n","import pandas as pd\n","import glob\n","def femhhs( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['femhhs']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aCLH2G6bJvqb"},"source":["#export \n","#@ title Run This Cell: -heatgas\n","\n","import pandas as pd\n","import glob\n","def heatgas( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"gcuKChg9xpO6"},"source":["#export \n","#@title Run This Cell:  hisp\n","\n","import pandas as pd\n","import glob\n","def hisp( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = ['B03002_001E_Total',\n","             'B03002_012E_Total_Hispanic_or_Latino']\n","  columns = df.filter(regex='001E|012E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","  for col in columns:\n","      print('addKey df',df.columns,'fi',fi.columns,'col: ', col)\n","      fi = addKey(df, fi, col)\n","      print(' ')\n","\n","  fi['final']  = ( df.filter(regex='012E').sum(axis=1)\n",") / df['B03002_001E_Total:'] * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"6GZA8dfg2k8X"},"source":["#export \n","#@title Run This Cell: hh25inc\n","\n","import pandas as pd\n","import glob\n","def hh25inc( df, columnsToInclude ):\n","  df.columns = df.columns.str.replace(r\"[$]\", \"\")\n","  fi = pd.DataFrame()\n","  columns = ['B19001_001E_Total',\n","       \"B19001_002E_Total_Less_than_10,000\",\n","       \"B19001_003E_Total_10,000_to_14,999\",\n","       \"B19001_004E_Total_15,000_to_19,999\",\n","       \"B19001_005E_Total_20,000_to_24,999\"]\n","  columns = df.filter(regex='002E|003E|004E|005E|001E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","  for col in columns:\n","      print('addKey col: ', col, df.columns)\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='002E|003E|004E|005E').sum(axis=1)\n",") / df['B19001_001E_Total:'] * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YjUzM6HWJwsD"},"source":["#export \n","#@ title Run This Cell: -hh40inc\n","\n","import pandas as pd\n","import glob\n","def hh40inc( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGFj1TK3J42s"},"source":["#export \n","#@ title Run This Cell: -hh60inc\n","\n","import pandas as pd\n","import glob\n","def hh60inc( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-a9PcTt-J6Q7"},"source":["#export \n","#@ title Run This Cell: -hh75inc\n","\n","import pandas as pd\n","import glob\n","def hh75inc( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHE7ET21KMhN"},"source":["#export \n","#@ title Run This Cell: -hhchpov\n","\n","import pandas as pd\n","import glob\n","def hhchpov( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eRgYBJsFKOBs"},"source":["#export \n","#@ title Run This Cell: -hhm75\n","\n","import pandas as pd\n","import glob\n","def hhm75( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xus6CAiWKQXN"},"source":["#export \n","#@ title Run This Cell: -hhs\n","\n","import pandas as pd\n","import glob\n","def hhs( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZjMcskfKRMl"},"source":["#export \n","#@ title Run This Cell: -hsdipl\n","\n","import pandas as pd\n","import glob\n","def hsdipl( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KF_mBsMXKS98"},"source":["#export \n","#@ title Run This Cell: -lesshs\n","\n","import pandas as pd\n","import glob\n","def lesshs( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9vLcEfsKUgF"},"source":["#export \n","#@ title Run This Cell: -male\n","\n","import pandas as pd\n","import glob\n","def male( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"S9NQS1_bWjQK"},"source":["#export \n","# @title Run This Cell : Create MHHI\n","\n","#File: mhhi.py\n","#Author: Charles Karpati\n","#Date: 1/24/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description:\n","# Uses ACS Table B19001 - HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2016 INFLATION-ADJUSTED DOLLARS)\n","# Universe: Households\n","# Table Creates: hh25 hh40 hh60 hh75 hhm75, mhhi\n","#purpose: Produce Sustainability - Percent of Population that Walks to Work Indicator\n","#input:\n","#output:\n","import pandas as pd\n","import glob\n","\n","def mhhi( df, columnsToInclude = [] ):\n","  info = pd.DataFrame(\n","      [\n","          ['B19001_002E', 0, 10000],\n","          ['B19001_003E', 10000, 4999 ],\n","          ['B19001_004E', 15000, 4999 ],\n","          ['B19001_005E', 20000, 4999 ],\n","          ['B19001_006E', 25000, 4999 ],\n","          ['B19001_007E', 30000, 4999],\n","          ['B19001_008E', 35000, 4999 ],\n","          ['B19001_009E', 40000, 4999 ],\n","          ['B19001_010E', 45000, 4999 ],\n","          ['B19001_011E', 50000, 9999 ],\n","          ['B19001_012E', 60000, 14999],\n","          ['B19001_013E', 75000, 24999 ],\n","          ['B19001_014E', 100000, 24999 ],\n","          ['B19001_015E', 125000, 24999 ],\n","          ['B19001_016E', 150000, 49000 ],\n","          ['B19001_017E', 200000, 1000000000000000000000000 ],\n","\n","      ],\n","      columns=['variable', 'lower', 'range']\n","  )\n","\n","  # Final Dataframe\n","  data_table = pd.DataFrame()\n","  for index, row in info.iterrows():\n","      data_table = addKey(df, data_table, row['variable'])\n","\n","  # Accumulate totals accross the columns.\n","  # Midpoint: Divide column index 16 (the last column) of the cumulative totals\n","  temp_table = data_table.cumsum(axis=1)\n","  temp_table['midpoint'] = (temp_table.iloc[ : , -1 :] /2) # V3\n","  temp_table['midpoint_index'] = False\n","  temp_table['midpoint_index_value'] = False # Z3\n","  temp_table['midpoint_index_lower'] = False # W3\n","  temp_table['midpoint_index_range'] = False # X3\n","  temp_table['midpoint_index_minus_one_cumulative_sum'] = False #Y3\n","  # step 3 - csa_agg3: get the midpoint index by \"when midpoint > agg[1] and midpoint <= agg[2] then 2\"\n","\n","  # Get CSA Midpoint Index using the breakpoints in our info table.\n","  for index, row in temp_table.iterrows():\n","      # Get the index of the first column where our midpoint is greater than the columns value.\n","      midpoint = row['midpoint']\n","      midpoint_index = 0\n","      # For each column (except the 6 columns we just created)\n","\n","      # The tracts midpoint was < than the first tracts value at column 'B19001_002E_Total_Less_than_$10,000'\n","      if( midpoint < int(row[0]) or row[-6] == False ):\n","        temp_table.loc[ index, 'midpoint_index' ] = 0\n","      else:\n","        for column in row.iloc[:-6]:\n","            # set midpoint index to the column with the highest value possible that is under midpoint\n","            if( midpoint >= int(column) ):\n","                if midpoint==False: print (str(column) + ' - ' + str(midpoint))\n","                temp_table.loc[ index, 'midpoint_index' ] = midpoint_index +1\n","            midpoint_index += 1\n","\n","  # temp_table = temp_table.drop('Unassigned--Jail')\n","  for index, row in temp_table.iterrows():\n","    temp_table.loc[ index, 'midpoint_index_value' ] = data_table.loc[ index, data_table.columns[row['midpoint_index']] ]\n","    temp_table.loc[ index, 'midpoint_index_lower' ] = info.loc[ row['midpoint_index'] ]['lower']\n","    temp_table.loc[ index, 'midpoint_index_range' ] = info.loc[ row['midpoint_index'] ]['range']\n","    temp_table.loc[ index, 'midpoint_index_minus_one_cumulative_sum'] = row[ row['midpoint_index']-1 ]\n","\n","  # This is our denominator, which cant be negative.\n","  for index, row in temp_table.iterrows():\n","    if row['midpoint_index_value']==False:\n","      temp_table.at[index, 'midpoint_index_value']=1;\n","\n","  #~~~~~~~~~~~~~~~\n","  # Step 3)\n","  # Run the Calculation\n","  # Calculation = (midpoint_lower::numeric + (midpoint_range::numeric * ( (midpoint - midpoint_upto_agg) / nullif(midpoint_total,0)\n","  # Calculation = W3+X3*((V3-Y3)/Z3)\n","\n","  # v3 -> 1 - midpoint of households  == sum / 2\n","  # w3 -> 2 - lower limit of the income range containing the midpoint of the housing total == row[lower]\n","  # x3 -> width of the interval containing the medium == row[range]\n","  # z3 -> number of hhs within the interval containing the median == row[total]\n","  # y3 -> 4 - cumulative frequency up to, but no==NOT including the median interval\n","  #~~~~~~~~~~~~~~~\n","\n","  def finalCalc(x):\n","    return ( x['midpoint_index_lower']+ x['midpoint_index_range']*(\n","      ( x['midpoint']-x['midpoint_index_minus_one_cumulative_sum'])/ x['midpoint_index_value'] )\n","    )\n","\n","  temp_table['final'] = temp_table.apply(lambda x: finalCalc(x), axis=1)\n","\n","  temp_table[columnsToInclude] = df[columnsToInclude]\n","\n","  return temp_table"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sviUOHXgKVlu"},"source":["#export \n","#@ title Run This Cell: -nilf\n","\n","import pandas as pd\n","import glob\n","def drvalone( df, columnsToInclude ):\n","    \n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdM07mBxFp5G"},"source":["#export \n","#@title Run This Cell: novhcl\n","\n","import pandas as pd\n","import glob\n","def novhcl( df, columnsToInclude ):\n","    \n","  fi = pd.DataFrame()\n","\n","  columns = ['B08201_002E_Total_No_vehicle_available','B08201_001E_Total']\n","  columns = df.filter(regex='002E|003E|004E|005E|001E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","  for col in columns:\n","      print('addKey df',df.columns,'fi',fi.columns,'col: ', col)\n","      fi = addKey(df, fi, col)\n","      \n","  fi['final']  = ( df.filter(regex='002E').sum(axis=1)\n",") / df['B08201_001E_Total:'] * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"PccycL_8JlEI"},"source":["#export \n","#@title Run This Cell: nohhint\n","\n","import pandas as pd\n","import glob\n","def nohhint( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = ['B28011_001E_Total',\n","       'B28011_002E_Total_With_an_Internet_subscription',\n","       'B28011_003E_Total_With_an_Internet_subscription_Dial-up_alone',\n","       'B28011_004E_Total_With_an_Internet_subscription_Broadband_such_as_cable,_fiber_optic,_or_DSL',\n","       'B28011_005E_Total_With_an_Internet_subscription_Satellite_Internet_service',\n","       'B28011_006E_Total_With_an_Internet_subscription_Other_service',\n","       'B28011_007E_Total_Internet_access_without_a_subscription',\n","       'B28011_008E_Total_No_Internet_access']\n","  columns = df.filter(regex='008E|001E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","  for col in columns:\n","      print('addKey df',df.columns,'col: ', col)\n","      fi = addKey(df, fi, col)\n","      print(' ')\n","\n","  # Calculate\n","  fi['nohhint']  = ( df.filter(regex='008E').sum(axis=1)\n",") / df['B28011_001E_Total:'] * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wu-5bWAhKYKk"},"source":["#export \n","#@ title Run This Cell: -othercom\n","\n","import pandas as pd\n","import glob\n","def othercom( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['othercom']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbB11uoNtrWU"},"source":["#export \n","#@title Run This Cell: paa\n","\n","import pandas as pd\n","import glob\n","def paa( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = ['B03002_001E_Total:',\n","             'B03002_004E_Total_Not_Hispanic_or_Latino_Black_or_African_American_alone']\n","  columns = df.filter(regex='001E|004E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      print('addKey df',df.columns,'fi',fi.columns,'col: ', col)\n","      fi = addKey(df, fi, col)\n","\n","  fi['paa']  = ( df.filter(regex='004E').sum(axis=1)\n",") / df['B03002_001E_Total:'] * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"jn17iD1sKbHc"},"source":["#export \n","#@title Run This Cell: -p2more\n","\n","import pandas as pd\n","import glob\n","def p2more( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['final']  = ( df.filter(regex='B08101_009E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"EC_Jz5EjKd_l"},"source":["#export \n","#@title Run This Cell: -pasi ***\n","\n","import pandas as pd\n","import glob\n","def pasi( df, columnsToInclude ):\n","    \n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='006E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"U6QOoIDUKfE9"},"source":["#export \n","#@title Run This Cell: -pubtran\n","\n","import pandas as pd\n","import glob\n","def pubtran( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='025E|001E|049E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['pubtran']  = ( df.filter(regex='025E').sum(axis=1)\n",") / ( df.filter(regex='B08101_001E|B08101_049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gytgEUQfx5ff"},"source":["#export \n","#@title Run This Cell: pwhite\n","\n","import pandas as pd\n","import glob\n","def pwhite( df, columnsToInclude ):\n","    \n","  fi = pd.DataFrame()\n","  columns = ['B03002_001E_Total',\n","             'B03002_003E_Total_Not_Hispanic_or_Latino_White_alone']\n","  columns = df.filter(regex='001E|003E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","  for col in columns:\n","      print('addKey df',df.columns,'fi',fi.columns,'col: ', col)\n","      fi = addKey(df, fi, col)\n","      print(' ')\n","\n","  # Calculate\n","  fi['pwhite']  = ( df.filter(regex='003E').sum(axis=1)\n",") / df['B03002_001E_Total:'] * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"kbyS5_56Kiac"},"source":["#export \n","#@title Run This Cell: -racdiv ***"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"bvzhGTIMKjwN"},"source":["#export \n","#@title Run This Cell: -sclemp\n","\n","import pandas as pd\n","import glob\n","def sclemp( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|004E|005E|006E|009E|013E|018E|019E|020E|023E|027E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['sclemp']  = ( df.filter(regex='004E|005E|006E|009E|013E|018E|019E|020E|023E|027E').sum(axis=1)\n",") / ( df.filter(regex='001E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"nL7NwFhbKlcc"},"source":["#export \n","#@title Run This Cell: -tpop\n","\n","import pandas as pd\n","import glob\n","def tpop( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['tpop']  = ( df.filter(regex='001E').sum(axis=1)\n",")\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pIgBBtk3Ed-1"},"source":["#export \n","#@title Run This Cell: trav14\n","\n","import pandas as pd\n","import glob\n","def trav14( df, columnsToInclude ):\n","    \n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='002E|003E|004E|001E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['age65']  = ( df.filter(regex='002E|003E|004E').sum(axis=1)\n",") / df['B08303_001E'] * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dGhJL8jjFMQl","cellView":"form"},"source":["#export \n","#@title Run This Cell: trav29\n","\n","import pandas as pd\n","import glob\n","def trav14( df, columnsToInclude ):\n","    \n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='005E|006E|007E|001E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['age65']  = ( df.filter(regex='005E|006E|007E').sum(axis=1)\n",") / df['B08303_001E'] * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PeqketMgWjQO","cellView":"form"},"source":["#export \n","#@title Run This Cell: Create trav45\n","\n","#File: trav45.py\n","#Author: Charles Karpati\n","#Date: 1/17/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description:\n","# Uses ACS Table B08303 - TRAVEL TIME TO WORK,\n","# (Universe: Workers 16 years and over who did not work at home)\n","# Table Creates: trav14, trav29, trav44, trav45\n","#purpose: Produce Sustainability - Percent of Employed Population with Travel Time to Work of 45 Minutes and Over Indicator\n","#input:\n","#output:\n","\n","import pandas as pd\n","import glob\n","def trav45(df, columnsToInclude = [] ):\n","\n","    # Final Dataframe\n","    fi = pd.DataFrame()\n","    columns = ['B08303_011E','B08303_012E','B08303_013E','B08303_001E', 'tract']\n","    columns.extend(columnsToInclude)\n","    for col in columns:\n","        fi = addKey(df, fi, col)\n","\n","    # Numerators\n","    numerators = pd.DataFrame()\n","    columns = ['B08303_011E','B08303_012E','B08303_013E']\n","    for col in columns:\n","        numerators = addKey(df, numerators, col)\n","\n","    # Denominators\n","    denominators = pd.DataFrame()\n","    columns = ['B08303_001E']\n","    for col in columns:\n","        denominators = addKey(df, denominators, col)\n","    # construct the denominator, returns 0 iff the other two rows are equal.\n","\n","    #~~~~~~~~~~~~~~~\n","    # Step 3)\n","    # Run the Calculation\n","# ( (value[1] + value[2] + value[3] ) / nullif(value[4],0) )*100\n","    #~~~~~~~~~~~~~~~\n","    fi['numerator'] = numerators.sum(axis=1)\n","    fi['denominator'] = denominators.sum(axis=1)\n","    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n","    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n","\n","    return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"8du9-KdlWjQQ"},"source":["#export \n","#@title Run This Cell: Create trav44\n","\n","#File: trav44.py\n","#Author: Charles Karpati\n","#Date: 1/17/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description:\n","# Uses ACS Table B08303 - TRAVEL TIME TO WORK,\n","# (Universe: Workers 16 years and over who did not work at home)\n","# Table Creates: trav14, trav29, trav44, trav45\n","#purpose: Produce Sustainability - Percent of Employed Population with Travel Time to Work of 30-44 Minutes Indicator\n","#input:\n","#output:\n","\n","import pandas as pd\n","import glob\n","def trav44( df, columnsToInclude = [] ):\n","    \n","    fi = pd.DataFrame()\n","    columns = ['B08303_008E','B08303_009E','B08303_010E','B08303_001E', 'tract']\n","    columns.extend(columnsToInclude)\n","    for col in columns:\n","        fi = addKey(df, fi, col)\n","\n","    # Numerators\n","    numerators = pd.DataFrame()\n","    columns = ['B08303_008E','B08303_009E','B08303_010E']\n","    for col in columns:\n","        numerators = addKey(df, numerators, col)\n","\n","    # Denominators\n","    denominators = pd.DataFrame()\n","    columns = ['B08303_001E']\n","    for col in columns:\n","        denominators = addKey(df, denominators, col)\n","    # construct the denominator, returns 0 iff the other two rows are equal.\n","\n","    #~~~~~~~~~~~~~~~\n","    # Step 3)\n","    # Run the Calculation\n","    # ( (value[1] + value[2] + value[3] ) / nullif(value[4],0) )*100\n","    #~~~~~~~~~~~~~~~\n","    fi['numerator'] = numerators.sum(axis=1)\n","    fi['denominator'] = denominators.sum(axis=1)\n","    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n","    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n","\n","    return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"RtTbq0xGN7g7"},"source":["#export \n","#@title Run This Cell: -unempl\n","\n","import pandas as pd\n","import glob\n","def unempr( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='003E|010E|017E|024E|031E|038E|045E|052E|059E|066E|089E|096E|103E|110E|117E|124E|131E|138E|145E|152E|008E|015E|022E|029E|036E|043E|050E|057E|064E|071E|094E|101E|108E|115E|122E|129E|136E|143E|150E|157E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","\n","  fi['final']  = ( df.filter(regex='008E|015E|022E|029E|036E|043E|050E|057E|064E|071E|094E|101E|108E|115E|122E|129E|136E|143E|150E|157E').sum(axis=1)\n",") / ( df.filter(regex='003E|010E|017E|024E|031E|038E|045E|052E|059E|066E|089E|096E|103E|110E|117E|124E|131E|138E|145E|152E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"MWjPSPFtKnZz"},"source":["#export \n","#@title Run This Cell: -unempr\n","\n","import pandas as pd\n","import glob\n","def unempr( df, columnsToInclude ):\n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='006E|013E|020E|027E|034E|041E|048E|055E|062E|069E|092E|099E|106E|113E|120E|127E|134E|141E|148E|155E|008E|015E|022E|029E|036E|043E|050E|057E|064E|071E|094E|101E|108E|115E|122E|129E|136E|143E|150E|157E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['unempr']  = ( df.filter(regex='008E|015E|022E|029E|036E|043E|050E|057E|064E|071E|094E|101E|108E|115E|122E|129E|136E|143E|150E|157E').sum(axis=1)\n",") / ( df.filter(regex='006E|013E|020E|027E|034E|041E|048E|055E|062E|069E|092E|099E|106E|113E|120E|127E|134E|141E|148E|155E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"qKo5QVlDKpCW"},"source":["#export \n","#@title Run This Cell: -walked\n","\n","import pandas as pd\n","import glob\n","def walked( df, columnsToInclude ):\n","    \n","  fi = pd.DataFrame()\n","\n","  columns = df.filter(regex='001E|049E|009E').columns.values\n","  columns = numpy.append(columns, columnsToInclude)\n","\n","  for col in columns:\n","      fi = addKey(df, fi, col)\n","      \n","  fi['walked']  = ( df.filter(regex='033E').sum(axis=1)\n",") / ( df.filter(regex='001E|049E').sum(axis=1)\n",") * 100\n","\n","  return fi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VHxedLQBWjQT"},"source":["Now that our calculations have been created, lets: \n","- create a final function that will download our data, \n","- optionally crosswalk and \n","- optionally aggregate it, and then \n","- run/return the appropriate calculation. "]},{"cell_type":"code","metadata":{"id":"bOjL2YPUW3qV"},"source":["%%capture\n","!pip install geopandas VitalSigns dataplay"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"27K0nLDL34yY"},"source":["# help(dataplay.intaker.Intake)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0W-tbffqTa6y"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"atwo3lpQsHuQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aUr7Hs0msN-5"},"source":["1 no denom\n","2 no percent\n","3 sum = false or sum or median\n","4 nullif / jail\n","null if equal"]},{"cell_type":"code","metadata":{"id":"4dqpFRkesf6e"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hCeX2tdwWjQT"},"source":["# export\n","# @ title Run This Cell: Create createIndicator()\n","import geopandas as gpd\n","import numpy as np\n","import pandas as pd\n","from VitalSigns.acsDownload import retrieve_acs_data\n","from dataplay.merge import mergeDatasets\n","from dataplay.intaker import Intake\n","def createAcsIndicator(state, county, tract, year, tableId,\n","                    mergeUrl, merge_left_col, merge_right_col, merge_how, groupBy,\n","                    aggMethod, method, columnsToInclude, finalFileName=False):\n","\n","  # Pull the data\n","  df = retrieve_acs_data(state, county, tract, tableId, year)\n","  print('Table: ' + tableId + ', Year: ' + year + ' imported.')\n","\n","  # Get the crosswalk\n","  if mergeUrl:\n","    right_ds = Intake.getData( mergeUrl )\n","    print( right_ds.columns )\n","    print('Merge file imported')\n","    # Merge crosswalk with the data\n","    df = mergeDatasets( left_ds=df, right_ds=right_ds,\n","                  left_col=merge_left_col, right_col=merge_right_col,\n","                  merge_how=merge_how, interactive=False )\n","\n","    print('Both are now merged.')\n","\n","  # Group and Aggregate\n","  if groupBy:\n","    df = df.groupby(groupBy)\n","    print('Aggregating...')\n","    if aggMethod == 'sum':\n","      df = sumInts(df)\n","    else:\n","      df = sumInts(df)\n","    print('Aggregated')\n","\n","  # Create the indicator\n","  print('Creating Indicator')\n","  resp = method( df, columnsToInclude)\n","  print('Indicator Created')\n","  if finalFileName:\n","    resp.to_csv(finalFileName, quoting=csv.QUOTE_ALL)\n","    print('Indicator Saved')\n","\n","  return resp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yKAUCASnZzze"},"source":["## Run Em"]},{"cell_type":"code","metadata":{"id":"Y1LP4ND2OY4r"},"source":["state = '24'\n","county = '510'\n","tract = '*'\n","year = '17'\n","tableId = 'B19001'\n","saveAcs = False\n","\n","mergeUrl = 'https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv'\n","merge_left_col = 'tract'\n","merge_right_col= 'TRACTCE10' \n","merge_how = 'outer'\n","\n","groupBy = 'CSA2010'\n","\n","method = mhhi\n","aggMethod = 'sum'\n","columnsToInclude = []\n","\n","\n","createAcsIndicator(state, county, tract, year, tableId, saveAcs,\n","                    mergeUrl, merge_left_col, merge_right_col, merge_how, groupBy,\n","                    aggMethod, method, columnsToInclude, finalFileName=False).head(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XiMOXDpoWjQU"},"source":["# Create the trav45 Indicator\n","tableId = 'B08303'\n","finalFileName = './trav45_20'+year+'_tracts_26July2019.csv'\n","method = trav45\n","createAcsIndicator(state, county, tract, year, tableId, saveAcs,\n","                    mergeUrl, merge_left_col, merge_right_col, merge_how, groupBy,\n","                    aggMethod, method, columnsToInclude, finalFileName=False).head(1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JTgWLnKBWjQV"},"source":["# Create the trav44 Indicator\n","tableId = 'B08303'\n","finalFileName = './trav44_20'+year+'_tracts_26July2019.csv'\n","method = trav44\n","createAcsIndicator(state, county, tract, year, tableId, saveAcs,\n","                    mergeUrl, merge_left_col, merge_right_col, merge_how, groupBy,\n","                    aggMethod, method, columnsToInclude, finalFileName=False).head(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tobWhJw_WjQV"},"source":["# Create the affordr Indicator\n","tableId = 'B25070'\n","finalFileName = './affordr_20'+year+'_tracts_26July2019.csv'\n","method = affordr\n","createAcsIndicator(state, county, tract, year, tableId, saveAcs,\n","                    mergeUrl, merge_left_col, merge_right_col, merge_how, groupBy,\n","                    aggMethod, method, columnsToInclude, finalFileName=False).head(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DdBnYy7xWjQW"},"source":["# Create the affordm Indicator. Only at the Tract Level this time\n","tableId = 'B25091'\n","finalFileName = './affordm_20'+year+'_tracts_26July2019.csv'\n","method = affordm\n","createAcsIndicator(state, county, tract, year, tableId, saveAcs,\n","                    mergeUrl, merge_left_col, merge_right_col, merge_how, groupBy,\n","                    aggMethod, method, columnsToInclude, finalFileName=False).head(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"elbeMCQvWjQW"},"source":["# Create the age5 Indicator. Only at the Tract Level this time\n","tableId = 'B01001'\n","finalFileName = './age5_20'+year+'_communities_9Sept2019.csv'\n","method = age5\n","groupBy = 'CSA2010'\n","columnsToInclude = []\n","createAcsIndicator(state, county, tract, year, tableId, saveAcs,\n","                    mergeUrl, merge_left_col, merge_right_col, merge_how, groupBy,\n","                    aggMethod, method, columnsToInclude, finalFileName=False).head(1)"],"execution_count":null,"outputs":[]}]}