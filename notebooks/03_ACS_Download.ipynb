{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"90_ACS_Download.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"5ZWkqy752CB4"},"source":["# default_exp acsDownload"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4gh2WxGW2CCA"},"source":["# Explore and Download\n","\n","> In this tutorial, the basics of Colabs are introduced and an American Community Survey (ACS) dataset is downloaded."]},{"cell_type":"markdown","metadata":{"id":"c-A_ix0Q2CCA"},"source":["This Coding Notebook is the __first__ in a series.\n","\n","An Interactive version can be found here <a href=\"https://colab.research.google.com/github/karpatic/dataplay/blob/master/notebooks/01_ACS_Explore_and_Download.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>.\n","\n","This colab and more can be found on our [webpage](https://karpatic.github.io/dataplay/). \n","\n","- Content covered in previous tutorials will be used in later tutorials. \n","\n","- __New code and or  information *should* have explanations and or descriptions__ attached. \n","\n","- Concepts or code covered in previous tutorials will be used without being explaining in entirety.\n","\n","- The [Dataplay](https://karpatic.github.io/dataplay/) Handbook development techniques covered in the [Datalabs](https://karpatic.github.io/datalabs/) Guidebook\n","\n","- __If content can not be found in the current tutorial and is not covered in previous tutorials, please let me know.__\n","\n","- This notebook has been optimized for Google Colabs ran on a Chrome Browser. \n","\n","- Statements found in the index page on view expressed, responsibility, errors and ommissions, use at risk, and licensing  extend throughout the tutorial."]},{"cell_type":"markdown","metadata":{"id":"zFByH0Hv2CCB"},"source":["[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/karpatic/datalab/master?filepath=%2Fnotebooks%2Findex.ipynb)\n","[![Binder](https://pete88b.github.io/fastpages/assets/badges/colab.svg)](https://colab.research.google.com/github/karpatic/datalab/blob/master/notebooks/index.ipynb)\n","[![Binder](https://pete88b.github.io/fastpages/assets/badges/github.svg)](https://github.com/karpatic/datalab/tree/master/notebooks/index.ipynb)\n","[![Open Source Love svg3](https://badges.frapsoft.com/os/v3/open-source.svg?v=103)](https://github.com/ellerbrock/open-source-badges/)\n","\n","[![NPM License](https://img.shields.io/npm/l/all-contributors.svg?style=flat)](https://github.com/karpatic/dataplay/blob/master/LICENSE)\n","[![Active](http://img.shields.io/badge/Status-Active-green.svg)](https://karpatic.github.io) \n","[![Python Versions](https://img.shields.io/pypi/pyversions/dataplay.svg)](https://pypi.python.org/pypi/dataplay/)\n","[![GitHub last commit](https://img.shields.io/github/last-commit/karpatic/dataplay.svg?style=flat)]() \n","[![No Maintenance Intended](http://unmaintained.tech/badge.svg)](http://unmaintained.tech/) \n","\n","[![GitHub stars](https://img.shields.io/github/stars/karpatic/dataplay.svg?style=social&label=Star)](https://github.com/karpatic/dataplay) \n","[![GitHub watchers](https://img.shields.io/github/watchers/karpatic/dataplay.svg?style=social&label=Watch)](https://github.com/karpatic/dataplay) \n","[![GitHub forks](https://img.shields.io/github/forks/karpatic/dataplay.svg?style=social&label=Fork)](https://github.com/karpatic/dataplay) \n","[![GitHub followers](https://img.shields.io/github/followers/karpatic.svg?style=social&label=Follow)](https://github.com/karpatic/dataplay) \n","\n","[![Tweet](https://img.shields.io/twitter/url/https/github.com/karpatic/dataplay.svg?style=social)](https://twitter.com/intent/tweet?text=Check%20out%20this%20%E2%9C%A8%20colab%20by%20@bniajfi%20https://github.com/karpatic/dataplay%20%F0%9F%A4%97) \n","[![Twitter Follow](https://img.shields.io/twitter/follow/bniajfi.svg?style=social)](https://twitter.com/bniajfi)"]},{"cell_type":"markdown","metadata":{"id":"Jd6lIlfO2CCB"},"source":["## About this Tutorial: "]},{"cell_type":"markdown","metadata":{"id":"l0h5if8S2CCC"},"source":["### Whats inside?"]},{"cell_type":"markdown","metadata":{"id":"RT5zCxrr2CCC"},"source":["#### __The Tutorial__\n","\n","In this notebook, the basics of Colabs are introduced.\n","\n","- We will explore ACS data catalogs to locate data we like\n","- We will programmatically download data from the American Community Survey (ACS)\n","- - Examples will use ACS table B19001, Baltimore City 2017 estimates\n","- We will rework the datasets to be human friendly"]},{"cell_type":"markdown","metadata":{"id":"mUz0vPvZ2CCC"},"source":["#### __Objectives__\n","\n","By the end of this tutorial users should have an understanding of:\n","- Google Colabs\n","- Census Data\n","- Exploring, Retrieveing, and cleaning ACS Data programmatically\n","- the 'retrieve_acs_data()' function, and how to use it in the future"]},{"cell_type":"markdown","metadata":{"id":"PttyqR4N2CCD"},"source":["# Background"]},{"cell_type":"markdown","metadata":{"id":"B_8pTXh42CCD"},"source":["## Using Colabs:\n"]},{"cell_type":"markdown","metadata":{"id":"-THwktk22CCD"},"source":["**Instructions:** Read all text and execute all code in order.  \n","\n","**How to execute code:**\n","\n","- Locate labels taking the form: '*Run: (A Short Description)*'\n","- Left of this text you will see an open bracket [ ], possibly with a number inside it.\n","- - Hovering over the brackets will reveal a play button. \n","- - Click the button to execute code.\n","- Alternately: Click on a box with code and hit 'Shift' + 'Enter' \n","\n","If you would like to see the code you are executing, double click the label 'Run: '. Code is accompanied with brief descriptions inlined. "]},{"cell_type":"markdown","metadata":{"id":"Xfmz-9uy2CCE"},"source":["__Try It!__ Go ahead and try running the cell below. What you will be shown as a result is a flow chart of how this current tutorial may be used."]},{"cell_type":"code","metadata":{"id":"qsAC4GsS2CCE"},"source":["%%html\n","<img src=\"https://bniajfi.org/images/mermaid/viewuserpath_short.PNG\">"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sbf2nE3D2CCF"},"source":["## About The Census Data"]},{"cell_type":"markdown","metadata":{"id":"l0i2BTfM2CCF"},"source":["### Census or ACS Data?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4vOfHAIk2CCG"},"source":["__Census data comes in 2 flavors:__ \n","\n","------------------------------------------------------\n","1) American Community Survey (ACS)\n","- First released to the public in 2006  \n","- Derived using 5 Year Estimates (Past 5 years of data)\n","- Delievered Annually\n","- Delievered at Tract Level. (READ -> 'Geographic Granularity')\n","- Margin of error generally prohibit a more granular view \n","- ACS Data is accessible programmatically  (READ -> 'ACS Programmatic Retrieval')(READ -> 'Geographic Reference Code')\n","\n","2) Decienial Census \n","- Estimates usings 10 years of ACS data\n","- Decenial Census data are created, in part, by ACS data.\n","- Delievered once every 10 years.\n","- Delivered at Block Level. Most Accurate\n","------------------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"bzSE8LbG2CCG"},"source":["### Geographic Granularity"]},{"cell_type":"markdown","metadata":{"id":"YPhuwQKB2CCH"},"source":["Census data can come in a variety of levels. \n","\n","These levels define the specificity of the data. \n","\n","**Ie.** Weather a data is reporting on individual communities, or entire cities is contingent on the data granularity. \n","\n","The data we will be downloading in this tutorial, ACS Data, can be found at the Tract level and no closer. \n","\n","Aggregating Tracts is the way BNIA calculates some of their yearly community indicators!"]},{"cell_type":"markdown","metadata":{"id":"n_NbjnX72CCH"},"source":["Each of the bolded words in the list below are levels that are identifiable through a 'Geographic Reference Code'. \n"," \n","For more information on Geographic Reference Codes, refer to the table of contents for the section on that matter.\n","\n","- A census block is the smallest unit of measurement used by the Census\n","- Information by census **block** is only available decenially (i.e. not ACS data)\n","- **Block groups** are the next smallest unit of measurement used by the census and are composed of aggregate census blocks\n","- Census **tracts** are composed of block groups and are the next largest unit of measurement used by the ACS\n","- **County**, **city** and census **designated places** are composed of Tracts"]},{"cell_type":"markdown","metadata":{"id":"6k7Lsg052CCH"},"source":["Run the following code to see how these different levels nest into eachother!"]},{"cell_type":"code","metadata":{"id":"eY_lykqn2CCI"},"source":["%%html\n","<img src=\"https://bniajfi.org/images/mermaid/census_granularities.PNG\">"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OBe1NlqS2CCI"},"source":["### Geographic Reference Codes"]},{"cell_type":"markdown","metadata":{"id":"x-9bIQKS2CCI"},"source":["State, County, and Tract ID's are called Geographic Reference Codes. \n","\n","This information is crucial to know when accessing data."]},{"cell_type":"markdown","metadata":{"id":"C8fhBkk72CCI"},"source":["In order to successfully pull data, Census State and County Codes must be provided.\n","\n","The code herin is configured by default to pull data on Baltimore City, MD and its constituent Tracts.\n","\n","**In order to find your State and County code:**\n","\n","------------------------------------------------------\n","Either \n","\n","A)  [Here](https://geocoding.geo.census.gov/geocoder/geographies/address): where upon entering a unique address you can locate state and county codes under the associated values 'Counties' and 'State' \n","\n","OR\n","\n","B) Conversly, click [here](https://www.census.gov/geographies/reference-files/time-series/geo/tallies.html)\n","- The Geographies mainpage contains a lot of data assets.\n","- The link to these tallies was located by accessing the geographical references subdirectory of the geographies mainpage and then filtered for publications made on the year 2010 (We are using the 2010 census boundaries)\n","- Once clicked, simply scroll down to where you find the header 'Tallies of Geographic Entities By State'\n","- Enter your state and press enter.\n","- You will be redirected to a plain text file that will contain all the information on your state and its counties. \n","------------------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"jdl63zs82CCJ"},"source":["## Working with the ACS Data"]},{"cell_type":"markdown","metadata":{"id":"HCZhBYeY2CCJ"},"source":["Searching for a dataset is the first step in the data processing pipeline. "]},{"cell_type":"markdown","metadata":{"id":"bn94qyMG2CCJ"},"source":["In this tutorial we plan on processing ACS data in a programmatic fashion. "]},{"cell_type":"markdown","metadata":{"id":"TzmcB3Vs2CCJ"},"source":["This tutorial will not just allow you to search/ explore ACS tables and inspect their contents (attributes), but also to download, format, and clean it! "]},{"cell_type":"markdown","metadata":{"id":"ErxeA7-e2CCJ"},"source":["### Search Advice"]},{"cell_type":"markdown","metadata":{"id":"3hZKU6GF2CCK"},"source":["Despite a table explorer section being provided, it is not suggested you use this approach, but rather, explore available data tables and retrieve their ID's using the dedicated websites provided below:"]},{"cell_type":"markdown","metadata":{"id":"-ld3pMez2CCK"},"source":["[American Fact Finder](https://factfinder.census.gov/faces/nav/jsf/pages/index.xhtml) may assist you in your data locating and download needs:\n","\n","Fact Finder provides a nice interface to explore available datasets. From Fact Finder you can grab a Table's ID and continue the tutorial. Alternately, from Fact Finder, You can download the data for your community directly via an interface. From there, you may continue the tutorial by loading the downloaded dataset as an external resource, instructions on how to do this are provided further below in this tutorial."]},{"cell_type":"markdown","metadata":{"id":"SaX_RKWI2CCK"},"source":["__Update : 12/18/2019__\n","\" American FactFinder (AFF) will remain as an \"archive\" system for accessing historical data until spring 2020. \" - American Fact Finder Website\n","\n","*[The New American Fact Finder](https://data.census.gov/cedsci/)* \n","\n","This new website is provided by the Census Org.  Within its 'Advanced Search' feature exist all the filtering abilities of the older, depricated, (soon discontinued) American Fact Finder Website. It is still a bit buggy to date and may not apply all filters. Filters include years(can only pick on year at a time), geography(state county tract), topic, surveys and Table ID. The filters you apply are shown at the bottom of the query and submitting the search will yield data tables ready for download as well as table ID's that you may snag for use in this tutorial."]},{"cell_type":"markdown","metadata":{"id":"b9r5f03z2CCL"},"source":["### ACS Programmatic Retrieval"]},{"cell_type":"markdown","metadata":{"id":"3DWtSgJN2CCL"},"source":["#### Developer Resources"]},{"cell_type":"markdown","metadata":{"id":"u5kCRlwA2CCL"},"source":["- Census dot gov [Developers Resource](https://www.census.gov/developers/)\n","- ACS API [Datasets](https://www.census.gov/data/developers/data-sets.html)\n","- Census ACS Developer Guide for the [5-year Datasets](https://www.census.gov/data/developers/data-sets/acs-5year.html) "]},{"cell_type":"markdown","metadata":{"id":"IpUcKf2a2CCL"},"source":["#### Notes on the Census API"]},{"cell_type":"markdown","metadata":{"id":"qV3hXp8g2CCL"},"source":["Tutorial Notes:\n","\n","- Details and Subject tables are derived using the 5 year ACS data.\n","- - As a reminder, estimates using (ACS) 5-year estimates arrive at the tract level\n","\n","- These tables are created by the census and are pre-compiled views of the data. \n","- The Detail Tables contain all possible ACS Data. \n","- The Subjects Table contains ACS data in convenient groups \n","- BNIA create their data mostly using Details table, but sometimes pulling the data from a Subject Table is more convenient (the data would otherwise be found along multiple details tables).\n","\n","ACS Website Notes:\n","\n","- Detailed Tables contain the most detailed cross-tabulations, many of which are published down to block groups. The data are population counts. There are over 20,000 variables in this dataset.\n","\n","- Subject Tables provide an overview of the estimates available in a particular topic.  The data are presented as population counts and percentages.  There are over 18,000 variables in this dataset. \n","\n","For more Information (via API) Please Visit This [Link](https://www.census.gov/data/developers/data-sets/acs-5year.html)\n"]},{"cell_type":"markdown","metadata":{"id":"uKvzlUl_2CCM"},"source":["# Guided Walkthrough"]},{"cell_type":"markdown","metadata":{"id":"0AeTQ8DX2CCM"},"source":["## SETUP"]},{"cell_type":"markdown","metadata":{"id":"uYzl2rj-2CCM"},"source":["Install these libraries onto the virtual environment.\n","\n","```\n","! pip install  -U -q ipywidgets \n","! pip install geopandas\n","```"]},{"cell_type":"code","metadata":{"id":"Az8AF2Xr2CCM"},"source":["# hide\n","# @title Run: Install Modules\n","\n","# Install the Widgets Module. \n","# Colabs does not locally provide this Python Library\n","# The '!' is a special prefix used in colabs when talking to the terminal\n","! pip install -U -q ipywidgets\n","! pip install geopandas"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4nCoTRI1VhV"},"source":["# Show entire column widths\n","pd.set_option('display.max_colwidth', -1)\n","pd.set_option('max_colwidth', 20)\n","pd.set_option('display.expand_frame_repr', False)\n","pd.set_option('display.precision', 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJL6xApk2CCN"},"source":["# @title Run: Import Modules\n","\n","# Once installed we need to..\n","\n","# import and configure the Widgets\n","import ipywidgets as widgets\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = 'all'\n","import ipywidgets as widgets\n","from ipywidgets import interact, interact_manual\n","\n","# About importing data\n","import urllib.request as urllib\n","# This Prevents Timeouts when Importing\n","import socket\n","socket.setdefaulttimeout(10.0)\n","\n","# Pandas Data Manipulation Libraries\n","import pandas as pd\n","# Working with Json Data\n","import json\n","# Data Processing\n","import numpy as np\n","# Reading Json Data into Pandas\n","from pandas.io.json import json_normalize\n","\n","\n","# Geo-Formatting\n","# Postgres-Conversion\n","import geopandas as gpd\n","from geopandas import GeoDataFrame\n","import psycopg2,pandas,numpy\n","from shapely import wkb\n","from shapely.wkt import loads\n","import os\n","import sys\n","\n","# In case file is KML\n","# enable KML support; disabled by default\n","import fiona\n","fiona.drvsupport.supported_drivers['kml'] = 'rw'\n","fiona.drvsupport.supported_drivers['KML'] = 'rw'\n","\n","# load libraries\n","# from shapely.wkt import loads\n","# from pandas import ExcelWriter\n","# from pandas import ExcelFile\n","import matplotlib.pyplot as plt\n","import glob\n","import imageio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SMhxQqd92CCN"},"source":["# hide\n","%matplotlib inline\n","!jupyter nbextension enable --py widgetsnbextension"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IXmrIhLl2CCN"},"source":["## Explore Table Directories"]},{"cell_type":"markdown","metadata":{"id":"29UgpvrP2CCN"},"source":["**Please Note:** The following section details a programmatic way to access and explore the census data catalogs. It is advised that rather than use this portion of the section of the tutorial, you read the section '*Searching For Data*' --> '*Search Advice*' above and which provide links to dedicated websites hosted by the census bureaue explicitly  for your data exploration needs!"]},{"cell_type":"markdown","metadata":{"id":"UPCNvOYR2CCO"},"source":["### Explore the Detailed Table Directory"]},{"cell_type":"markdown","metadata":{"id":"_6unAAS92CCO"},"source":["Retrieve and search available ACS datasets through the ACS's table directory. \n","\n","The table directory contains TableId's and Descriptions for each datatable the ACS provides.\n","\n","By running the next cell, an interactive searchbox will filter the directory for keywords within the description.\n","\n","Be sure to grab the TableId once you find a table with a description of interest."]},{"cell_type":"markdown","metadata":{"id":"pfDMSebJ2CCO"},"source":["```\n","response = urllib.urlopen('https://api.census.gov/data/2017/acs/acs5/groups/')\n","metaDataTable = json_normalize( json.loads(response.read())['groups'] )\n","metaDataTable.set_index('name', drop=True, inplace=True)\n","description = input(\"Search ACS Table Directory by Keyword: \")\n","metaDataTable[ metaDataTable['description'].str.contains(description.upper()) ]\n","```"]},{"cell_type":"code","metadata":{"cellView":"form","id":"lgME88nQ2CCO"},"source":["#hide\n","#@title Run: Import Dataset Directory\n","\n","pd.set_option('display.max_columns', None)\n","\n","url = 'https://api.census.gov/data/2017/acs/acs5/groups/'\n","response = urllib.urlopen(url)\n","data = json.loads(response.read())\n","data = data['groups']\n","metaDataTable = json_normalize(data)\n","metaDataTable.set_index('name', drop=True, inplace=True)\n","\n","\n","#--------------------\n","# SEARCH BOX 1: This reliably produces a searhbox. \n","# The ell must be reran for every query.\n","#--------------------\n","description = input(\"Search ACS Table Directory by Keyword: \")\n","metaDataTable[ metaDataTable['description'].str.contains(description.upper()) ]\n","\n","#--------------------\n","# SEARCH BOX 2: FOR CHROME USERS: \n","# Commenting out the code above and running the code \n","# below will update the searchbox in real time.\n","#--------------------\n","# @interact\n","# def tableExplorer(description='family'): \n","#  return metaDataTable[ metaDataTable['description'].str.contains(description.upper()) ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mNg9yRlr2CCO"},"source":["Once you a table from the explorer has been picked, you can inspect its column names in the next part. \n","\n","This will help ensure it has the data you need!"]},{"cell_type":"markdown","metadata":{"id":"VZeS0IyW2CCP"},"source":["```\n","tableId = input(\"Please enter a Table ID to inspect: \")\n","url = f'https://api.census.gov/data/2017/acs/acs5/groups/{tableId}.json'\n","metaDataTable = pd.read_json(url).reset_index(inplace = True, drop=False) \n","metaDataTable = pd.merge(\n","    json_normalize(data=metaDataTable['variables']), \n","    metaDataTable['index'] , left_index=True, right_index=True )\n","metaDataTable = metaDataTable[['index', 'concept']].dropna(subset=['concept'])\n","```"]},{"cell_type":"code","metadata":{"id":"pdj_WZPs2CCP"},"source":["#hide\n","#@title Run: Interactive Table Lookup\n","\n","import json \n","import pandas as pd \n","from pandas.io.json import json_normalize\n","\n","pd.set_option('display.max_columns', None)\n","#--------------------\n","# SEARCH BOX 1: This reliably produces a searchbox. \n","# The ell must be reran for every query.\n","#--------------------\n","tableId = input(\"Please enter a Table ID to inspect: \")\n","\n","url = f'https://api.census.gov/data/2017/acs/acs5/groups/{tableId}.json'\n","metaDataTable = pd.read_json(url)\n","\n","metaDataTable.reset_index(inplace = True, drop=False) \n","metaDataTable = pd.merge(json_normalize(data=metaDataTable['variables']), metaDataTable['index'] , left_index=True, right_index=True)\n","metaDataTable = metaDataTable[['index', 'concept']]\n","metaDataTable = metaDataTable.dropna(subset=['concept'])\n","metaDataTable.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8WYYr3Q62CCP"},"source":["### Explore the Subject Table Directory"]},{"cell_type":"markdown","metadata":{"id":"8zb6wALd2CCP"},"source":["The Data Structure we recieve is different than the prior table. \n","\n","Intake and processing is different as a result.\n","\n","Now lets explore what we got, just like before. \n","\n","Only difference is that the column names are automatically included in this query."]},{"cell_type":"markdown","metadata":{"id":"MEvov5K12CCP"},"source":["```\n","url = 'https://api.census.gov/data/2017/acs/acs5/subject/variables.json'\n","data = json.loads(urllib.urlopen(url).read())['variables']\n","objArr = []\n","for key, value in data.items():\n","  value['name'] = key\n","  objArr.append(value)\n","metaDataTable = json_normalize(objArr).set_index('name', drop=True, inplace=True)\n","metaDataTable = metaDataTable[ ['attributes', 'concept', 'group', 'label', 'limit', 'predicateType' ] ]\n","concept = input(\"Search ACS Subject Table Directory by Keyword\")\n","metaDataTable[ metaDataTable['concept'].str.contains(concept.upper(), na=False) ]\n","```"]},{"cell_type":"code","metadata":{"cellView":"form","id":"_DBrjZP42CCQ"},"source":["#hide\n","#@title Run: Interactive Dataset Directory\n","\n","\n","# Note the json representation\n","url = 'https://api.census.gov/data/2017/acs/acs5/subject/variables.json'\n","response = urllib.urlopen(url)\n","# Decode the url response as json\n","# https://docs.python.org/3/library/json.html\n","data = json.loads(response.read())\n","# the json object contains all its information within attribute 'variables' \n","data = data['variables']\n","\n","# Process  by flattening the raw json data\n","objArr = []\n","for key, value in data.items():\n","  value['name'] = key\n","  objArr.append(value)\n","\n","# Normalize semi-structured JSON data into a flat table.\n","metaDataTable = json_normalize(objArr)\n","# Set the column 'name' as an index.\n","metaDataTable.set_index('name', drop=True, inplace=True)\n","# Reduce the directory to only contain these attributes\n","metaDataTable = metaDataTable[ ['attributes', 'concept', 'group', 'label', 'limit', 'predicateType' ] ]\n","\n","\n","\n","#--------------------\n","# SEARCH BOX 1: This reliably produces a searhbox. \n","# The ell must be reran for every query.\n","#--------------------\n","concept = input(\"Search ACS Subject Table Directory by Keyword\")\n","metaDataTable[ metaDataTable['concept'].str.contains(concept.upper(), na=False) ]\n","\n","#--------------------\n","# SEARCH BOX 2: FOR CHROME USERS: \n","# Commenting out the code above and running the code \n","# below will update the searchbox in real time.\n","#--------------------\n","#@interact\n","#def subjectExplorer(concept='transport'): \n","#  return metaDataTable[ metaDataTable['concept'].str.contains(concept.upper(), na=False) ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DLa5NhDn2CCQ"},"source":["## Get Table Data"]},{"cell_type":"markdown","metadata":{"id":"aQUbTPqB2CCQ"},"source":["__Intro__\n","\n","Hopefully, by now you know which datatable you would like to download!\n","\n","The following Python function will do that for you.\n","\n","- It can be imported and used in future projects or stand alone."]},{"cell_type":"code","metadata":{"id":"-hpyKkqDuci5"},"source":["#export \n","import pandas as pd\n","from urllib.parse import urlencode\n","import csv # quoting=csv.QUOTE_ALL"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6uSBz3_k2CCQ"},"source":["#export\n","# @ title Run: Create retrieve_acs_data()\n","\n","#File: retrieveAcsData.py\n","#Author: Charles Karpati\n","#Date: 1/9/19\n","#Section: Bnia\n","#Email: karpati1@umbc.edu\n","#Description:\n","#This file returns ACS data given an ID and Year\n","# The county total is given a tract of '010000'\n","\n","#def retrieve_acs_data():\n","#purpose: Retrieves ACS data from the web\n","#input:\n","# state (required)\n","# county (required)\n","# tract (required)\n","# tableId (required)\n","# year (required)\n","# includeCountyAgg (True)(todo)\n","# replaceColumnNames (False)(todo)\n","# save (required)\n","#output:\n","# Acs Data.\n","# Prints to ../../data/2_cleaned/acs/\n","\n","def retrieve_acs_data(state, county, tract, tableId, year):\n","    dictionary = ''\n","    keys = []\n","    vals = []\n","    header = []\n","    keys1=keys2=keys3=keys4=keys5=keys6=keys7=keys8=''\n","    keyCount = 0\n","\n","    # Called in addKeys(), Will create the final URL for readIn()\n","    # These are parameters used in the API URL Query\n","    # This query will retrieve the census tracts\n","    def getParams(keys): return {\n","        'get': 'NAME'+keys,\n","        'for': 'tract:'+tract,\n","        'in': 'state:'+state+' county:'+county,\n","        'key': '829bf6f2e037372acbba32ba5731647c5127fdb0'\n","      }\n","    # Aggregate City data is best retrieved seperatly rather than as an aggregate of its constituent tracts\n","    def getCityParams(keys): return {\n","        'get': 'NAME'+keys,\n","        'for': 'county:'+county,\n","        'in': 'state:'+state,\n","        'key': '829bf6f2e037372acbba32ba5731647c5127fdb0'\n","      }\n","    # Called in AddKeys(). Requests data by url and preformats it.\n","    def readIn( url ):\n","        tbl = pd.read_json(url, orient='records')\n","        tbl.columns = tbl.iloc[0]\n","        return tbl\n","\n","    # Called by retrieveAcsData.\n","    # Creates a url and retrieve the data\n","    # Then appends the city values as tract '010000'\n","    # Finaly it merges and returns the tract and city totals.\n","    def addKeys( table, params):\n","        # Get Tract and City Records For Specific Columns\n","        table2 = readIn( base+urlencode(getParams(params)) )\n","        table3 = readIn( base+urlencode(getCityParams(params)) )\n","        table3['tract'] = '010000'\n","        # Concatenate the Records\n","        table2.append([table2, table3], sort=False)\n","        table2 = pd.concat([table2, table3], ignore_index=True)\n","        # Merge to Master Table\n","        table = pd.merge(table, table2,  how='left',\n","                         left_on=[\"NAME\",\"state\",\"county\",\"tract\"],\n","                         right_on = [\"NAME\",\"state\",\"county\",\"tract\"])\n","        return table\n","\n","    #~~~~~~~~~~~~~~~\n","    # Step 1)\n","    # Retrieve a Meta Data Table Describing the Content of the Table\n","    #~~~~~~~~~~~~~~~\n","    url = 'https://api.census.gov/data/20'+year+'/acs/acs5/groups/'+tableId+'.json'\n","    metaDataTable = pd.read_json(url, orient='records')\n","\n","    #~~~~~~~~~~~~~~~\n","    # Step 2)\n","    # Createa a Dictionary using the Meta Data Table\n","    #~~~~~~~~~~~~~~~\n","    # Multiple Queries may be Required.\n","    # Max columns returned from any given query is 50.\n","    # For that reasons bin the Columns into Groups of 50.\n","    for key in metaDataTable['variables'].keys():\n","      if key[-1:] == 'E':\n","        keyCount = keyCount + 1\n","        if keyCount < 40 : keys1 = keys1+','+key\n","        elif keyCount < 80 : keys2 = keys2+','+key\n","        elif keyCount < 120 : keys3 = keys3+','+key\n","        elif keyCount < 160 : keys4 = keys4+','+key\n","        elif keyCount < 200 : keys5 = keys5+','+key\n","        elif keyCount < 240 : keys6 = keys6+','+key\n","        elif keyCount < 280 : keys7 = keys7+','+key\n","        elif keyCount < 320 : keys8 = keys8+','+key\n","        keys.append(key)\n","        val = metaDataTable['variables'][key]['label']\n","        # Column name formatting\n","        val = key+'_'+val.replace('Estimate!!', '').replace('!!', '_').replace(' ', '_')\n","        vals.append(val)\n","    dictionary = dict(zip(keys, vals))\n","\n","    #~~~~~~~~~~~~~~~\n","    # Step 2)\n","    # Get the actual Table with the data we want using\n","    #~~~~~~~~~~~~~~~\n","\n","    # The URL we call is contingent on if the Table we want is a Detailed or Subject table\n","    url1 = 'https://api.census.gov/data/20'+year+'/acs/acs5?'\n","    url2 = 'https://api.census.gov/data/20'+year+'/acs/acs5/subject?'\n","    base = ''\n","    if tableId[:1] == 'B': base = url1\n","    if tableId[:1] == 'S': base = url2\n","\n","    # The addKey function only works after the first set of columns has been downloaded\n","    # Download First set of Tract columns\n","    url = base+urlencode(getParams(keys1) )\n","    table = pd.read_json(url, orient='records')\n","    table.columns = table.iloc[0]\n","    table = table.iloc[1:]\n","    # Download First set of Aggregate City data\n","    url = base+urlencode(getCityParams(keys1))\n","    table2 = pd.read_json(url, orient='records')\n","    table2.columns = table2.iloc[0]\n","    table2 = table2[1:]\n","    table2['tract'] = '010000'\n","\n","    # Merge EM\n","    #table = pd.concat([table, table2], keys=[\"NAME\",\"state\",\"county\",], axis=0)\n","    table.append([table, table2], sort=False)\n","    table = pd.concat([table, table2], ignore_index=True)\n","\n","    # Now we can repetedly use this function to add as many columns as there are keys listed from the meta data table\n","    if keys2 != '' : table = addKeys(table, keys2)\n","    if keys3 != '' : table = addKeys(table, keys3)\n","    if keys4 != '' : table = addKeys(table, keys4)\n","    if keys5 != '' : table = addKeys(table, keys5)\n","    if keys6 != '' : table = addKeys(table, keys6)\n","    if keys7 != '' : table = addKeys(table, keys7)\n","    if keys8 != '' : table = addKeys(table, keys8)\n","\n","    #~~~~~~~~~~~~~~~\n","    # Step 3)\n","    # Prepare Column Names using the meta data table. The raw data has columnsNames in the first row, as well.\n","    # Replace column ID's with labels from the dictionary where applicable (should be always)\n","    #~~~~~~~~~~~~~~~\n","    # print('Number of Columns', len(dictionary) )\n","\n","    header = []\n","    for column in table.columns:\n","        if column in keys: header.append(dictionary[column])\n","        else: header.append(column)\n","    table.columns = header\n","\n","    # Prettify Names. Only happens with Baltimore...\n","    table['NAME'] = table['NAME'].str.replace(', Baltimore city, Maryland', '')\n","    table['NAME'][table['NAME'] == 'Baltimore city, Maryland'] = 'Baltimore City'\n","\n","    # Convert to Integers Columns from Strings where Applicable\n","    table = table.apply(pd.to_numeric, errors='ignore')\n","\n","    # Set the 'NAME' Column as the index dropping the default increment\n","    table.set_index(\"NAME\", inplace = True)\n","    '''\n","    if save:\n","\n","      # Save the raw data as 'TABLEID_5yYEAR.csv'\n","      table.to_csv('./'+state+county+'_'+tableId+'_5y'+year+'_est_Original.csv', quoting=csv.QUOTE_ALL)\n","\n","      # Remove the id in the column names & Save the data as 'TABLEID_5yYEAR_est.csv'\n","      saveThis = table.rename( columns = lambda x : ( str(x)[:] if str(x) in [\n","        \"NAME\",\"state\",\"county\",\"tract\"] else str(x)[12:] )  )\n","      saveThis.to_csv('./'+state+county+'_'+tableId+'_5y'+year+'_est.csv', quoting=csv.QUOTE_ALL)\n","\n","    '''\n","    return table"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"To7zhAt92CCQ"},"source":["### Function Explanation"]},{"cell_type":"markdown","metadata":{"id":"CovNbxS92CCR"},"source":["**Description:** This function returns ACS data given appropriate params.\n","\n","**Purpose:** Retrieves ACS data from the web\n","\n","__Services__\n","\n","- Download an ACS dataset from an Subject (S) table\n","- Download an ACS dataset from a Details (B) table\n","\n","**Input:** \n","- state\n","- county\n","- tract\n","- tableId\n","- year\n","- saveAcs\n","\n","**Output:** \n","- Acs Data. \n","- Prints to ../../data/2_cleaned/acs/\n","\n","__How it works__\n","- Before our program retrieve the actual data, it will want the table's metadata. \n","\n","- - This metadata will be used as a crosswalk to replace the awkward column names\n","\n","- - If this is not done, only a column ID would denote each column. not human readable.\n","\n","- The Function changes the URL it requests data from depending on if it is an S or B type table the user has requested \n","\n","- Multiple calls for data must be made as a single table may have several hundred columns in them.\n","\n","- - Constructing a table requires merging the data from multiple responces \n","\n","- Our program not just pulls tract level data but the aggregate for the county.\n","\n","- - County totals are included automatically as 'tract 010000'. \n","\n","- - - The County total is not the sum of all other tracts but a seperate, indendent and unique query.\n","\n","- - Tract and County Datatables must be merged to form a single dataset \n","\n","- Finally, we will download the data in two different formats if desired.\n","\n","- If we choose to save the data, we save it with the Table IDs + ColumnNames, and once without the TableIDs."]},{"cell_type":"markdown","metadata":{"id":"ZO0oVAqC2CCR"},"source":["### Function Diagrams"]},{"cell_type":"code","metadata":{"id":"J5bDdOFR2CCR"},"source":["#@title Run: Class Diagram retrieve_acs_data()\n","\n","%%html\n","<img src=\"https://bniajfi.org/images/mermaid/class_diagram_retrieve_acs_data.PNG\">"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NTr_ACbC2CCR"},"source":["#@title Run: retrieve_acs_data Flow Chart\n","\n","%%html\n","<img src=\"https://bniajfi.org/images/mermaid/flow_chart_retrieve_acs_data.PNG\">"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NdIcwjCc2CCR"},"source":["#@title Run: Gannt Chart  retrieve_acs_data()\n","\n","%%html\n","<img src=\"https://bniajfi.org/images/mermaid/gannt_chart_retrieve_acs_data.PNG\">"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-z47zu92CCS"},"source":["#@title Run: Sequence Diagram  retrieve_acs_data()\n","\n","%%html\n","<img src=\"https://bniajfi.org/images/mermaid/sequence_diagram_retrieve_acs_data.PNG\">"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nvsL_kVN2CCS"},"source":["### Function Examples"]},{"cell_type":"markdown","metadata":{"id":"q5dQ8we_2CCS"},"source":["Now use this function to Download the Data!"]},{"cell_type":"code","metadata":{"id":"_VoXQS9I2CCS"},"source":["# Our download function will use Baltimore City's tract, county and state as internal paramters\n","# Change these values in the cell below using different geographic reference codes will change those parameters\n","tract = '*'\n","county = '153' # '059' # 153 '510'\n","state = '51'\n","\n","# Specify the download parameters the function will receieve here\n","tableId = 'B19049' # 'B19001'\n","year = '17'\n","saveAcs = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YfDUeXP-2CCS"},"source":["# state, county, tract, tableId, year, saveOriginal, save\n","\n","df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pXbzor1x2CCT"},"source":[""],"execution_count":null,"outputs":[]}]}