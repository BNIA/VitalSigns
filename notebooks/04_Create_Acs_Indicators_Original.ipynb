{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMo4IRjn0UBN"
   },
   "outputs": [],
   "source": [
    "# default_exp indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMOGyuQ-nzjQ"
   },
   "source": [
    "# Original ACS Python Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgUHDXELz4jP"
   },
   "source": [
    "These were origially SQL Scripts. We moved them over to python. Now we are trying to make these scripts even better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCnXf8GxqsOV"
   },
   "source": [
    "## racdiv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULTwgxO2ox8d"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: racdiv.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B02001 - Race\n",
    "# Universe: Total Population\n",
    "# Uses ACS Table B03002 - HISPANIC OR LATINO ORIGIN BY RACE\n",
    "# Universe: Total Population\n",
    "# Table Creates: racdiv, paa, pwhite, pasi, phisp, p2more, ppac\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def racdiv( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B02001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B03002*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df_hisp = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    df_hisp = df_hisp.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "    df_hisp = df_hisp.sum(numeric_only=True)\n",
    "\n",
    "    # Append the one column from the other ACS Table\n",
    "    df['B03002_012E_Total_Hispanic_or_Latino'] = df_hisp['B03002_012E_Total_Hispanic_or_Latino']\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    df1['African-American%'] = df[ 'B02001_003E_Total_Black_or_African_American_alone' ] / df[ 'B02001_001E_Total' ] * 100\n",
    "    df1['White%'] = df[ 'B02001_002E_Total_White_alone' ] / df[ 'B02001_001E_Total' ] * 100\n",
    "    df1['American Indian%'] = df[ 'B02001_004E_Total_American_Indian_and_Alaska_Native_alone' ]/ df[ 'B02001_001E_Total' ] * 100\n",
    "    df1['Asian%'] = df[ 'B02001_005E_Total_Asian_alone' ] / df[ 'B02001_001E_Total' ] * 100\n",
    "    df1['Native Hawaii/Pac Islander%'] = df[ 'B02001_006E_Total_Native_Hawaiian_and_Other_Pacific_Islander_alone'] / df[ 'B02001_001E_Total' ] * 100\n",
    "    df1['Hisp %'] = df['B03002_012E_Total_Hispanic_or_Latino'] / df[ 'B02001_001E_Total' ] * 100\n",
    "    # =1-(POWER(%AA/100,2)+POWER(%White/100,2)+POWER(%AmerInd/100,2)+POWER(%Asian/100,2) + POWER(%NativeAm/100,2))*(POWER(%Hispanci/100,2) + POWER(1-(%Hispanic/100),2))\n",
    "    df1['Diversity_index'] = ( 1- (\n",
    "        ( df1['African-American%'] /100 )**2\n",
    "        +( df1['White%'] /100 )**2\n",
    "        +( df1['American Indian%'] /100 )**2\n",
    "        +( df1['Asian%'] /100 )**2\n",
    "        +( df1['Native Hawaii/Pac Islander%'] /100 )**2\n",
    "    )*(\n",
    "        ( df1['Hisp %'] /100 )**2\n",
    "        +(1-( df1['Hisp %'] /100) )**2\n",
    "    ) ) * 100\n",
    "\n",
    "    return df1['Diversity_index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYZVn_Raq1_6"
   },
   "source": [
    "## pasi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPZy939Eos29"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: pasi.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B03002 - HISPANIC OR LATINO ORIGIN BY RACE\n",
    "# Universe: Total Population\n",
    "# Table Creates: racdiv, paa, pwhite, pasi, phisp, p2more, ppac\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def pasi( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B03002*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # Append the one column from the other ACS Table\n",
    "    df['B03002_012E_Total_Hispanic_or_Latino']\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    tot = df[ 'B03002_001E_Total' ]\n",
    "    df1['Asian%NH'] = df[ 'B03002_006E_Total_Not_Hispanic_or_Latino_Asian_alone' ]/ tot * 100\n",
    "\n",
    "    return df1['Asian%NH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbMqU45ttDsw"
   },
   "source": [
    "## Undone -> Yet to be Transcribed From SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_z25Zxr1Aev9"
   },
   "source": [
    "??? 199 Number of Trees Planted treeplntXX TreeBaltimore "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1U8LjwRdxri"
   },
   "source": [
    "### 49 nomail - R\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hr3fgWBxkipW"
   },
   "source": [
    "NO INFORMATION LOCATED. \n",
    "\n",
    "This comes already aggregated and so it may be quicker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PBNoXyvhY2F"
   },
   "source": [
    "### 129 artevnt - G\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8I-LGZgIjxWl"
   },
   "source": [
    "****events_2017_csa indicator number 130****\n",
    "SELECT bAll.csa AS Bound, sum(bQuery.events_2017)*(1000/bAll.the_pop)as events_2017\n",
    "  FROM boundaries.csa2010 bAll\n",
    "    LEFT JOIN (\n",
    "      SELECT bounds.csa AS Boundary, (count(Tables.gid ::numeric(20,4))::numeric(20,2)) AS events_2017\n",
    "        FROM arts.events_2017 AS Tables\n",
    "          JOIN boundaries.csa2010 AS bounds\n",
    "            ON st_contains(bounds.the_geom, Tables.the_geom)\n",
    "              GROUP BY bounds.csa\n",
    "                ORDER BY bounds.csa\n",
    "    ) bQuery\n",
    "      ON bAll.csa = bQuery.Boundary\n",
    "        GROUP BY Bound, the_pop\n",
    "          ORDER BY Bound;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmBSC_ekhZAA"
   },
   "source": [
    "### 168 weather - R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0YWNvBOjwr9"
   },
   "source": [
    "Waiting on Weatherization Data\n",
    "Normalization Source -> MD Property View. Aquired\n",
    "\n",
    "with tbl AS (\n",
    " select (count(job_number)::real)*(1000/the_pop::real) as result, csa\n",
    "  from vital_signs.match_csas_and_bc_by_geom('sustainability.weatherization_2017', 'gid', 'the_geom') a\n",
    "  left join sustainability.weatherization_2017 b on a.gid = b.gid\n",
    "  \n",
    "    group by csa,the_pop\n",
    " )\n",
    " update vital_signs.data\n",
    " set weather = result from tbl where data.csa = tbl.csa and data_year = '2017';\n",
    "\n",
    "  with numerator AS (\n",
    "   select (count(\n",
    "   case \n",
    "   when csa_present\n",
    "   then 1\n",
    "   else NULL\n",
    "   end)::numeric) as result, csa\n",
    "   from vital_signs.match_csas_and_bc_by_geom('sustainability.weatherization_2017', 'gid', 'the_geom') a\n",
    "   left join sustainability.weatherization_2017 b on a.gid = b.gid\n",
    "   group by csa\n",
    "   ),\n",
    "   denominator AS (\n",
    "    select (sum(\n",
    "     case \n",
    "     when (address != $$NULL$$) AND (desclu = $$Apartments$$ OR desclu = $$Residential$$ OR desclu = $$Residential Commercial$$ OR desclu = $$Residential Condominium$$)\n",
    "     then 1\n",
    "     else NULL\n",
    "     end)::numeric \n",
    "    ) as result, csa\n",
    "    from vital_signs.match_csas_and_bc_by_geom('housing.mdprop_2017v2', 'gid', 'the_geom') a\n",
    "    left join housing.mdprop_2017v2 b on a.gid = b.gid\n",
    "    group by csa, the_pop\n",
    "   ),\n",
    "   tbl AS (\n",
    "     select denominator.csa,(numerator.result / denominator.result)*(100::numeric) as result \n",
    "     from numerator left join denominator on numerator.csa = denominator.csa\n",
    "     )\n",
    "select * from tbl where 1 = 1 ORDER BY csa ASC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_0VllC8rmyg"
   },
   "source": [
    "## elheat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXsV-RBcoL7E"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: elheat.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B25040 - HOUSE HEATING FUEL\n",
    "# Universe - Occupied housing units\n",
    "# Table Creates: elheat, heatgas\n",
    "#purpose: Produce Sustainability - Percent of Residences Heated by Electricity Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def elheat( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B25040*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B25040_004E','B25040_001E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B25040_004E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B25040_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation + final mods\n",
    "    # ( value[1] / nullif(value[2],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <elheat_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( value[1] / nullif(value[2],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B25040_004E','B25040_001E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset elheat = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ACCKmW0rlQX"
   },
   "source": [
    "## empl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8czcSdxoNsk"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: empl.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B23001 - SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULATION 16 YEARS AND OVER\n",
    "# Universe - Population 16 years and over\n",
    "# Table Creates: empl, unempl, unempr, nilf\n",
    "#purpose: Produce Workforce and Economic Development - Percent Population 16-64 Employed Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def empl( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B23001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B23001_003E', 'B23001_010E', 'B23001_017E', 'B23001_024E', 'B23001_031E', 'B23001_038E', 'B23001_045E', 'B23001_052E', 'B23001_059E', 'B23001_066E', 'B23001_089E', 'B23001_096E', 'B23001_103E', 'B23001_110E', 'B23001_117E', 'B23001_124E', 'B23001_131E', 'B23001_138E', 'B23001_145E', 'B23001_152E', 'B23001_007E', 'B23001_014E', 'B23001_021E', 'B23001_028E', 'B23001_035E', 'B23001_042E', 'B23001_049E', 'B23001_056E', 'B23001_063E', 'B23001_070E', 'B23001_093E', 'B23001_100E', 'B23001_107E', 'B23001_114E', 'B23001_121E', 'B23001_128E', 'B23001_135E', 'B23001_142E', 'B23001_149E', 'B23001_156E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B23001_007E', 'B23001_014E', 'B23001_021E', 'B23001_028E', 'B23001_035E', 'B23001_042E', 'B23001_049E', 'B23001_056E', 'B23001_063E', 'B23001_070E', 'B23001_093E', 'B23001_100E', 'B23001_107E', 'B23001_114E', 'B23001_121E', 'B23001_128E', 'B23001_135E', 'B23001_142E', 'B23001_149E', 'B23001_156E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B23001_003E', 'B23001_010E', 'B23001_017E', 'B23001_024E', 'B23001_031E', 'B23001_038E', 'B23001_045E', 'B23001_052E', 'B23001_059E', 'B23001_066E', 'B23001_089E', 'B23001_096E', 'B23001_103E', 'B23001_110E', 'B23001_117E', 'B23001_124E', 'B23001_131E', 'B23001_138E', 'B23001_145E', 'B23001_152E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "#  (value[21]+value[22]+value[23]+value[24]+value[25]+value[26]+value[27]+value[28]+value[29]+value[30]+value[31]+value[32]+value[33]+value[34]+value[35]+value[36]+value[37]+value[38]+value[39]+value[40]) --civil labor force empl 16-64\n",
    "#/\n",
    "#nullif( (value[1]+value[2]+value[3]+value[4]+value[5]+value[6]+value[7]+value[8]+value[9]+value[10]+value[11]+value[12]+value[13]+value[14]+value[15]+value[16]+value[17]+value[18]+value[19]+value[20]) -- population 16 to 64    ,0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <empl_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "( ( value[21]+value[22]+value[23]+value[24]+value[25]+value[26]+value[27]+value[28]+value[29]+value[30]+value[31]+value[32]+value[33]+value[34]+value[35]+value[36]+value[37]+value[38]+value[39]+value[40]) --civil labor force empl 16-64     / nullif( (value[1]+value[2]+value[3]+value[4]+value[5]+value[6]+value[7]+value[8]+value[9]+value[10]+value[11]+value[12]+value[13]+value[14]+value[15]+value[16]+value[17]+value[18]+value[19]+value[20]) -- population 16 to 64    ,0) )*100::numeric\n",
    "\t\t\tas result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY[ 'B23001_003E','B23001_010E','B23001_017E','B23001_024E','B23001_031E','B23001_038E','B23001_045E','B23001_052E','B23001_059E','B23001_066E','B23001_089E','B23001_096E','B23001_103E','B23001_110E','B23001_117E','B23001_124E','B23001_131E','B23001_138E','B23001_145E','B23001_152E','B23001_007E','B23001_014E','B23001_021E','B23001_028E','B23001_035E','B23001_042E','B23001_049E','B23001_056E','B23001_063E','B23001_070E','B23001_093E','B23001_100E','B23001_107E','B23001_114E','B23001_121E','B23001_128E','B23001_135E','B23001_142E','B23001_149E','B23001_156E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset empl = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijV2TDdUrjlY"
   },
   "source": [
    "## fam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FegOoJjloPw0"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: fam.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B11005 - HOUSEHOLDS BY PRESENCE OF PEOPLE UNDER 18 YEARS BY HOUSEHOLD TYPE\n",
    "# Universe: Households\n",
    "# Table Creates: hhs, fam, femhhs\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def fam( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B11005*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    # DIFFERENCES IN TABLE NAMES EXIST BETWEEN 16 and 17. 17 has no comma.\n",
    "    rootStr = 'B11005_007E_Total_Households_with_one_or_more_people_under_18_years_Family_households_Other_family_Female_householder'\n",
    "    str16 = rootStr + ',_no_husband_present'\n",
    "    str17 = rootStr + '_no_husband_present'\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "    # Delete Unassigned--Jail\n",
    "    df = df[df.index != 'Unassigned--Jail']\n",
    "\n",
    "    # Move Baltimore to Bottom\n",
    "    bc = df.loc[ 'Baltimore City' ]\n",
    "    df = df.drop( df.index[1] )\n",
    "    df.loc[ 'Baltimore City' ] = bc\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    # Actually produce the data\n",
    "    df1['total'] = df[ 'B11005_001E_Total' ]\n",
    "    df1['18Under'] = df[ 'B11005_002E_Total_Households_with_one_or_more_people_under_18_years' ] / df1['total'] * 100\n",
    "    return df1['18Under']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5gTVyiCrhsV"
   },
   "source": [
    "## female.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HgSEhP9oRgm"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: female.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B01001 - SEX BY AGE\n",
    "# Universe: Total population\n",
    "# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def female( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B01001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # df.columns\n",
    "    total = df['B01001_001E_Total']\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    df1['onlyTheLadies']  = df[ 'B01001_026E_Total_Female' ]\n",
    "\n",
    "    return df1['onlyTheLadies']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOZGVS2Trf16"
   },
   "source": [
    "## femhhs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwT-s8RxoTbl"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: femhhs.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B11005 - HOUSEHOLDS BY PRESENCE OF PEOPLE UNDER 18 YEARS BY HOUSEHOLD TYPE\n",
    "# Universe: Households\n",
    "# Table Creates: male, hhs, fam, femhhs\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def femhhs( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B11005*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    # DIFFERENCES IN TABLE NAMES EXIST BETWEEN 16 and 17. 17 has no comma.\n",
    "    rootStr = 'B11005_007E_Total_Households_with_one_or_more_people_under_18_years_Family_households_Other_family_Female_householder'\n",
    "    str16 = rootStr + ',_no_husband_present'\n",
    "    str17 = rootStr + '_no_husband_present'\n",
    "    str19 = rootStr + ',_no_spouse_present'\n",
    "    femhh = str17 if year == '17' else str19 if year == '19' else str16\n",
    "\n",
    "    # Actually produce the data\n",
    "    df1['total'] = df[ 'B11005_001E_Total' ]\n",
    "    df1['18Under'] = df[ 'B11005_002E_Total_Households_with_one_or_more_people_under_18_years' ] / df1['total'] * 100\n",
    "    df1['FemaleHH'] = df[ femhh ] / df['B11005_002E_Total_Households_with_one_or_more_people_under_18_years'] * 100\n",
    "    df1['FamHHChildrenUnder18'] = df['B11005_003E_Total_Households_with_one_or_more_people_under_18_years_Family_households']\n",
    "    df1['FamHHChildrenOver18'] = df['B11005_012E_Total_Households_with_no_people_under_18_years_Family_households']\n",
    "    df1['FamHH'] = df1['FamHHChildrenOver18'] + df1['FamHHChildrenUnder18']\n",
    "\n",
    "    return df1['FemaleHH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1J2m25WreEF"
   },
   "source": [
    "## heatgas.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5k8mNtyoWR9"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: heatgas.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B25040 - HOUSE HEATING FUEL\n",
    "# Universe - Occupied housing units\n",
    "# Table Creates: elheat, heatgas\n",
    "#purpose: Produce Sustainability - Percent of Residences Heated by Electricity Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def heatgas( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B25040*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B25040_002E','B25040_001E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B25040_002E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B25040_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    # ( value[1] / nullif(value[2],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <heatgas_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( value[1] / nullif(value[2],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B25040_002E','B25040_001E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset heatgas = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-i4PH3I3sCzp"
   },
   "source": [
    "## hh40inc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RC_zBBBYoZnA"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: hh40inc.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B19001 - HOUSEHOLD INCOME V\n",
    "# HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2017 INFLATION-ADJUSTED DOLLARS)\n",
    "# Table Creates: hh25 hh40 hh60 hh75 hhm75, mhhi\n",
    "#purpose: Produce Household Income 25K-40K Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def hh40inc( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B19001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # val1.__class__.__name__\n",
    "    #\n",
    "\n",
    "    # create a new dataframe for giggles\n",
    "    fi = pd.DataFrame()\n",
    "\n",
    "    # append into that dataframe col 001\n",
    "    key = getColName(df, '001')\n",
    "    val = getColByName(df, '001')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 006\n",
    "    key = getColName(df, '006')\n",
    "    val = getColByName(df, '006')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 007\n",
    "    key = getColName(df, '007')\n",
    "    val = getColByName(df, '007')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 008\n",
    "    key = getColName(df, '008')\n",
    "    val = getColByName(df, '008')\n",
    "    fi[key] = val\n",
    "\n",
    "    # Delete Rows where the 'denominator' column is 0 -> like the Jail\n",
    "    fi = fi[fi[fi.columns[0]] != 0]\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    return fi.apply(lambda x: ( ( x[fi.columns[1] ]+ x[fi.columns[2] ]+ x[fi.columns[3] ] ) / x[fi.columns[0]])*100, axis=1)\n",
    "\n",
    "\"\"\"\n",
    "/* hh40inc */ --\n",
    "WITH tbl AS (\n",
    "\tselect csa,\n",
    "\t( (value[1] + value[2] + value[3])  / value[4] )*100 as result\n",
    "\tfrom vital_signs.get_acs_vars_csa_and_bc('2013',ARRAY['B19001_006E','B19001_007E','B19001_008E','B19001_001E'])\n",
    "\t)\n",
    "\tUPDATE vital_signs.data\n",
    "\tset hh40inc = result from tbl where data.csa = tbl.csa and data_year = '2013';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxgEFDeOrZ_l"
   },
   "source": [
    "## hh60inc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hAzA0mBobOp"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: hh60inc.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B19001 - HOUSEHOLD INCOME V\n",
    "# HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2017 INFLATION-ADJUSTED DOLLARS)\n",
    "# Table Creates: hh25 hh40 hh60 hh75 hhm75, mhhi\n",
    "#purpose: Produce Household 45-60K Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def hh60inc( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B19001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # val1.__class__.__name__\n",
    "    #\n",
    "\n",
    "    # create a new dataframe for giggles\n",
    "    fi = pd.DataFrame()\n",
    "\n",
    "    # append into that dataframe col 001\n",
    "    key = getColName(df, '001')\n",
    "    val = getColByName(df, '001')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 009\n",
    "    key = getColName(df, '009')\n",
    "    val = getColByName(df, '009')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 010\n",
    "    key = getColName(df, '010')\n",
    "    val = getColByName(df, '010')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 011\n",
    "    key = getColName(df, '011')\n",
    "    val = getColByName(df, '011')\n",
    "    fi[key] = val\n",
    "\n",
    "    # Delete Rows where the 'denominator' column is 0 -> like the Jail\n",
    "    fi = fi[fi[fi.columns[0]] != 0]\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    return fi.apply(lambda x: ( ( x[fi.columns[1] ]+ x[fi.columns[2] ]+ x[fi.columns[3] ] ) / x[fi.columns[0]])*100, axis=1)\n",
    "\n",
    "\"\"\"\n",
    "/* hh60inc */ --\n",
    "WITH tbl AS (\n",
    "\tselect csa,\n",
    "\t( (value[1] + value[2] + value[3])  / value[4] )*100 as result\n",
    "\tfrom vital_signs.get_acs_vars_csa_and_bc('2013',ARRAY['B19001_009E','B19001_010E','B19001_011E','B19001_001E'])\n",
    "\t)\n",
    "\tUPDATE vital_signs.data\n",
    "\tset hh60inc = result from tbl where data.csa = tbl.csa and data_year = '2013';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gL3uRpPXrXgb"
   },
   "source": [
    "## hh75inc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gX0-MIl0ocRE"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: hh75inc.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B19001 - HOUSEHOLD INCOME V\n",
    "# HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2017 INFLATION-ADJUSTED DOLLARS)\n",
    "# Table Creates: hh25 hh40 hh60 hh75 hhm75, mhhi\n",
    "#purpose: Produce Household Income 60-70K Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def hh75inc( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B19001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # val1.__class__.__name__\n",
    "    #\n",
    "\n",
    "    # create a new dataframe for giggles\n",
    "    fi = pd.DataFrame()\n",
    "\n",
    "    # append into that dataframe col 001\n",
    "    key = getColName(df, '001')\n",
    "    val = getColByName(df, '001')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 012\n",
    "    key = getColName(df, '012')\n",
    "    val = getColByName(df, '012')\n",
    "    fi[key] = val\n",
    "\n",
    "    # Delete Rows where the 'denominator' column is 0 -> like the Jail\n",
    "    fi = fi[fi[fi.columns[0]] != 0]\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    #12/1\n",
    "    return fi.apply(lambda x: ( x[fi.columns[1] ] / x[fi.columns[0]])*100, axis=1)\n",
    "\n",
    "\"\"\"\n",
    "/* hh75inc */ --\n",
    "WITH tbl AS (\n",
    "\tselect csa,\n",
    "\t( value[1]  / value[2] )*100 as result\n",
    "\tfrom vital_signs.get_acs_vars_csa_and_bc('2013',ARRAY['B19001_012E','B19001_001E'])\n",
    "\t)\n",
    "\tUPDATE vital_signs.data\n",
    "\tset hh75inc = result from tbl where data.csa = tbl.csa and data_year = '2013';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VllBOTcRrVnL"
   },
   "source": [
    "## hhchpov.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0L_n3fqModRp"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: hhchpov.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B17001 - POVERTY STATUS IN THE PAST 12 MONTHS BY SEX BY AGE\n",
    "# Universe: Population for whom poverty status is determined  more information\n",
    "#purpose: Produce Household Poverty Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def hhchpov( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B17001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B17001_004E', 'B17001_005E', 'B17001_006E', 'B17001_007E', 'B17001_008E', 'B17001_009E', 'B17001_018E', 'B17001_019E', 'B17001_020E', 'B17001_021E', 'B17001_022E', 'B17001_023E', 'B17001_033E', 'B17001_034E', 'B17001_035E', 'B17001_036E', 'B17001_037E', 'B17001_038E', 'B17001_047E', 'B17001_048E', 'B17001_049E', 'B17001_050E', 'B17001_051E', 'B17001_052E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B17001_004E', 'B17001_005E', 'B17001_006E', 'B17001_007E', 'B17001_008E', 'B17001_009E', 'B17001_018E', 'B17001_019E', 'B17001_020E', 'B17001_021E', 'B17001_022E', 'B17001_023E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B17001_004E', 'B17001_005E', 'B17001_006E', 'B17001_007E', 'B17001_008E', 'B17001_009E', 'B17001_018E', 'B17001_019E', 'B17001_020E', 'B17001_021E', 'B17001_022E', 'B17001_023E', 'B17001_033E', 'B17001_034E', 'B17001_035E', 'B17001_036E', 'B17001_037E', 'B17001_038E', 'B17001_047E', 'B17001_048E', 'B17001_049E', 'B17001_050E', 'B17001_051E', 'B17001_052E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] #Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 4)\n",
    "    # Add Special Baltimore City Data\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    url = 'https://api.census.gov/data/20'+str(year)+'/acs/acs5/subject?get=NAME,S1701_C03_002E&for=county%3A510&in=state%3A24&key=829bf6f2e037372acbba32ba5731647c5127fdb0'\n",
    "    table = pd.read_json(url, orient='records')\n",
    "    fi['final']['Baltimore City'] = float(table.loc[1, table.columns[1]])\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <hhchpov_14> */\n",
    "\t\t\tWITH tbl AS (\n",
    "\t\t\t\tselect csa,\n",
    "\t\t\t\t( (value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8] + value[9] + value[10] + value[11] + value[12])\n",
    "\t\t\t\t/ nullif(\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8] + value[9] + value[10] + value[11] + value[12] + value[13] + value[14] + value[15] + value[16] + value[17] + value[18] + value[19] + value[20] + value[21] + value[22] + value[23] + value[24] ),\n",
    "\t\t\t\t\t0)\n",
    "\t\t\t\t) * 100::numeric as result\n",
    "\t\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B17001_004E','B17001_005E','B17001_006E','B17001_007E','B17001_008E','B17001_009E','B17001_018E','B17001_019E','B17001_020E','B17001_021E','B17001_022E','B17001_023E','B17001_033E','B17001_034E','B17001_035E','B17001_036E','B17001_037E','B17001_038E','B17001_047E','B17001_048E','B17001_049E','B17001_050E','B17001_051E','B17001_052E'])\n",
    "\t\t\t\t)\n",
    "\t\t\t\tupdate vital_signs.data\n",
    "\t\t\t\tset hhchpov = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__sPm-C0rSUe"
   },
   "source": [
    "## hhm75.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URLpIliYoeec"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: hhm75.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B19001 - HOUSEHOLD INCOME V\n",
    "# HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2017 INFLATION-ADJUSTED DOLLARS)\n",
    "# Table Creates: hh25 hh40 hh60 hh75 hhm75, mhhi\n",
    "#purpose: Produce Household Income Over 75K Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def hhm75( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B19001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # val1.__class__.__name__\n",
    "    #\n",
    "\n",
    "    # create a new dataframe for giggles\n",
    "    fi = pd.DataFrame()\n",
    "\n",
    "    # append into that dataframe col 001\n",
    "    key = getColName(df, '001')\n",
    "    val = getColByName(df, '001')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 002\n",
    "    key = getColName(df, '002')\n",
    "    val = getColByName(df, '002')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 003\n",
    "    key = getColName(df, '003')\n",
    "    val = getColByName(df, '003')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 004\n",
    "    key = getColName(df, '004')\n",
    "    val = getColByName(df, '004')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 005\n",
    "    key = getColName(df, '005')\n",
    "    val = getColByName(df, '005')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 006\n",
    "    key = getColName(df, '006')\n",
    "    val = getColByName(df, '006')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 007\n",
    "    key = getColName(df, '007')\n",
    "    val = getColByName(df, '007')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 008\n",
    "    key = getColName(df, '008')\n",
    "    val = getColByName(df, '008')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 009\n",
    "    key = getColName(df, '009')\n",
    "    val = getColByName(df, '009')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 010\n",
    "    key = getColName(df, '010')\n",
    "    val = getColByName(df, '010')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 011\n",
    "    key = getColName(df, '011')\n",
    "    val = getColByName(df, '011')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 012\n",
    "    key = getColName(df, '012')\n",
    "    val = getColByName(df, '012')\n",
    "    fi[key] = val\n",
    "\n",
    "    # Delete Rows where the 'denominator' column is 0 -> like the Jail\n",
    "    fi = fi[fi[fi.columns[0]] != 0]\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    return fi.apply(lambda x: ( ( x[fi.columns[0]]-( x[fi.columns[1] ]+ x[fi.columns[2] ]+ x[fi.columns[3] ]+ x[fi.columns[4] ]+ x[fi.columns[5] ]+ x[fi.columns[6] ]+ x[fi.columns[7] ]+ x[fi.columns[8] ]+ x[fi.columns[9] ]+ x[fi.columns[10] ]+ x[fi.columns[11] ] ) ) / x[fi.columns[0]])*100, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCudz3T1rQb2"
   },
   "source": [
    "## hhpov.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owbBifRwofci"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: hhpov.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B17017 - Household Poverty, Uses Table B17017 which includes V\n",
    "# Poverty Status in the Past 12 Months by Household Type by Age of Householder (Universe = households)\n",
    "#purpose: Produce Household Poverty Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def hhpov( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B17017*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # create a new dataframe for giggles\n",
    "    fi = pd.DataFrame()\n",
    "\n",
    "    # append into that dataframe col 003\n",
    "    key = getColName(df, '003')\n",
    "    val = getColByName(df, '003')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 032\n",
    "    key = getColName(df, '032')\n",
    "    val = getColByName(df, '032')\n",
    "    fi[key] = val\n",
    "\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "    fi['denominator'] = nullIfEqual( df, '003',  '032')\n",
    "\n",
    "    # Delete Rows where the 'denominator' column is 0\n",
    "    fi = fi[fi['denominator'] != 0]\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    return fi.apply(lambda x: (x[fi.columns[0]] / x['denominator'])*100, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kduYoYRDrPAY"
   },
   "source": [
    "## hhs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHakNgE6ogcy"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: hhs.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B11005 - HOUSEHOLDS BY PRESENCE OF PEOPLE UNDER 18 YEARS BY HOUSEHOLD TYPE\n",
    "# Universe: Households\n",
    "# Table Creates: hhs, fam, femhhs\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def hhs( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B11005*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    df1['tot'] = df[ 'B11005_001E_Total' ]\n",
    "\n",
    "    return df1['tot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVZh_56DrNdF"
   },
   "source": [
    "## hsdipl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEh8TUumohkU"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: hsdipl.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B06009 - PLACE OF BIRTH BY EDUCATIONAL ATTAINMENT IN THE UNITED STATES\n",
    "#purpose: Produce Workforce and Economic Development - Percent Population (25 Years and over) With High School Diploma and Some College or Associates Degree\n",
    "#Table Uses: B06009 - lesshs, hsdipl, bahigher\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def hsdipl( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B06009*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B06009_003E','B06009_004E','B06009_001E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B06009_003E','B06009_004E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B06009_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation + final mods\n",
    "    # ( ( value[1] + value[2] ) / nullif(value[3],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <hsdipl_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( ( value[1] + value[2] ) / nullif(value[3],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B06009_003E','B06009_004E','B06009_001E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset hsdipl = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCirZkI0rL02"
   },
   "source": [
    "## lesshs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pO4iqDCVoie8"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: lesshs.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B06009 - PLACE OF BIRTH BY EDUCATIONAL ATTAINMENT IN THE UNITED STATES\n",
    "#purpose: Produce Workforce and Economic Development - Percent Population (25 Years and over) With Less Than a High School Diploma or GED Indicator\n",
    "#Table Uses: B06009 - lesshs, hsdipl, bahigher\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def lesshs( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B06009*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B06009_002E','B06009_001E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B06009_002E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B06009_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation + final mods\n",
    "    # (  value[1] / nullif(value[2],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <lesshs_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t(  value[1] / nullif(value[2],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B06009_002E','B06009_001E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset lesshs = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hHHrGp7rJuP"
   },
   "source": [
    "## male.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bB1-cnhfoju5"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: male.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B01001 - SEX BY AGE\n",
    "# Universe: Total population\n",
    "# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def male( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B01001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # df.columns\n",
    "    total = df['B01001_001E_Total']\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    df1['onlyTheFellas'] = df[ 'B01001_002E_Total_Male' ]\n",
    "\n",
    "    return df1['onlyTheFellas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dO2Cq_lrDU2"
   },
   "source": [
    "## nilf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bj2km05-ol1N"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: nilf.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B23001 - SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULATION 16 YEARS AND OVER\n",
    "# Universe - Population 16 years and over\n",
    "# Table Creates: empl, unempl, unempr, nilf\n",
    "#purpose: Produce Workforce and Economic Development - Percent Population 16-64 Not in Labor Force Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def nilf( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B23001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B23001_003E', 'B23001_010E', 'B23001_017E', 'B23001_024E', 'B23001_031E', 'B23001_038E', 'B23001_045E', 'B23001_052E', 'B23001_059E', 'B23001_066E', 'B23001_089E', 'B23001_096E', 'B23001_103E', 'B23001_110E', 'B23001_117E', 'B23001_124E', 'B23001_131E', 'B23001_138E', 'B23001_145E', 'B23001_152E', 'B23001_009E', 'B23001_016E', 'B23001_023E', 'B23001_030E', 'B23001_037E', 'B23001_044E', 'B23001_051E', 'B23001_058E', 'B23001_065E', 'B23001_072E', 'B23001_095E', 'B23001_102E', 'B23001_109E', 'B23001_116E', 'B23001_123E', 'B23001_130E', 'B23001_137E', 'B23001_144E', 'B23001_151E', 'B23001_158E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B23001_009E', 'B23001_016E', 'B23001_023E', 'B23001_030E', 'B23001_037E', 'B23001_044E', 'B23001_051E', 'B23001_058E', 'B23001_065E', 'B23001_072E', 'B23001_095E', 'B23001_102E', 'B23001_109E', 'B23001_116E', 'B23001_123E', 'B23001_130E', 'B23001_137E', 'B23001_144E', 'B23001_151E', 'B23001_158E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B23001_003E', 'B23001_010E', 'B23001_017E', 'B23001_024E', 'B23001_031E', 'B23001_038E', 'B23001_045E', 'B23001_052E', 'B23001_059E', 'B23001_066E', 'B23001_089E', 'B23001_096E', 'B23001_103E', 'B23001_110E', 'B23001_117E', 'B23001_124E', 'B23001_131E', 'B23001_138E', 'B23001_145E', 'B23001_152E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    # ( ( value[21]+value[22]+value[23]+value[24]+value[25]+value[26]+value[27]+value[28]+value[29]+value[30]+value[31]+value[32]+value[33]+value[34]+value[35]+value[36]+value[37]+value[38]+value[39]+value[40]) --not in labor force 16-64\n",
    "# /\n",
    "# nullif( (value[1]+value[2]+value[3]+value[4]+value[5]+value[6]+value[7]+value[8]+value[9]+value[10]+value[11]+value[12]+value[13]+value[14]+value[15]+value[16]+value[17]+value[18]+value[19]+value[20]) -- population 16 to 64      ,0) )*100::numeric\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <nilf_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( (value[21]+value[22]+value[23]+value[24]+value[25]+value[26]+value[27]+value[28]+value[29]+value[30]+value[31]+value[32]+value[33]+value[34]+value[35]+value[36]+value[37]+value[38]+value[39]+value[40]) --not in labor force 16-64        / nullif( (value[1]+value[2]+value[3]+value[4]+value[5]+value[6]+value[7]+value[8]+value[9]+value[10]+value[11]+value[12]+value[13]+value[14]+value[15]+value[16]+value[17]+value[18]+value[19]+value[20]) -- population 16 to 64      ,0) )*100::numeric\n",
    "\t\t\tas result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014', ARRAY['B23001_003E','B23001_010E','B23001_017E','B23001_024E','B23001_031E','B23001_038E','B23001_045E','B23001_052E','B23001_059E','B23001_066E','B23001_089E','B23001_096E','B23001_103E','B23001_110E','B23001_117E','B23001_124E','B23001_131E','B23001_138E','B23001_145E','B23001_152E','B23001_009E','B23001_016E','B23001_023E','B23001_030E','B23001_037E','B23001_044E','B23001_051E','B23001_058E','B23001_065E','B23001_072E','B23001_095E','B23001_102E','B23001_109E','B23001_116E','B23001_123E','B23001_130E','B23001_137E','B23001_144E','B23001_151E','B23001_158E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset nilf = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6W7qN7vQq--p"
   },
   "source": [
    "## othrcom.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aG71TgsRopcl"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: othrcom.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/24/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B08101 - MEANS OF TRANSPORTATION TO WORK BY AGE\n",
    "# Universe: Workers 16 years and over\n",
    "# Table Creates: othrcom, drvalone, carpool, pubtran, walked\n",
    "#purpose: Produce Sustainability - Percent of Population Using Other Means to Commute to Work (Taxi, Motorcycle, Bicycle, Other) Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def othrcom( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B08101*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B08101_001E','B08101_049E','B08101_041E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B08101_041E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B08101_001E','B08101_049E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "# ( value[3] / nullif((value[1]-value[2]),0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.iloc[: ,0] - denominators.iloc[: ,1]\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 4)\n",
    "    # Add Special Baltimore City Data\n",
    "    # 100- \"6.7\",    \"59.8\",    \"9.2\",    \"18.4\",   \"3.7\",            = 2.2\n",
    "    # 100- (walked + drvalone + carpool + pubtran + workfromhome(13e))\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    url = 'https://api.census.gov/data/20'+str(year)+'/acs/acs5/subject?get=NAME,S0801_C01_010E,S0801_C01_003E,S0801_C01_004E,S0801_C01_009E,S0801_C01_013E&for=county%3A510&in=state%3A24&key=829bf6f2e037372acbba32ba5731647c5127fdb0'\n",
    "    table = pd.read_json(url, orient='records')\n",
    "    walked = float(table.loc[1, table.columns[1]] )\n",
    "    drvalone = float(table.loc[1, table.columns[2]] )\n",
    "    carpool = float(table.loc[1, table.columns[3]] )\n",
    "    pubtran = float(table.loc[1, table.columns[4]] )\n",
    "    workfromhome =   float(table.loc[1, table.columns[5]] )\n",
    "    fi['final']['Baltimore City'] = 100 - ( walked + drvalone + carpool + pubtran + workfromhome )\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <othrcom_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( value[3] / nullif((value[1]-value[2]),0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B08101_001E','B08101_049E','B08101_041E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset othrcom = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hr-YQhhHq54R"
   },
   "source": [
    "## p2more.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3d9MkrRBoqhm"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: p2more.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B03002 - HISPANIC OR LATINO ORIGIN BY RACE\n",
    "# Universe: Total Population\n",
    "# Table Creates: racdiv, paa, pwhite, pasi, phisp, p2more, ppac\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def p2more( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B03002*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # Append the one column from the other ACS Table\n",
    "    df['B03002_012E_Total_Hispanic_or_Latino']\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    tot = df[ 'B03002_001E_Total' ]\n",
    "    df1['TwoOrMore%NH'] = df['B03002_009E_Total_Not_Hispanic_or_Latino_Two_or_more_races'] / tot * 100\n",
    "\n",
    "    return df1['TwoOrMore%NH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xETwOF84qvem"
   },
   "source": [
    "## pubtran.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovPX9DHZov9Y"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: pubtran.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B08101 - MEANS OF TRANSPORTATION TO WORK BY AGE\n",
    "# Universe: Workers 16 Years and Over\n",
    "# Table Creates: othrcom, drvalone, carpool, pubtran, walked\n",
    "#purpose: Produce Sustainability - Percent of Population that Uses Public Transportation to Get to Work Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def pubtran( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B08101*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B08101_001E','B08101_049E','B08101_025E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B08101_025E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B08101_001E','B08101_049E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    # ( value[3] / nullif((value[1]-value[2]),0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.iloc[: ,0] - denominators.iloc[: ,1]\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 4)\n",
    "    # Add Special Baltimore City Data\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    url = 'https://api.census.gov/data/20'+str(year)+'/acs/acs5/subject?get=NAME,S0801_C01_009E&for=county%3A510&in=state%3A24&key=829bf6f2e037372acbba32ba5731647c5127fdb0'\n",
    "    table = pd.read_json(url, orient='records')\n",
    "    fi['final']['Baltimore City'] = float(table.loc[1, table.columns[1]])\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\"\"\"\t\t/* <pubtran_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( value[3] / nullif((value[1]-value[2]),0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B08101_001E','B08101_049E','B08101_025E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset pubtran = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmrdZYjY8ATH"
   },
   "source": [
    "# Updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1w0jabMJr4jY"
   },
   "source": [
    "## age5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvKoOq7un9bG"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: age5.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B01001 - SEX BY AGE\n",
    "# Universe: Total population\n",
    "# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def age5( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B01001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # df.columns\n",
    "    total = df['B01001_001E_Total']\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    # Under 5\n",
    "    df1['under_5']  = ( df[ 'B01001_003E_Total_Male_Under_5_years' ]\n",
    "               + df[ 'B01001_027E_Total_Female_Under_5_years' ]\n",
    "    ) / total * 100\n",
    "\n",
    "    return df1['under_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mcGyo99r1Cm"
   },
   "source": [
    "## age24.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3Umvqp5oBhH"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: age24.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B01001 - SEX BY AGE\n",
    "# Universe: Total population\n",
    "# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def age24( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B01001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # df.columns\n",
    "    total = df['B01001_001E_Total']\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    df1['eighteen_to_24']  = ( df[ 'B01001_007E_Total_Male_18_and_19_years' ]\n",
    "         + df[ 'B01001_008E_Total_Male_20_years' ]\n",
    "         + df[ 'B01001_009E_Total_Male_21_years' ]\n",
    "         + df[ 'B01001_010E_Total_Male_22_to_24_years' ]\n",
    "     + df[ 'B01001_031E_Total_Female_18_and_19_years' ]\n",
    "         + df[ 'B01001_032E_Total_Female_20_years' ]\n",
    "         + df[ 'B01001_033E_Total_Female_21_years' ]\n",
    "         + df[ 'B01001_034E_Total_Female_22_to_24_years' ]\n",
    "    ) / total * 100\n",
    "\n",
    "    return df1['eighteen_to_24']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS4rCbmurzV-"
   },
   "source": [
    "## age64.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuwHiaBkoDEm"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: age64.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B01001 - SEX BY AGE\n",
    "# Universe: Total population\n",
    "# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def age64( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B01001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # df.columns\n",
    "    total = df['B01001_001E_Total']\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    df1['twentyfive_to_64']  = ( df[ 'B01001_011E_Total_Male_25_to_29_years' ]\n",
    "         + df[ 'B01001_012E_Total_Male_30_to_34_years' ]\n",
    "         + df[ 'B01001_013E_Total_Male_35_to_39_years' ]\n",
    "         + df[ 'B01001_014E_Total_Male_40_to_44_years' ]\n",
    "         + df[ 'B01001_015E_Total_Male_45_to_49_years' ]\n",
    "         + df[ 'B01001_016E_Total_Male_50_to_54_years' ]\n",
    "         + df[ 'B01001_017E_Total_Male_55_to_59_years' ]\n",
    "         + df[ 'B01001_018E_Total_Male_60_and_61_years' ]\n",
    "         + df[ 'B01001_019E_Total_Male_62_to_64_years' ]\n",
    "     + df[ 'B01001_035E_Total_Female_25_to_29_years' ]\n",
    "         + df[ 'B01001_036E_Total_Female_30_to_34_years' ]\n",
    "         + df[ 'B01001_037E_Total_Female_35_to_39_years' ]\n",
    "         + df[ 'B01001_038E_Total_Female_40_to_44_years' ]\n",
    "         + df[ 'B01001_039E_Total_Female_45_to_49_years' ]\n",
    "         + df[ 'B01001_040E_Total_Female_50_to_54_years' ]\n",
    "         + df[ 'B01001_041E_Total_Female_55_to_59_years' ]\n",
    "         + df[ 'B01001_042E_Total_Female_60_and_61_years' ]\n",
    "         + df[ 'B01001_043E_Total_Female_62_to_64_years' ]\n",
    "    ) / total * 100\n",
    "\n",
    "    return df1['twentyfive_to_64']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tz9kdsgdr28-"
   },
   "source": [
    "## age18.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-uMJdPsn_mm"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: age18.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B01001 - SEX BY AGE\n",
    "# Universe: Total population\n",
    "# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def age18( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B01001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # df.columns\n",
    "    total = df['B01001_001E_Total']\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    df1['five_to_17']  = ( df[ 'B01001_004E_Total_Male_5_to_9_years'  ]\n",
    "         + df[ 'B01001_005E_Total_Male_10_to_14_years'  ]\n",
    "         + df[ 'B01001_006E_Total_Male_15_to_17_years' ]\n",
    "     + df[ 'B01001_028E_Total_Female_5_to_9_years' ]\n",
    "         + df[ 'B01001_029E_Total_Female_10_to_14_years' ]\n",
    "         + df[ 'B01001_030E_Total_Female_15_to_17_years' ]\n",
    "    ) / total * 100\n",
    "\n",
    "    return df1['five_to_17']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHOnpkVQrwHw"
   },
   "source": [
    "## age65.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nzj4TwkyoE3u"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: age65.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B01001 - SEX BY AGE\n",
    "# Universe: Total population\n",
    "# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def age65( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B01001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # df.columns\n",
    "    total = df['B01001_001E_Total']\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    df1['sixtyfive_and_up']  = ( df[ 'B01001_020E_Total_Male_65_and_66_years' ]\n",
    "         + df[ 'B01001_021E_Total_Male_67_to_69_years' ]\n",
    "         + df[ 'B01001_022E_Total_Male_70_to_74_years' ]\n",
    "         + df[ 'B01001_023E_Total_Male_75_to_79_years' ]\n",
    "         + df[ 'B01001_024E_Total_Male_80_to_84_years' ]\n",
    "         + df[ 'B01001_025E_Total_Male_85_years_and_over' ]\n",
    "     + df[ 'B01001_044E_Total_Female_65_and_66_years' ]\n",
    "         + df[ 'B01001_045E_Total_Female_67_to_69_years' ]\n",
    "         + df[ 'B01001_046E_Total_Female_70_to_74_years' ]\n",
    "         + df[ 'B01001_047E_Total_Female_75_to_79_years' ]\n",
    "         + df[ 'B01001_048E_Total_Female_80_to_84_years' ]\n",
    "         + df[ 'B01001_049E_Total_Female_85_years_and_over' ]\n",
    "    ) / total * 100\n",
    "    return df1['sixtyfive_and_up']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pq1fKimjp-sm"
   },
   "source": [
    "## afform.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iDG0XhBn1DV"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: affordm.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/25/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B25091 - MORTGAGE STATUS BY SELECTED MONTHLY OWNER COSTS AS A PERCENTAGE OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS\n",
    "# Universe: Owner-occupied housing units\n",
    "# Table Creates:\n",
    "#purpose: Produce Housing and Community Development - Affordability Index - Mortgage Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def affordm( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B25091*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B25091_008E','B25091_009E','B25091_010E','B25091_011E','B25091_002E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B25091_008E','B25091_009E','B25091_010E','B25091_011E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B25091_002E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    # ( (value[1]+value[2]+value[3]+value[4]) / nullif(value[5],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( (value[1]+value[2]+value[3]+value[4]) / nullif(value[5],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B25091_008E','B25091_009E','B25091_010E','B25091_011E','B25091_002E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset affordm = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BTgIyACr6aO"
   },
   "source": [
    "## affordr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikQPxUbEn7d2"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: affordr.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B25070 - GROSS RENT AS A PERCENTAGE OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS\n",
    "# Universe: Renter-occupied housing units\n",
    "#purpose: Produce Housing and Community Development - Affordability Index - Rent Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def affordr( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B25070*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B25070_007E','B25070_008E','B25070_009E','B25070_010E','B25070_001E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B25070_007E','B25070_008E','B25070_009E','B25070_010E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B25070_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    # ( (value[1]+value[2]+value[3]+value[4]) / nullif(value[5],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( (value[1]+value[2]+value[3]+value[4]) / nullif(value[5],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B25070_007E','B25070_008E','B25070_009E','B25070_010E','B25070_001E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset affordr = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM-Dx3Qxrt2d"
   },
   "source": [
    "## bahigher.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYl4boNQoGiM"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: bahigher.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B06009 - PLACE OF BIRTH BY EDUCATIONAL ATTAINMENT IN THE UNITED STATES\n",
    "#purpose: Produce Workforce and Economic Development - Percent Population (25 Years and over) with a Bachelor's Degree or Above\n",
    "#Table Uses: B06009 - lesshs, hsdipl, bahigher\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def bahigher( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B06009*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B06009_005E','B06009_006E','B06009_001E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B06009_005E','B06009_006E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B06009_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation + final mods\n",
    "    # ( ( value[1] + value[2] ) / nullif(value[3],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <hsdipl_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( ( value[1] + value[2] ) / nullif(value[3],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B06009_003E','B06009_004E','B06009_001E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset hsdipl = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\n",
    "B06009_004E\t\n",
    "label\t\"Estimate!!Total!!Some college or associate's degree\"\n",
    "\n",
    "B06009_003E\t\n",
    "label\t\"Estimate!!Total!!High school graduate (includes equivalency)\"\n",
    "\n",
    "B06009_002E\t\n",
    "label\t\"Estimate!!Total!!Less than high school graduate\"\n",
    "\n",
    "B06009_001E\t\n",
    "label\t\"Estimate!!Total\"\n",
    "\n",
    "B06009_005E\t\n",
    "label\t\"Estimate!!Total!!Bachelor's degree\"\n",
    "\n",
    "B06009_006E\t\n",
    "label\t\"Estimate!!Total!!Graduate or professional degree\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHnWLEVsrsSO"
   },
   "source": [
    "## carpool.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Up8ie4uhoIKF"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: carpool.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B08101 - MEANS OF TRANSPORTATION TO WORK BY AGE\n",
    "# Universe: Workers 16 Years and Over\n",
    "# Table Creates: othrcom, drvalone, carpool, pubtran, walked\n",
    "#purpose: Produce Sustainability - Percent of Population that Carpool to Work Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def carpool( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B08101*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B08101_001E','B08101_049E','B08101_017E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B08101_017E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B08101_001E','B08101_049E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation + final mods\n",
    "    # ( value[3] / (value[1]-value[2]) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.iloc[: ,0] - denominators.iloc[: ,1]\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 4)\n",
    "    # Add Special Baltimore City Data\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    url = 'https://api.census.gov/data/20'+str(year)+'/acs/acs5/subject?get=NAME,S0801_C01_004E&for=county%3A510&in=state%3A24&key=829bf6f2e037372acbba32ba5731647c5127fdb0'\n",
    "    table = pd.read_json(url, orient='records')\n",
    "    fi['final']['Baltimore City'] = float(table.loc[1, table.columns[1]])\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\"\"\"\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( value[3] / nullif( (value[1]-value[2]) ,0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2013',ARRAY['B08101_001E','B08101_049E','B08101_017E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset carpool = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2013';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAoqzYFurqtO"
   },
   "source": [
    "## drvalone.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JizqRgqcoKDt"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: drvalone.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B08101 - MEANS OF TRANSPORTATION TO WORK BY AGE\n",
    "# Universe: Workers 16 Years and Over\n",
    "# Table Creates: othrcom, drvalone, carpool, pubtran, walked\n",
    "#purpose: Produce Sustainability - Percent of Population that Drove Alone to Work Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def drvalone( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B08101*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B08101_001E','B08101_049E','B08101_009E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B08101_009E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B08101_001E','B08101_049E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    # ( value[3] / nullif((value[1]-value[2]),0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.iloc[: ,0] - denominators.iloc[: ,1]\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 4)\n",
    "    # Add Special Baltimore City Data\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    url = 'https://api.census.gov/data/20'+str(year)+'/acs/acs5/subject?get=NAME,S0801_C01_003E&for=county%3A510&in=state%3A24&key=829bf6f2e037372acbba32ba5731647c5127fdb0'\n",
    "    table = pd.read_json(url, orient='records')\n",
    "    fi['final']['Baltimore City'] = float(table.loc[1, table.columns[1]])\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <drvalone_13> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( value[3] / nullif((value[1]-value[2]),0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2013',ARRAY['B08101_001E','B08101_049E','B08101_009E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset drvalone = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2013';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsydjQkjrcHD"
   },
   "source": [
    "## hh25inc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-XL_xkvoX-d"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: hh25inc.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B19001 - HOUSEHOLD INCOME V\n",
    "# HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2017 INFLATION-ADJUSTED DOLLARS)\n",
    "# Table Creates: hh25 hh40 hh60 hh75 hhm75, mhhi\n",
    "#purpose: Produce Household Income Under 25K Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def hh25inc( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B19001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # val1.__class__.__name__\n",
    "    #\n",
    "\n",
    "    # create a new dataframe for giggles\n",
    "    fi = pd.DataFrame()\n",
    "\n",
    "    # append into that dataframe col 001\n",
    "    key = getColName(df, '001')\n",
    "    val = getColByName(df, '001')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 002\n",
    "    key = getColName(df, '002')\n",
    "    val = getColByName(df, '002')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 003\n",
    "    key = getColName(df, '003')\n",
    "    val = getColByName(df, '003')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 004\n",
    "    key = getColName(df, '004')\n",
    "    val = getColByName(df, '004')\n",
    "    fi[key] = val\n",
    "\n",
    "    # append into that dataframe col 005\n",
    "    key = getColName(df, '005')\n",
    "    val = getColByName(df, '005')\n",
    "    fi[key] = val\n",
    "\n",
    "    # Delete Rows where the 'denominator' column is 0 -> like the Jail\n",
    "    fi = fi[fi[fi.columns[0]] != 0]\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    return fi.apply(lambda x: ( ( x[fi.columns[1] ]+ x[fi.columns[2] ]+ x[fi.columns[3] ]+ x[fi.columns[4] ] ) / x[fi.columns[0]])*100, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGo1F2PdrH8N"
   },
   "source": [
    "##  mhhi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAnIDu2Uoks1"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: mhhi.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/24/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B19001 - HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2016 INFLATION-ADJUSTED DOLLARS)\n",
    "# Universe: Households\n",
    "# Table Creates: hh25 hh40 hh60 hh75 hhm75, mhhi\n",
    "#purpose: Produce Sustainability - Percent of Population that Walks to Work Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def mhhi( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B19001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    info = pd.DataFrame(\n",
    "        [\n",
    "            ['B19001_002E', 0, 10000],\n",
    "            ['B19001_003E', 10000, 4999 ],\n",
    "            ['B19001_004E', 15000, 4999 ],\n",
    "            ['B19001_005E', 20000, 4999 ],\n",
    "            ['B19001_006E', 25000, 4999 ],\n",
    "            ['B19001_007E', 30000, 4999],\n",
    "            ['B19001_008E', 35000, 4999 ],\n",
    "            ['B19001_009E', 40000, 4999 ],\n",
    "            ['B19001_010E', 45000, 4999 ],\n",
    "            ['B19001_011E', 50000, 9999 ],\n",
    "            ['B19001_012E', 60000, 14999],\n",
    "            ['B19001_013E', 75000, 24999 ],\n",
    "            ['B19001_014E', 100000, 24999 ],\n",
    "            ['B19001_015E', 125000, 24999 ],\n",
    "            ['B19001_016E', 150000, 49000 ],\n",
    "            ['B19001_017E', 200000, 1000000000000000000000000 ],\n",
    "\n",
    "        ],\n",
    "        columns=['variable', 'lower', 'range']\n",
    "    )\n",
    "\n",
    "    # Final Dataframe\n",
    "    data_table = pd.DataFrame()\n",
    "    for index, row in info.iterrows():\n",
    "        #print(row['variable'], row['lower'], row['range'])\n",
    "        data_table = addKey(df, data_table, row['variable'])\n",
    "\n",
    "    # create a table of the accumulating total accross the columns from left to right for each csa.\n",
    "    temp_table = data_table.cumsum(axis=1)\n",
    "\n",
    "    # get the csa midpoint by divide column index 16 (the last column) of the cumulative totals\n",
    "    temp_table['midpoint'] = (temp_table.iloc[ : , -1 :] /2) # V3\n",
    "    temp_table['midpoint_index'] = False\n",
    "    temp_table['midpoint_index_value'] = False # Z3\n",
    "    temp_table['midpoint_index_lower'] = False # W3\n",
    "    temp_table['midpoint_index_range'] = False # X3\n",
    "    temp_table['midpoint_index_minus_one_cumulative_sum'] = False #Y3\n",
    "\n",
    "    # step 3 - csa_agg3: get the midpoint index by \"when midpoint > agg[1] and midpoint <= agg[2] then 2\"\n",
    "\n",
    "    # Get CSA Midpoint Index using the breakpoints in our info table.\n",
    "    # For each CSA\n",
    "    for index, row in temp_table.iterrows():\n",
    "        # Get the index of the first column where our midpoint is greater than the columns value.\n",
    "        # Do not use the temp columns (we just created)\n",
    "        midpoint = row['midpoint']\n",
    "        midpoint_index = 0\n",
    "        for column in row.iloc[:-6]:\n",
    "            # set midpoint index to the column with the highest value possible that is under midpoint\n",
    "            if( midpoint >= int(column) ):\n",
    "                # print (str(column) + ' - ' + str(midpoint))\n",
    "                temp_table.loc[ index, 'midpoint_index' ] = midpoint_index +1\n",
    "            midpoint_index += 1\n",
    "\n",
    "    temp_table = temp_table.drop('Unassigned--Jail')\n",
    "    for index, row in temp_table.iterrows():\n",
    "        temp_table.loc[ index, 'midpoint_index_value' ] = data_table.loc[ index, data_table.columns[row['midpoint_index']] ]\n",
    "        temp_table.loc[ index, 'midpoint_index_lower' ] = info.loc[ row['midpoint_index'] ]['lower']\n",
    "        temp_table.loc[ index, 'midpoint_index_range' ] = info.loc[ row['midpoint_index'] ]['range']\n",
    "        temp_table.loc[ index, 'midpoint_index_minus_one_cumulative_sum'] = row[ row['midpoint_index']-1 ]\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    # Calculation = (midpoint_lower::numeric + (midpoint_range::numeric * ( (midpoint - midpoint_upto_agg) / nullif(midpoint_total,0)\n",
    "    # Calculation = W3+X3*((V3-Y3)/Z3)\n",
    "\n",
    "    # v3 -> 1 - midpoint of households  == sum / 2\n",
    "    # w3 -> 2 - lower limit of the income range containing the midpoint of the housing total == row[lower]\n",
    "    # x3 -> width of the interval containing the medium == row[range]\n",
    "    # z3 -> number of hhs within the interval containing the median == row[total]\n",
    "    # y3 -> 4 - cumulative frequency up to, but no==NOT including the median interval\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    temp_table['final'] = temp_table['midpoint_index_lower']+temp_table['midpoint_index_range']*((temp_table['midpoint']-temp_table['midpoint_index_minus_one_cumulative_sum'])/temp_table['midpoint_index_value'])\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 4)\n",
    "    # Add Special Baltimore City Data\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    url = 'https://api.census.gov/data/20'+str(year)+'/acs/acs5/subject?get=NAME,S1901_C01_012E&for=county%3A510&in=state%3A24&key=829bf6f2e037372acbba32ba5731647c5127fdb0'\n",
    "    table = pd.read_json(url, orient='records')\n",
    "    temp_table['final']['Baltimore City'] = float(table.loc[1, table.columns[1]])\n",
    "\n",
    "    return temp_table['final']\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <mmhhi_14> */ --\n",
    "\t\twith tbl_csa as (\n",
    "\t\t\t\tselect a.*,b.count from vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B19001_002E','B19001_003E','B19001_004E','B19001_005E','B19001_006E','B19001_007E','B19001_008E','B19001_009E','B19001_010E','B19001_011E','B19001_012E','B19001_013E','B19001_014E','B19001_015E','B19001_016E','B19001_017E','B19013_001E'])\n",
    "\t\t\t\ta left join (select csa,count(*) as count from vital_signs.tracts group by csa) b\n",
    "\t\t\t\ton a.csa = b.csa\n",
    "\t\t\t\t),\n",
    "\t\t\t\tinfo as (\n",
    "\t\t\t\t\tselect 'B19001_002E' as variable, 0 as lower, 10000 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_003E' as variable, 10000 as lower, 4999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_004E' as variable, 15000 as lower, 4999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_005E' as variable, 20000 as lower, 4999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_006E' as variable, 25000 as lower, 4999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_007E' as variable, 30000 as lower, 4999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_008E' as variable, 35000 as lower, 4999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_009E' as variable, 40000 as lower, 4999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_010E' as variable, 45000 as lower, 4999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_011E' as variable, 50000 as lower, 9999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_012E' as variable, 60000 as lower, 14999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_013E' as variable, 75000 as lower, 24999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_014E' as variable, 100000 as lower, 24999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_015E' as variable, 125000 as lower, 24999 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_016E' as variable, 150000 as lower, 49000 as range\n",
    "\t\t\t\t\tunion all\tselect 'B19001_017E' as variable, 200000 as lower, null as range\n",
    "\t\t\t\t),\n",
    "\t\t\t\tcsa_agg as (\n",
    "\t\t\t\t\tselect csa,value as total,count,\n",
    "\t\t\t\t\tARRAY[\n",
    "\t\t\t\t\t(value[1]),\n",
    "\t\t\t\t\t(value[1] + value[2]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5] + value[6]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8] + value[9]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8] + value[9] + value[10]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8] + value[9] + value[10] + value[11]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8] + value[9] + value[10] + value[11] + value[12]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8] + value[9] + value[10] + value[11] + value[12] + value[13]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8] + value[9] + value[10] + value[11] + value[12] + value[13] + value[14]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8] + value[9] + value[10] + value[11] + value[12] + value[13] + value[14] + value[15]),\n",
    "\t\t\t\t\t(value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8] + value[9] + value[10] + value[11] + value[12] + value[13] + value[14] + value[15] + value[16])\n",
    "\t\t\t\t\t] as agg,\n",
    "\t\t\t\t\tvalue[17] as median,\n",
    "\t\t\t\t\tvariable from tbl_csa\n",
    "\t\t\t\t),\n",
    "\t\t\t\tcsa_agg2 as (\n",
    "\t\t\t\t\tselect csa,count,median,total,agg,variable,\n",
    "\t\t\t\t\tagg[16]/2::numeric as midpoint from csa_agg\n",
    "\t\t\t\t),\n",
    "\t\t\t\tcsa_agg3 as (\n",
    "\t\t\t\t\tselect csa,count,median,total,agg,variable,midpoint,\n",
    "\t\t\t\t\t(case\n",
    "\t\t\t\t\twhen midpoint <= agg[1] then 1\n",
    "\t\t\t\t\twhen midpoint > agg[1] and midpoint <= agg[2] then 2\n",
    "\t\t\t\t\twhen midpoint > agg[2] and midpoint <= agg[3] then 3\n",
    "\t\t\t\t\twhen midpoint > agg[3] and midpoint <= agg[4] then 4\n",
    "\t\t\t\t\twhen midpoint > agg[4] and midpoint <= agg[5] then 5\n",
    "\t\t\t\t\twhen midpoint > agg[5] and midpoint <= agg[6] then 6\n",
    "\t\t\t\t\twhen midpoint > agg[6] and midpoint <= agg[7] then 7\n",
    "\t\t\t\t\twhen midpoint > agg[7] and midpoint <= agg[8] then 8\n",
    "\t\t\t\t\twhen midpoint > agg[8] and midpoint <= agg[9] then 9\n",
    "\t\t\t\t\twhen midpoint > agg[9] and midpoint <= agg[10] then 10\n",
    "\t\t\t\t\twhen midpoint > agg[10] and midpoint <= agg[11] then 11\n",
    "\t\t\t\t\twhen midpoint > agg[11] and midpoint <= agg[12] then 12\n",
    "\t\t\t\t\twhen midpoint > agg[12] and midpoint <= agg[13] then 13\n",
    "\t\t\t\t\twhen midpoint > agg[13] and midpoint <= agg[14] then 14\n",
    "\t\t\t\t\twhen midpoint > agg[14] and midpoint <= agg[15] then 15\n",
    "\t\t\t\t\twhen midpoint > agg[15] and midpoint <= agg[16] then 16\n",
    "\t\t\t\t\twhen midpoint > agg[16] then 17\n",
    "\t\t\t\t\tend) as midpoint_idx from csa_agg2\n",
    "\t\t\t\t),\n",
    "\t\t\t\tcsa_agg4 as (\n",
    "\t\t\t\t\tselect csa,count,median,total,agg,variable,midpoint,midpoint_idx,\n",
    "\t\t\t\t\ttotal[midpoint_idx] as midpoint_total,\n",
    "\t\t\t\t\t(case\n",
    "\t\t\t\t\twhen (midpoint_idx - 1) = 0 then 0\n",
    "\t\t\t\t\telse total[(midpoint_idx - 1)]\n",
    "\t\t\t\t\tend) as midpoint_upto_total,\n",
    "\t\t\t\t\tagg[midpoint_idx] as midpoint_agg, (case when (midpoint_idx - 1) = 0 then 0 else agg[(midpoint_idx - 1)] end) as midpoint_upto_agg,\n",
    "\t\t\t\t\tvariable[midpoint_idx] as midpoint_variable\n",
    "\t\t\t\t\tfrom csa_agg3\n",
    "\t\t\t\t),\n",
    "\t\t\t\tcsa_agg5 as (\n",
    "\t\t\t\t\tselect a.*,b.lower as midpoint_lower, b.range as midpoint_range from\n",
    "\t\t\t\t\tcsa_agg4 a left join info b on a.midpoint_variable = b.variable\n",
    "\t\t\t\t),\n",
    "\t\t\t\ttbl as (\n",
    "\t\t\t\t\tselect (CASE\n",
    "\t\t\t\t\t\twhen count = 1 OR csa = 'Baltimore City'\n",
    "\t\t\t\t\t\tthen median\n",
    "\t\t\t\t\t\telse\n",
    "\t\t\t\t\t\t(midpoint_lower::numeric +\n",
    "\t\t\t\t\t\t\t(midpoint_range::numeric * (\n",
    "\t\t\t\t\t\t\t\t\t (midpoint - midpoint_upto_agg) / nullif(midpoint_total,0)\n",
    "\t\t\t\t\t\t\t\t\t)\n",
    "\t\t\t\t\t\t\t)\n",
    "\t\t\t\t\t\t)\n",
    "\t\t\t\t\t\tEND) as result,csa\n",
    "\t\t\t\t\tfrom csa_agg5\n",
    "\t\t\t\t)\n",
    "\t\t\t\tUPDATE vital_signs.data\n",
    "\t\t\t\tset mhhi = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5vRku51rBjX"
   },
   "source": [
    "## nohhint.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEo8QlA3om6k"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: nohhint.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/25/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B28011 - INTERNET SUBSCRIPTIONS IN HOUSEHOLD\n",
    "# Universe: Households\n",
    "#purpose: Percent of Population with Broadband Internet Access\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def nohhint( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B28011*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B28011_001E', 'B28011_008E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B28011_008E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B28011_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    # ( (value[1]+value[2]+value[3]+value[4]) / nullif(value[5],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( (value[1]+value[2]+value[3]+value[4]) / nullif(value[5],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B25091_008E','B25091_009E','B25091_010E','B25091_011E','B25091_002E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset affordm = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jaAhKTsq8h2"
   },
   "source": [
    "## novhcl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvbGRtzpooKc"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: novhcl.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B08201 - HOUSEHOLD SIZE BY VEHICLES AVAILABLE\n",
    "# Universe: Households\n",
    "#purpose: Produce Sustainability - Percent of Households with No Vehicles Available Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def novhcl( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B08201*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B08201_002E','B08201_001E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B08201_002E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B08201_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "# ( value[1]/ nullif(value[2],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <novhcl_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\t\tselect csa,\n",
    "\t\t\t\t( value[1]/ nullif(value[2],0) )*100::numeric as result\n",
    "\t\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B08201_002E','B08201_001E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset novhcl = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-V-JsUuQq4UD"
   },
   "source": [
    "## paa.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJSYvUQaornz"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: paa.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B03002 - HISPANIC OR LATINO ORIGIN BY RACE\n",
    "# Universe: Total Population\n",
    "# Table Creates: racdiv, paa, pwhite, pasi, phisp, p2more, ppac\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def paa( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B03002*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # Append the one column from the other ACS Table\n",
    "    df['B03002_012E_Total_Hispanic_or_Latino']\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    tot = df[ 'B03002_001E_Total' ]\n",
    "    df1['African-American%NH'] = df[ 'B03002_004E_Total_Not_Hispanic_or_Latino_Black_or_African_American_alone' ]/ tot * 100\n",
    "\n",
    "    return df1['African-American%NH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsiY9pxaqxK3"
   },
   "source": [
    "## ppac.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vP5don5novBv"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: ppac.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B03002 - HISPANIC OR LATINO ORIGIN BY RACE\n",
    "# Universe: Total Population\n",
    "# Table Creates: racdiv, paa, pwhite, pasi, phisp, p2more, ppac\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def ppac( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B03002*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # Append the one column from the other ACS Table\n",
    "    df['B03002_012E_Total_Hispanic_or_Latino']\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    tot = df[ 'B03002_001E_Total' ]\n",
    "    df1['AllOther%NH'] = (\n",
    "        df['B03002_008E_Total_Not_Hispanic_or_Latino_Some_other_race_alone']\n",
    "        + df['B03002_005E_Total_Not_Hispanic_or_Latino_American_Indian_and_Alaska_Native_alone']\n",
    "        + df['B03002_007E_Total_Not_Hispanic_or_Latino_Native_Hawaiian_and_Other_Pacific_Islander_alone']\n",
    "    )/ tot * 100\n",
    "\n",
    "    return df1['AllOther%NH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8WpeTz3qyvN"
   },
   "source": [
    "## phisp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_jVhVm8ouD-"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: phisp.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B03002 - HISPANIC OR LATINO ORIGIN BY RACE\n",
    "# Universe: Total Population\n",
    "# Table Creates: racdiv, paa, pwhite, pasi, phisp, p2more, ppac\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def phisp( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B03002*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # Append the one column from the other ACS Table\n",
    "    df['B03002_012E_Total_Hispanic_or_Latino']\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    tot = df[ 'B03002_001E_Total' ]\n",
    "    df1['Hisp%'] = df['B03002_012E_Total_Hispanic_or_Latino']/ tot * 100\n",
    "\n",
    "    return df1['Hisp%']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q2SFrLcqt-g"
   },
   "source": [
    "## pwhite.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqeQGx2How7b"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: pwhite.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B03002 - HISPANIC OR LATINO ORIGIN BY RACE\n",
    "# Universe: Total Population\n",
    "# Table Creates: racdiv, paa, pwhite, pasi, phisp, p2more, ppac\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def pwhite( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B03002*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # Append the one column from the other ACS Table\n",
    "    df['B03002_012E_Total_Hispanic_or_Latino']\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    tot = df[ 'B03002_001E_Total' ]\n",
    "    df1['White%NH'] = df[ 'B03002_003E_Total_Not_Hispanic_or_Latino_White_alone' ]/ tot * 100\n",
    "\n",
    "    return df1['White%NH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hToadfmqm88"
   },
   "source": [
    "## sclemp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ht1hZ0Evo0b5"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: sclemp.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B14005 - SEX BY SCHOOL ENROLLMENT BY EDUCATIONAL ATTAINMENT BY EMPLOYMENT STATUS FOR THE POPULATION 16 TO 19 YEARS\n",
    "# (Universe = Population 16 to 19 years)\n",
    "#purpose: Produce Education and Youth - Percentage of Population aged 16-19 in School and/or Employed Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def sclemp( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B14005*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B14005_004E', 'B14005_005E', 'B14005_006E', 'B14005_009E', 'B14005_013E', 'B14005_018E', 'B14005_019E',\n",
    "               'B14005_020E', 'B14005_023E', 'B14005_027E','B14005_001E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B14005_004E', 'B14005_005E', 'B14005_006E', 'B14005_009E', 'B14005_013E', 'B14005_018E', 'B14005_019E', 'B14005_020E', 'B14005_023E', 'B14005_027E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B14005_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "# ( ( value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8] + value[9] + value[10] )  / nullif(value[11],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <sclemp_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( ( value[1] + value[2] + value[3] + value[4] + value[5] + value[6] + value[7] + value[8] + value[9] + value[10] )  / nullif(value[11],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B14005_004E', 'B14005_005E', 'B14005_006E', 'B14005_009E', 'B14005_013E', 'B14005_018E', 'B14005_019E', 'B14005_020E', 'B14005_023E', 'B14005_027E','B14005_001E']) )\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset sclemp = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CalgiqvFqlBh"
   },
   "source": [
    "## tpop.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYlLoi9lo1s2"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: tpop.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 4/16/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B01001 - SEX BY AGE\n",
    "# Universe: Total population\n",
    "# Table Creates: tpop, female, male, age5 age18 age24 age64 age65\n",
    "#purpose:\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def tpop( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B01001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = df.sum(numeric_only=True)\n",
    "\n",
    "    # df.columns\n",
    "    total = df['B01001_001E_Total']\n",
    "    df1 = pd.DataFrame()\n",
    "    df1['CSA'] = df.index\n",
    "    df1.set_index('CSA', drop = True, inplace = True)\n",
    "\n",
    "    df1['totalPop'] = total\n",
    "\n",
    "    return df1['totalPop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZtEt0qnqaAM"
   },
   "source": [
    "## trav14.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYQKmO_Qo2jf"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: trav14.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B08303 - TRAVEL TIME TO WORK,\n",
    "# (Universe: Workers 16 years and over who did not work at home)\n",
    "# Table Creates: trav14, trav29, trav44, trav45\n",
    "#purpose: Produce Sustainability - Percent of Employed Population with Travel Time to Work of 0-14 Minutes Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def trav14( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B08303*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B08303_002E','B08303_003E','B08303_004E','B08303_001E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B08303_002E','B08303_003E','B08303_004E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B08303_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "# ( (value[1] + value[2] + value[3] ) / nullif(value[4],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <trav14_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( (value[1] + value[2] + value[3] ) / nullif(value[4],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B08303_002E','B08303_003E','B08303_004E','B08303_001E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset trav14_ = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4OYkOuSqf0-"
   },
   "source": [
    "## trav29.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-Nu8HZlo3fO"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: trav29.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B08303 - TRAVEL TIME TO WORK,\n",
    "# (Universe: Workers 16 years and over who did not work at home)\n",
    "# Table Creates: trav14, trav29, trav44, trav45\n",
    "#purpose: Produce Sustainability - Percent of Employed Population with Travel Time to Work of 15-29 Minutes Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def trav29( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B08303*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B08303_005E','B08303_006E','B08303_007E','B08303_001E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B08303_005E','B08303_006E','B08303_007E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B08303_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "# ( (value[1] + value[2] + value[3] ) / nullif(value[4],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <trav29_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( (value[1] + value[2] + value[3] ) / nullif(value[4],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B08303_005E','B08303_006E','B08303_007E','B08303_001E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset trav29_ = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exbwDNUjqTPI"
   },
   "source": [
    "## trav45.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L346z6qUo5ja"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: trav45.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B08303 - TRAVEL TIME TO WORK,\n",
    "# (Universe: Workers 16 years and over who did not work at home)\n",
    "# Table Creates: trav14, trav29, trav44, trav45\n",
    "#purpose: Produce Sustainability - Percent of Employed Population with Travel Time to Work of 45 Minutes and Over Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def trav45( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B08303*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B08303_011E','B08303_012E','B08303_013E','B08303_001E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B08303_011E','B08303_012E','B08303_013E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B08303_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "# ( (value[1] + value[2] + value[3] ) / nullif(value[4],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( (value[1] + value[2] + value[3] ) / nullif(value[4],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B08303_011E','B08303_012E','B08303_013E','B08303_001E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset trav45_ = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23JC95n_8CkN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Emd0FT39qVrE"
   },
   "source": [
    "## trav44.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQbOdsAao4cj"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: trav44.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B08303 - TRAVEL TIME TO WORK,\n",
    "# (Universe: Workers 16 years and over who did not work at home)\n",
    "# Table Creates: trav14, trav29, trav44, trav45\n",
    "#purpose: Produce Sustainability - Percent of Employed Population with Travel Time to Work of 30-44 Minutes Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def trav44( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B08303*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B08303_008E','B08303_009E','B08303_010E','B08303_001E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B08303_008E','B08303_009E','B08303_010E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B08303_001E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "# ( (value[1] + value[2] + value[3] ) / nullif(value[4],0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <trav44_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( (value[1] + value[2] + value[3] ) / nullif(value[4],0) )*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B08303_008E','B08303_009E','B08303_010E','B08303_001E']) )\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset trav44_ = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqtZcocjqPlb"
   },
   "source": [
    "## unempl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjrhyuQio6sR"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: unempl.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/17/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B23001 - SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULATION 16 YEARS AND OVER\n",
    "# Universe - Population 16 years and over\n",
    "#Table Creates: empl, unempl, unempr, nilf\n",
    "#purpose: Produce Workforce and Economic Development - Percent Population 16-64 Unemployed and Looking for Work Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def unempl( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B23001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = [ 'B23001_003E','B23001_010E', 'B23001_017E', 'B23001_024E', 'B23001_031E', 'B23001_038E', 'B23001_045E', 'B23001_052E', 'B23001_059E', 'B23001_066E', 'B23001_089E', 'B23001_096E', 'B23001_103E', 'B23001_110E', 'B23001_117E', 'B23001_124E', 'B23001_131E', 'B23001_138E', 'B23001_145E', 'B23001_152E', 'B23001_008E', 'B23001_015E', 'B23001_022E', 'B23001_029E', 'B23001_036E', 'B23001_043E', 'B23001_050E', 'B23001_057E', 'B23001_064E', 'B23001_071E', 'B23001_094E', 'B23001_101E', 'B23001_108E', 'B23001_115E', 'B23001_122E', 'B23001_129E', 'B23001_136E', 'B23001_143E', 'B23001_150E', 'B23001_157E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B23001_008E', 'B23001_015E', 'B23001_022E', 'B23001_029E', 'B23001_036E', 'B23001_043E', 'B23001_050E', 'B23001_057E', 'B23001_064E', 'B23001_071E', 'B23001_094E', 'B23001_101E', 'B23001_108E', 'B23001_115E', 'B23001_122E', 'B23001_129E', 'B23001_136E', 'B23001_143E', 'B23001_150E', 'B23001_157E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B23001_003E', 'B23001_010E', 'B23001_017E', 'B23001_024E', 'B23001_031E', 'B23001_038E', 'B23001_045E', 'B23001_052E', 'B23001_059E', 'B23001_066E', 'B23001_089E', 'B23001_096E', 'B23001_103E', 'B23001_110E', 'B23001_117E', 'B23001_124E', 'B23001_131E', 'B23001_138E', 'B23001_145E', 'B23001_152E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "    #( ( value[21]+value[22]+value[23]+value[24]+value[25]+value[26]+value[27]+value[28]+value[29]+value[30]+value[31]+value[32]+value[33]+value[34]+value[35]+value[36]+value[37]+value[38]+value[39]+value[40]) --civil labor force unempl 16-64\n",
    "# /\n",
    "# nullif( (value[1]+value[2]+value[3]+value[4]+value[5]+value[6]+value[7]+value[8]+value[9]+value[10]+value[11]+value[12]+value[13]+value[14]+value[15]+value[16]+value[17]+value[18]+value[19]+value[20]) -- population 16 to 64   ,0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\t/* <unempl_14> */ --\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "( ( value[21]+value[22]+value[23]+value[24]+value[25]+value[26]+value[27]+value[28]+value[29]+value[30]+value[31]+value[32]+value[33]+value[34]+value[35]+value[36]+value[37]+value[38]+value[39]+value[40]) --civil labor force unempl 16-64  / nullif( (value[1]+value[2]+value[3]+value[4]+value[5]+value[6]+value[7]+value[8]+value[9]+value[10]+value[11]+value[12]+value[13]+value[14]+value[15]+value[16]+value[17]+value[18]+value[19]+value[20]) -- population 16 to 64   ,0) )*100::numeric\n",
    "\t\t\tas result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY[ 'B23001_003E','B23001_010E','B23001_017E','B23001_024E','B23001_031E','B23001_038E','B23001_045E','B23001_052E','B23001_059E','B23001_066E','B23001_089E','B23001_096E','B23001_103E','B23001_110E','B23001_117E','B23001_124E','B23001_131E','B23001_138E','B23001_145E','B23001_152E','B23001_008E','B23001_015E','B23001_022E','B23001_029E','B23001_036E','B23001_043E','B23001_050E','B23001_057E','B23001_064E','B23001_071E','B23001_094E','B23001_101E','B23001_108E','B23001_115E','B23001_122E','B23001_129E','B23001_136E','B23001_143E','B23001_150E','B23001_157E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset unempl = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pn8FyHO4qNAT"
   },
   "source": [
    "## unempr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cdBX2bso7xo"
   },
   "outputs": [],
   "source": [
    "#export \n",
    "#File: unempr.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/24/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B23001 - SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULATION 16 YEARS AND OVER\n",
    "# Universe: Workers 16 years and over\n",
    "#Table Creates: empl, unempl, unempr, nilf\n",
    "#purpose: Produce Sustainability - Percent of Population that Walks to Work Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def unempr( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B23001*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = [ 'B23001_006E', 'B23001_013E', 'B23001_020E', 'B23001_027E', 'B23001_034E', 'B23001_041E', 'B23001_048E',\n",
    "               'B23001_055E', 'B23001_062E', 'B23001_069E', 'B23001_092E', 'B23001_099E', 'B23001_106E', 'B23001_113E',\n",
    "               'B23001_120E', 'B23001_127E', 'B23001_134E', 'B23001_141E', 'B23001_148E', 'B23001_155E', 'B23001_008E',\n",
    "               'B23001_015E', 'B23001_022E', 'B23001_029E', 'B23001_036E', 'B23001_043E', 'B23001_050E', 'B23001_057E',\n",
    "               'B23001_064E', 'B23001_071E', 'B23001_094E', 'B23001_101E', 'B23001_108E', 'B23001_115E', 'B23001_122E',\n",
    "               'B23001_129E', 'B23001_136E', 'B23001_143E', 'B23001_150E', 'B23001_157E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B23001_008E', 'B23001_015E', 'B23001_022E', 'B23001_029E', 'B23001_036E', 'B23001_043E', 'B23001_050E',\n",
    "               'B23001_057E', 'B23001_064E', 'B23001_071E', 'B23001_094E', 'B23001_101E', 'B23001_108E', 'B23001_115E',\n",
    "               'B23001_122E', 'B23001_129E', 'B23001_136E', 'B23001_143E', 'B23001_150E', 'B23001_157E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B23001_006E', 'B23001_013E', 'B23001_020E', 'B23001_027E', 'B23001_034E', 'B23001_041E', 'B23001_048E',\n",
    "               'B23001_055E', 'B23001_062E', 'B23001_069E', 'B23001_092E', 'B23001_099E', 'B23001_106E', 'B23001_113E',\n",
    "               'B23001_120E', 'B23001_127E', 'B23001_134E', 'B23001_141E', 'B23001_148E', 'B23001_155E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "# ( ( value[21]+ value[22]+ value[23]+ value[24]+ value[25]+ value[26]+ value[27]+ value[28]+ value[29]+ value[30]+ value[31]+ value[32]+ value[33]+ value[34]+v alue[35]+ value[36]+ value[37]+ value[38]+ value[39]+ value[40]) --civil labor force unemployed 16-64 / nullif( (value[1] +value[2]+ value[3]+ value[4]+ value[5]+ value[6]+ value[7]+ value[8]+ value[9]+ value[10]+ value[11]+ value[12]+ value[13]+ value[14]+ value[15]+ value[16]+ value[17]+ value[18]+ value[19]+ value[20]) --civil labor force 16-64 ,0) )*100\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.sum(axis=1)\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\"\"\"\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t( (value[21]+value[22]+value[23]+value[24]+value[25]+value[26]+value[27]+value[28]+value[29]+value[30]+value[31]+value[32]+value[33]+value[34]+value[35]+value[36]+value[37]+value[38]+value[39]+value[40]) --civil labor force unemployed 16-64 / nullif( (value[1]+value[2]+value[3]+value[4]+value[5]+value[6]+value[7]+value[8]+value[9]+value[10]+value[11]+value[12]+value[13]+value[14]+value[15]+value[16]+value[17]+value[18]+value[19]+value[20]) --civil labor force 16-64 ,0) )*100::numeric\n",
    "\t\t\tas result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2013',ARRAY['B23001_006E', 'B23001_013E', 'B23001_020E', 'B23001_027E', 'B23001_034E', 'B23001_041E', 'B23001_048E', 'B23001_055E', 'B23001_062E', 'B23001_069E', 'B23001_092E', 'B23001_099E', 'B23001_106E', 'B23001_113E', 'B23001_120E', 'B23001_127E', 'B23001_134E', 'B23001_141E', 'B23001_148E', 'B23001_155E', 'B23001_008E', 'B23001_015E', 'B23001_022E', 'B23001_029E', 'B23001_036E', 'B23001_043E', 'B23001_050E', 'B23001_057E', 'B23001_064E', 'B23001_071E', 'B23001_094E', 'B23001_101E', 'B23001_108E', 'B23001_115E', 'B23001_122E', 'B23001_129E', 'B23001_136E', 'B23001_143E', 'B23001_150E', 'B23001_157E'] )\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset unempr = result from tbl where data2.csa = tbl.csa and update_data_year = '2013' and data_year = '2014';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9nyGydKqHiK"
   },
   "source": [
    "## walked.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tbhcWLhqo85t"
   },
   "outputs": [],
   "source": [
    "#@ title\n",
    "#export\n",
    "#File: walked.py\n",
    "#Author: Charles Karpati\n",
    "#Date: 1/24/19\n",
    "#Section: Bnia\n",
    "#Email: karpati1@umbc.edu\n",
    "#Description:\n",
    "# Uses ACS Table B08101 - MEANS OF TRANSPORTATION TO WORK BY AGE\n",
    "# Universe: Workers 16 years and over\n",
    "# Table Creates: othrcom, drvalone, carpool, pubtran, walked\n",
    "#purpose: Produce Sustainability - Percent of Population that Walks to Work Indicator\n",
    "#input: Year\n",
    "#output:\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "def walked( year ):\n",
    "\n",
    "    def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
    "    def getColByName (df, col): return df[getColName(df, col)]\n",
    "    def addKey(df, fi, col):\n",
    "        key = getColName(df, col)\n",
    "        val = getColByName(df, col)\n",
    "        fi[key] = val\n",
    "        return fi\n",
    "    def nullIfEqual(df, c1, c2):\n",
    "        return df.apply(lambda x:\n",
    "            x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
    "    def sumInts(df): return df.sum(numeric_only=True)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 1)\n",
    "    # Fetch Tract Files w/CSA Lables by Name from the 2_cleaned folder.\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fileName = ''\n",
    "    for name in glob.glob('AcsDataClean/B08101*5y'+str(year)+'_est.csv'):\n",
    "        fileName = name\n",
    "    df = pd.read_csv( fileName, index_col=0 )\n",
    "\n",
    "    # Aggregate by CSA\n",
    "    # Group By CSA so that they may be opperated on\n",
    "    df = df.groupby('CSA')\n",
    "    # Aggregate Numeric Values by Sum\n",
    "    df = sumInts(df)\n",
    "\n",
    "    # Add 'BALTIMORE' which is the SUM of all the CSAs\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 2)\n",
    "    # Prepare the columns\n",
    "    #~~~~~~~~~~~~~~~\n",
    "\n",
    "    # Final Dataframe\n",
    "    fi = pd.DataFrame()\n",
    "    columns = ['B08101_001E','B08101_049E','B08101_033E']\n",
    "    for col in columns:\n",
    "        fi = addKey(df, fi, col)\n",
    "\n",
    "    # Numerators\n",
    "    numerators = pd.DataFrame()\n",
    "    columns = ['B08101_033E']\n",
    "    for col in columns:\n",
    "        numerators = addKey(df, numerators, col)\n",
    "\n",
    "    # Denominators\n",
    "    denominators = pd.DataFrame()\n",
    "    columns = ['B08101_001E','B08101_049E']\n",
    "    for col in columns:\n",
    "        denominators = addKey(df, denominators, col)\n",
    "    # construct the denominator, returns 0 iff the other two rows are equal.\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 3)\n",
    "    # Run the Calculation\n",
    "# value[3] / nullif((value[1]-value[2]),0)\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    fi['numerator'] = numerators.sum(axis=1)\n",
    "    fi['denominator'] = denominators.iloc[: ,0] - denominators.iloc[: ,1]\n",
    "    fi = fi[fi['denominator'] != 0] # Delete Rows where the 'denominator' column is 0\n",
    "    fi['final'] = (fi['numerator'] / fi['denominator'] ) * 100\n",
    "\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    # Step 4)\n",
    "    # Add Special Baltimore City Data\n",
    "    #~~~~~~~~~~~~~~~\n",
    "    url = 'https://api.census.gov/data/20'+str(year)+'/acs/acs5/subject?get=NAME,S0801_C01_010E&for=county%3A510&in=state%3A24&key=829bf6f2e037372acbba32ba5731647c5127fdb0'\n",
    "    table = pd.read_json(url, orient='records')\n",
    "    fi['final']['Baltimore City'] = float(table.loc[1, table.columns[1]])\n",
    "\n",
    "    return fi['final']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\t\tWITH tbl AS (\n",
    "\t\t\tselect csa,\n",
    "\t\t\t(\n",
    "\t\t\t\tvalue[3]\n",
    "\t\t\t\t/ nullif((value[1]-value[2]),0)\n",
    "\t\t\t)*100::numeric as result\n",
    "\t\t\tfrom vital_signs.get_acs_vars_csa_and_bc('2014',ARRAY['B08101_001E','B08101_049E','B08101_033E'])\n",
    "\t\t\t)\n",
    "\t\t\tupdate vital_signs.data\n",
    "\t\t\tset walked = result from tbl where data2.csa = tbl.csa and update_data_year = '2014' and data_year = '2014';\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "fCnXf8GxqsOV",
    "SYZVn_Raq1_6",
    "q1U8LjwRdxri",
    "9PBNoXyvhY2F",
    "VmBSC_ekhZAA",
    "z_0VllC8rmyg",
    "2ACCKmW0rlQX",
    "ijV2TDdUrjlY",
    "S5gTVyiCrhsV",
    "ZOZGVS2Trf16",
    "Q1J2m25WreEF",
    "-i4PH3I3sCzp",
    "DxgEFDeOrZ_l",
    "gL3uRpPXrXgb",
    "VllBOTcRrVnL",
    "__sPm-C0rSUe",
    "WCudz3T1rQb2",
    "kduYoYRDrPAY",
    "fVZh_56DrNdF",
    "LCirZkI0rL02",
    "2hHHrGp7rJuP",
    "4dO2Cq_lrDU2",
    "6W7qN7vQq--p",
    "hr-YQhhHq54R",
    "xETwOF84qvem",
    "1w0jabMJr4jY",
    "_mcGyo99r1Cm",
    "gS4rCbmurzV-",
    "exbwDNUjqTPI",
    "Emd0FT39qVrE",
    "JqtZcocjqPlb",
    "Pn8FyHO4qNAT",
    "l9nyGydKqHiK"
   ],
   "name": "04_Create_Acs_Indicators_Original.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
