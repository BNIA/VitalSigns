# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/CitiStat_Dirtyst_Clogged.ipynb (unless otherwise specified).

__all__ = ['dirtyst', 'dirtyst', 'dirtyst', 'dirtyst', 'dirtyst', 'clogged', 'clogged', 'clogged', 'clogged', 'clogged',
           'lights', 'fin']

# Cell

# Copy the Data
dirtyst = dirtydf.copy()

# Query the Data
# dirtyst = dirtyst[ (dirtyst['SRType'].str.contains('SW-Dirty Alley|SW-Dirty Street', regex=True) ) ]

# *Special*: # UPDATE HERE AND THEN GROUP
dirtyst['162-dirtyst'+year] = 1
dirtyst = dirtyst.append({'CSA2010': 'Baltimore City' , '162-dirtyst'+year : dirtyst['162-dirtyst'+year].sum() } , ignore_index=True)
dirtyst = dirtyst.groupby('CSA2010').sum(numeric_only=True)

# Make sure ALL csas and BaltimoreCity are included and sorted.
dirtyst = csa.merge( dirtyst, left_on='CSA2010', right_on='CSA2010', how='outer' )
dirtyst.drop(columns=['Shape__Length', 'Shape__Area', 'geometry' ], inplace=True)
dirtyst = dirtyst[['CSA2010', '162-dirtyst'+year, 'tpop10']]


# Create the Indicator
dirtyst['162-dirtyst'+year] = dirtyst['162-dirtyst'+year] * 1000 / dirtyst['tpop10']

display( dirtyst.head(2) )
dirtyst.tail(2)

dirtyst.to_csv('162-dirtyst'+year+'.csv')

# Cell

# Copy the Data
clogged = cloggedf.copy()

# Query the Data
# clogged = clogged[
#  (dirtyst['PROPERTYIN'].str.contains('CONDOMINIUM|SINGLE FAMILY', regex=True) )
#| (dirtyst['SALEDATE'] >= '20'+year+'-01-01')
#]

# *Special*: # UPDATE HERE AND THEN GROUP
clogged['163-clogged'+year] = 1
clogged = clogged.append({'CSA2010': 'Baltimore City' , '163-clogged'+year : clogged['163-clogged'+year].sum() } , ignore_index=True)
clogged = clogged.groupby('CSA2010').sum(numeric_only=True)

# Make sure ALL csas and BaltimoreCity are included and sorted.
clogged = csa.merge( clogged, left_on='CSA2010', right_on='CSA2010', how='outer' )
clogged.drop(columns=['Shape__Length', 'Shape__Area', 'geometry' ], inplace=True)
clogged = clogged[['CSA2010', '163-clogged'+year, 'tpop10']]


# Create the Indicator
clogged['163-clogged'+year] = clogged['163-clogged'+year] * 1000 / clogged['tpop10']

display( clogged.head(2) )
clogged.tail(2)

clogged.to_csv('163-clogged'+year+'.csv')

# Cell
def lights(df, csa, yr):
  # The rate of service requests for addressing street light outages made through Baltimore's 311 system per 1,000 residents.
  # More than one service request may be made for the same issue but is logged as a unique request.

  # Create the Numerator
  lights = df.copy()
  lights['count'] = 1
  lights = lights.groupby('CSA2010').sum(numeric_only=True)

  # Make sure ALL csas and BaltimoreCity are included and sorted.
  lights = csa.merge( lights, left_on='CSA2010', right_on='CSA2010', how='outer' )
  lights.drop( columns=['geometry', 'Shape__Length','CouncilDis','Latitude','Longitude','Shape__Area','OBJECTID_y','OBJECTID_x'], inplace=True)
  # Baltimoire has records not in the
  lights.at[55,'count']=lights['count'].sum()
  # Perform the calculation
  lights['215-lights'+year] = lights['count'] / lights['tpop10'] * 1000

  compareYears = gpd.read_file("https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Lights/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson");
  prevYear = 'lights'+ str( int(year) - 1 )
  if prevYear in compareYears.columns:
    lights = lights.merge( compareYears[['CSA2010', prevYear]], left_on='CSA2010', right_on='CSA2010', how='outer' )
    lights['change'] = lights['215-lights'+year] - lights[ prevYear ]
    lights['percentChange'] = lights['change' ] / lights[ prevYear ] * 100
    lights['change'] = lights['change'].apply(lambda x: "{:.2f}".format(x) )
  print( 'Records Matching Query: ', lights.size / len(lights.columns) )
  return lights

fin = lights(df, csa, year)
fin.to_csv('215-lights'+year+'.csv', index=False)
fin.head(60)