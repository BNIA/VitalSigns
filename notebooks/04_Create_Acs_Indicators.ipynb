{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbupF1WPeozn"
      },
      "outputs": [],
      "source": [
        "# default_exp create"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGSLNQdymwjB"
      },
      "outputs": [],
      "source": [
        "!pip install VitalSigns2022TEST dataplay geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c38OYV2HZ65Y"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Misc Function Declarations\n",
        "\n",
        "# These functions right here are used in the calculations below.\n",
        "# Finds a column matchings a substring\n",
        "def getColName  (df, col): return df.columns[df.columns.str.contains(pat = col)][0]\n",
        "def getColByName (df, col): return df[getColName(df, col)]\n",
        "\n",
        "# Pulls a column from one dataset into a new dataset.\n",
        "# This is not a crosswalk. calls getColByName()\n",
        "def addKey(df, fi, col):\n",
        "    key = getColName(df, col)\n",
        "    val = getColByName(df, col)\n",
        "    fi[key] = val\n",
        "    return fi\n",
        "    \n",
        "# Return 0 if two specified columns are equal.\n",
        "def nullIfEqual(df, c1, c2):\n",
        "    return df.apply(lambda x:\n",
        "        x[getColName(df, c1)]+x[getColName(df, c2)] if x[getColName(df, c1)]+x[getColName(df, c2)] != 0 else 0, axis=1)\n",
        "    \n",
        "# I'm thinking this doesnt need to be a function..\n",
        "def sumInts(df): return df.sum(numeric_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhQ_FIqhjHEG"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "\n",
        "#These are the libraries used by every script. The scripts WILL NOT run without them. \n",
        "from VitalSigns.acsDownload import retrieve_acs_data\n",
        "from dataplay.merge import mergeDatasets\n",
        "from dataplay.intaker import Intake \n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import glob\n",
        "import numpy\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ugqi3ycLnJV3"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "\n",
        "def calculateSimpleIndicator( shortname, tableId, numerators, denominators, aggregateTableId, operations, percent, specialNote, \n",
        "                             state='24', county='510', tract='*', year='20', saveAcs=False, columnsToInclude = '',\n",
        "                             mergeUrl = 'https://raw.githubusercontent.com/gparedes10/2022VitalSigns/main/CSA_2010_and_2020.csv',\n",
        "                             merge_left_col = 'tract', merge_right_col= 'TRACTCE', merge_how = 'outer', groupBy = 'CSA2020'):\n",
        "  # clear_output(wait=True)\n",
        "  if shortname[0:3] in ['age', 'tra', 'biz', 'mor']: shortname = shortname+'_'\n",
        "  lbl = shortname+'_'+year\n",
        "  # print('\\n ~~~~~~~~~~~~~~~~~~~~ Creating:', lbl, '~~~~~~~~~~~~~~~~~~~~');\n",
        "\n",
        "  # Pull the data\n",
        "  df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)\n",
        "\n",
        "  # Get the crosswalk\n",
        "  if mergeUrl:\n",
        "    right_ds = Intake.getData( mergeUrl ) \n",
        "    df = mergeDatasets( left_ds=df, right_ds=right_ds, left_col=merge_left_col, right_col=merge_right_col, merge_how=merge_how, interactive=False )\n",
        "\n",
        "  # Group and Aggregate\n",
        "  if groupBy:\n",
        "    df = df.groupby(groupBy)\n",
        "    if operations == 'sum':\n",
        "      df = sumInts(df)\n",
        "    else:\n",
        "      df = sumInts(df) \n",
        "    # print('Aggregated ACS on Crosswalk.')\n",
        "\n",
        "  # Create the indicator\n",
        "  columns = numerators + '|' + denominators; \n",
        "  if (columnsToInclude): columns = columns + '|'+ columnsToInclude\n",
        "  fi = df.filter( regex = columns ).copy()\n",
        "  fi[lbl]  = ( df.filter(regex=numerators).sum(axis=1) ) / df.filter(regex=denominators).sum(axis=1) * 100\n",
        "\n",
        "  filename = \"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/\"+shortname+\"/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\"\n",
        "  print(filename)\n",
        "  compareYears = gpd.read_file(filename);\n",
        "  goback = 0\n",
        "  prevYear = shortname+ str( int(year) - goback )\n",
        "  if prevYear in compareYears.columns:\n",
        "    fi = fi.merge( compareYears[['CSA2010', prevYear]], left_on='CSA2010', right_on='CSA2010', how='outer' )\n",
        "    print(fi.columns)\n",
        "    fi['change'] = fi[lbl] - fi[ prevYear ]\n",
        "    fi['percentChange'] = fi['change' ] / fi[ prevYear ] * 100\n",
        "    fi['change'] = fi['change'].apply(lambda x: \"{:.2f}\".format(x) )\n",
        "\n",
        "  if shortname:\n",
        "    fi.to_csv(lbl+'.csv', quoting=csv.QUOTE_ALL)\n",
        "    # print('Indicator Saved')\n",
        "\n",
        "#for index, row in inst[:].iterrows():\n",
        " # if (row['Come Back To'] == '-'): calculateSimpleIndicator( row['Shortname'], row['tables'], row['Numerator'], row['Denominators'], row['Special Table'], row['Operation'], row['Percent'], row['Come Back To'])\n",
        "  #else: print('\\r\\n --> ',row['Shortname'], '-->', row['Come Back To'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyPNNQF8q9nC"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create createIndicator()\n",
        "\n",
        "def createAcsIndicator(state, county, tract, year, tableId,\n",
        "                    mergeUrl, merge_left_col, merge_right_col, merge_how, groupBy,\n",
        "                    aggMethod, method, columnsToInclude, finalFileName=False):\n",
        "\n",
        "  # Pull the data\n",
        "  df = retrieve_acs_data(state, county, tract, tableId, year)\n",
        "  print('Table: ' + tableId + ', Year: ' + year + ' imported.')\n",
        "\n",
        "  # Get the crosswalk\n",
        "  if mergeUrl:\n",
        "    right_ds = Intake.getData( mergeUrl )\n",
        "    print( right_ds.columns )\n",
        "    print('Merge file imported')\n",
        "    # Merge crosswalk with the data\n",
        "    df = mergeDatasets( left_ds=df, right_ds=right_ds,\n",
        "                  left_col=merge_left_col, right_col=merge_right_col,\n",
        "                  merge_how=merge_how, interactive=False )\n",
        "\n",
        "    print('Both are now merged.')\n",
        "\n",
        "  # Group and Aggregate\n",
        "  if groupBy:\n",
        "    df = df.groupby(groupBy)\n",
        "    print('Aggregating...')\n",
        "    if aggMethod == 'sum':\n",
        "      df = sumInts(df)\n",
        "    else:\n",
        "      df = sumInts(df)\n",
        "    print('Aggregated')\n",
        "\n",
        "  # Create the indicator\n",
        "  print('Creating Indicator')\n",
        "  resp = method( df, columnsToInclude)\n",
        "  print('Indicator Created')\n",
        "  if finalFileName:\n",
        "    resp.to_csv(finalFileName, quoting=csv.QUOTE_ALL)\n",
        "    print('Indicator Saved')\n",
        "\n",
        "  return resp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHRv3nlMg06s"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create age5\n",
        "\n",
        "#Table ID - B01001\n",
        "#Table Name - Sex by Age\n",
        "#Indicator Output - Percent of Population Under 5 Years old\n",
        "\n",
        "def age5( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='027E|003E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['age5_XX']  = ( df.filter(regex='027E|003E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10,000. Since it has a tract number, it was added to the CSA csv file and the code calculated its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        "  \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ4JLtpUg04T"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create age18\n",
        "\n",
        "#Table ID - B01001\n",
        "#Table Name - Sex by Age\n",
        "#Indicator Output - Percent of Population 5-17 Years old\n",
        "\n",
        "def age18( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='004E|005E|006E|028E|029E|030E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                     #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['age18_XX']  = ( df.filter(regex='004E|005E|006E|028E|029E|030E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vaJAc5Og017"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create age24\n",
        "\n",
        "#Table ID - B01001\n",
        "#Table Name - Sex by Age\n",
        "#Indicator Output - Percent of Population 18-24 Years old\n",
        "\n",
        "def age24( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='007E|008E|009E|010E|031E|032E|033E|034E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                          #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['age24_XX']  = ( df.filter(regex='007E|008E|009E|010E|031E|032E|033E|034E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10,000. Since it has a tract number, it was added to the CSA csv file and the code calculated its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        "  \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xXphAkqg0z2"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create age64\n",
        "\n",
        "#Table ID - B01001\n",
        "#Table Name - Sex by Age\n",
        "#Indicator Output - Percent of Population 25-64 Years old\n",
        "\n",
        "\n",
        "def age64( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='011|012E|013E|014E|015E|016E|017E|018E|019E|035|036E|037E|038E|039E|040E|041E|042E|043E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                                                                          #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['age64_XX']  = ( df.filter(regex='011|012E|013E|014E|015E|016E|017E|018E|019E|035|036E|037E|038E|039E|040E|041E|042E|043E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10,000. Since it has a tract number, it was added to the CSA csv file and the code calculated its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        "  \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTqlJLdUg0tU"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create age65\n",
        "\n",
        "#Table ID - B01001\n",
        "#Table Name - Sex by Age\n",
        "#Indicator Output - Percent of Population 65 Years and over\n",
        "\n",
        "def age65( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|020E|021E|022E|023E|024E|025E|044E|045E|046E|047E|048E|049E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                                                   #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['age65_XX']  = ( df.filter(regex='020E|021E|022E|023E|024E|025E|044E|045E|046E|047E|048E|049E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10,000. Since it has a tract number, it was added to the CSA csv file and the code calculated its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        "  \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O82H26kg_L5"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create racdiv\n",
        "\n",
        "#Table ID - B02001\n",
        "#Table Name - Race\n",
        "#Indicator Output: Racial Diversity Index\n",
        "#NOTE: Import 'hisp' script as well, or this script WILL NOT work. This is the only script that uses TWO tables - table 2 (B03002) is called automatically to get the hispanic statistics.\n",
        "\n",
        "def racdiv(df, columnsToInclude):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        " #Get hisp table and Indicators\n",
        "  #'hisp' script HAS to be imported for this script to work.\n",
        "  #User has to re-enter the year they want the indicator for. Maybe there is a way to automate this input???\n",
        "  chosen_year = str(input(\"Please enter your chosen year again (i.e., '17', '20'): \"))\n",
        "  if(int(chosen_year)) <= 19:\n",
        "    fi_hisp = createAcsIndicator(state = '24', county = '510', tract = '*' , year = chosen_year, tableId = 'B03002',\n",
        "                      mergeUrl = 'https://raw.githubusercontent.com/gparedes10/2022VitalSigns/main/CSA_2010_and_2020.csv', \n",
        "                      merge_left_col = 'tract',\n",
        "                      merge_right_col = 'TRACTCE',\n",
        "                      merge_how = 'outer',\n",
        "                      groupBy = 'CSA2010',\n",
        "                      aggMethod= 'sum', \n",
        "                      method = hisp,\n",
        "                      columnsToInclude = [],\n",
        "                      finalFileName=False)\n",
        "  else:\n",
        "    fi_hisp = createAcsIndicator(state = '24', county = '510', tract = '*' , year = chosen_year, tableId = 'B03002',\n",
        "                      mergeUrl = 'https://raw.githubusercontent.com/gparedes10/2022VitalSigns/main/CSA_2010_and_2020.csv', \n",
        "                      merge_left_col = 'tract',\n",
        "                      merge_right_col = 'TRACTCE',\n",
        "                      merge_how = 'outer',\n",
        "                      groupBy = 'CSA2020',\n",
        "                      aggMethod= 'sum', \n",
        "                      method = hisp,\n",
        "                      columnsToInclude = [],\n",
        "                      finalFileName=False)\n",
        "\n",
        "  #Column 012E from the Hisp table has a different name on the years prior to 2019. \n",
        "  #This  code changes the name of that column automatically for every year prior to 2019.\n",
        "  if(int(chosen_year)) < 19:\n",
        "    fi_hisp.rename(columns = {'B03002_012E_Total_Hispanic_or_Latino':'B03002_012E_Total:_Hispanic_or_Latino:'}, inplace = True)\n",
        "\n",
        "  \n",
        "  #Append column 12 from table B03002 to table B02001          \n",
        "  df['B02001_012E_Total_Hispanic_or_Latino'] = fi_hisp['B03002_012E_Total:_Hispanic_or_Latino:']\n",
        "\n",
        "  columns = df.filter(regex='001E|003E|004E|005E|006E|012E|tract').columns.values  #'tract' HAS to be in this list.\n",
        "  columns = numpy.append(columns, columnsToInclude)                                \n",
        "  \n",
        "  #Get all the race percentages.\n",
        "  #'tract' is added here so that \"Unassigned--Jail\" can be removed later.\n",
        "  fi['White%'] = ( df.filter(regex='002E').sum(axis=1)) / df.filter(regex='001E').sum(axis=1) * 100\n",
        "  fi['African-American%'] = ( df.filter(regex='003E').sum(axis=1)) / df.filter(regex='001E').sum(axis=1) * 100\n",
        "  fi['American Indian%'] = ( df.filter(regex='004E').sum(axis=1)) / df.filter(regex='001E').sum(axis=1) * 100\n",
        "  fi['Asian%'] = ( df.filter(regex='005E').sum(axis=1)) / df.filter(regex='001E').sum(axis=1) * 100\n",
        "  fi['Native Hawaii/Pac Islander%'] = ( df.filter(regex='006E').sum(axis=1)) / df.filter(regex='001E').sum(axis=1) * 100\n",
        "  fi['Hisp%'] = ( df.filter(regex='012E').sum(axis=1)) / df.filter(regex='001E').sum(axis=1) * 100\n",
        "  fi['tract'] = df['tract'] \n",
        "\n",
        "  #Get the diversity index\n",
        "  fi['Diversity_Index'] = (1 -(\n",
        "      (fi['African-American%'] /100 )**2\n",
        "      + (fi['White%'] /100 )**2\n",
        "      + (fi['American Indian%'] /100 )**2\n",
        "      + (fi['Asian%'] /100 )**2\n",
        "      + (fi['Native Hawaii/Pac Islander%'] /100 )**2\n",
        "    )*(\n",
        "        ( fi['Hisp%'] /100 )**2\n",
        "        +(1-( fi['Hisp%'] /100) )**2\n",
        "    ) ) * 100\n",
        "\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyxGbFfCjd2-"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create hisp\n",
        "\n",
        "#Table ID - B03002\n",
        "#Table Name - Hipanic or Latino Origin by Race\n",
        "#Indicator Output: Percent of Residents - Hispanic\n",
        "\n",
        "def hisp( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='012E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)            #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['hispXX']  = ( df.filter(regex='012E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDPUZtxjjnQU"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create paa\n",
        "\n",
        "#Table ID - B03002\n",
        "#Table Name - Hipanic or Latino Origin by Race\n",
        "#Indicator Output: Percent of Residents - Black/African-American (Non-Hispanic)\n",
        "\n",
        "def paa( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='004E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)            #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['paaXX']  = ( df.filter(regex='004E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCeAAeWvjq-o"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create pwhite\n",
        "\n",
        "#Table ID - B03002\n",
        "#Table Name - Hipanic or Latino Origin by Race\n",
        "#Indicator Output: Percent of Residents - White/Caucasian (Non-Hispanic)\n",
        "\n",
        "def pwhite( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='003E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)            #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['pwhiteXX']  = ( df.filter(regex='003E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1xPgdKIjq6I"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create pasi\n",
        "\n",
        "#Table ID - B03002\n",
        "#Table Name - Hipanic or Latino Origin by Race\n",
        "#Indicator Output: Percent of residents - Asian (Non-Hispanic)\n",
        "\n",
        "def pasi( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='006E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)            #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['pasiXX']  = ( df.filter(regex='006E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHzKxTRXjq0L"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create p2more\n",
        "\n",
        "#Table ID - B03002\n",
        "#Table Name - Hipanic or Latino Origin by Race\n",
        "#Indicator Output: Percent of Residents - Two or More Races (Non-Hispanic)\n",
        "\n",
        "def p2more( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='009E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)            #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['p2moreXX']  = ( df.filter(regex='009E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuyOYVKCjqiY"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create ppac\n",
        "\n",
        "#Table ID - B03002\n",
        "#Table Name - Hipanic or Latino Origin by Race\n",
        "#Indicator Output: Percent of Residents - All Other Races (Hawaiian/ Pacific Islander, Alaskan/ Native American Other Race) (Non-Hispanic)\n",
        "\n",
        "def ppac( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='008E|005E|007E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                      #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['ppacXX']  = ( df.filter(regex='008E|005E|007E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBTW2CYtj7SD"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create bahigher\n",
        "\n",
        "#Table ID: B06009\n",
        "#Table Name: Place of Birth by Educational Attainment in the U.S.\n",
        "#Indicator Output: Percent Population (25 Years and over) with a Bachelor's Degree or Above\n",
        "\n",
        "def bahigher( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='005E|006E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)            #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['bahigherXX']  = ( df.filter(regex='005E|006E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVH_Dlymj7Nb"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create hsdipl\n",
        "\n",
        "#Table ID: B06009\n",
        "#Table Name: Place of Birth by Educational Attainment in the U.S.\n",
        "#Indicator Output: Percent Population (25 Years and over) With High School Diploma and Some College or Associates Degree\n",
        "\n",
        "def hsdipl( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "  df.columns = df.columns.str.replace(r\"[(]\", \"\")   #Remove parenthesis from column names. - Columns will give an error when this line isnt here.\n",
        "  df.columns = df.columns.str.replace(r\"[)]\", \"\")   #Remove parenthesis from column names. - Columns will give an error when this line isnt here.\n",
        "\n",
        "  columns = df.filter(regex='003E|004E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)            #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['hsdiplXX']  = ( df.filter(regex='003E|004E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-sU6Bnaj7IJ"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create lesshs\n",
        "\n",
        "#Table ID: B06009\n",
        "#Table Name: Place of Birth by Educational Attainment in the U.S.\n",
        "#Indicator Output: Percent Population (25 Years and over) With Less Than a High School Diploma or GED\n",
        "\n",
        "def lesshs( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='002E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)            #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['lesshsXX']  = ( df.filter(regex='002').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSCOa_rfkCnP"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create carpool\n",
        "\n",
        "#Table ID: B08101\n",
        "#Table Name: Means of transportation to work by age\n",
        "#Indicator Output: Percent of Population that Carpool to Work\n",
        "\n",
        "def carpool( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|049E|017E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['carpoolXX']  = ( df.filter(regex='017E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1) - (df.filter(regex='049E').sum(axis=1))) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYMzCKsqkCh0"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create drvalone\n",
        "\n",
        "#Table ID: B08101\n",
        "#Table Name: Means of transportation to work by age\n",
        "#Indicator Output: Percent of Population that Drove Alone to Work\n",
        "\n",
        "def drvalone( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|049E|009E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['drvaloneXX']  = ( df.filter(regex='009E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1) - (df.filter(regex='049E').sum(axis=1))) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row \n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "  \n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QF0lrnjkCb-"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create pubtran\n",
        "\n",
        "#Table ID: B08101\n",
        "#Table Name: Means of transportation to work by age\n",
        "#Indicator Output: Percent of Population that Uses Public Transportation to Get to Work\n",
        "\n",
        "def pubtran( df, columnsToInclude ):\n",
        "  df.columns = df.columns.str.replace(r\"[(]\", \"\")   #Remove parenthesis from column names. - Columns will give an error when this line isnt here.\n",
        "  df.columns = df.columns.str.replace(r\"[)]\", \"\")   #Remove parenthesis from column names. - Columns will give an error when this line isnt here.\n",
        "\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|025E|049E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['pubtranXX']  = ( df.filter(regex='025E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1) - (df.filter(regex='049E').sum(axis=1))) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row \n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyI8T04ekCV8"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create walked\n",
        "\n",
        "#Table ID: B08101\n",
        "#Table Name: Means of transportation to work by age\n",
        "#Indicator Output: Percent of Population that Walks to Work\n",
        "\n",
        "def walked( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|049E|033E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['walkedXX']  = ( df.filter(regex='033E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1) - (df.filter(regex='049E').sum(axis=1))) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row \n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ6SQqBHkCP_"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create othercom\n",
        "\n",
        "#Table ID: B08101\n",
        "#Table Name: Means of transportation to work by age\n",
        "#Indicator Output: Percent of Population Using Other Means to Commute to Work (Taxi, Motorcycle, Bicycle, Other)\n",
        "\n",
        "def othercom( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|049E|041E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['othercomXX']  = ( df.filter(regex='041E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1) - (df.filter(regex='049E').sum(axis=1))) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row \n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfVn6yEekTlo"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create trav14\n",
        "\n",
        "#Table ID - B08303\n",
        "#Table Name - Travel time to work\n",
        "#Indicator Output - Percent of Employed Population with Travel Time to Work of 0-14 Minutes\n",
        "\n",
        "def trav14( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|002E|003E|004E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['trav14_XX']  = ( df.filter(regex='002E|003E|004E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10,000. Since it has a tract number, it was added to the CSA csv file and the code calculated its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        "  \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV87vXNBkTho"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create trav29\n",
        "\n",
        "#Table ID - B08303\n",
        "#Table Name - Travel time to work\n",
        "#Indicator Output - Percent of Employed Population with Travel Time to Work of 15-29 Minutes\n",
        "\n",
        "def trav29( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='005E|006E|007E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['trav29_XX']  = ( df.filter(regex='005E|006E|007E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10,000. Since it has a tract number, it was added to the CSA csv file and the code calculated its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        "  \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI6pc7YOkTca"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create trav44\n",
        "\n",
        "#Table ID - B08303\n",
        "#Table Name - Travel time to work\n",
        "#Indicator Output - Percent of Employed Population with Travel Time to Work of 30-44 Minutes \n",
        "\n",
        "def trav44( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='008E|009E|010E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['trav44_XX']  = ( df.filter(regex='008E|009E|010E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10,000. Since it has a tract number, it was added to the CSA csv file and the code calculated its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        "  \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKXO4SA9kTXI"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create trav45\n",
        "\n",
        "#Table ID - B08303\n",
        "#Table Name - Travel time to work\n",
        "#Indicator Output - Percent of Employed Population with Travel Time to Work of 45 Minutes and Over\n",
        "\n",
        "def trav45( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='011E|012E|013E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['trav45_XX']  = ( df.filter(regex='011E|012E|013E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10,000. Since it has a tract number, it was added to the CSA csv file and the code calculated its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        "  \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVJb1qCukcGG"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create novhcl\n",
        "\n",
        "#Table ID - B08201\n",
        "#Table Name - Household size by vehicles available\n",
        "#Indicator Output - Percent of Households with No Vehicles Available\n",
        "\n",
        "def novhcl( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='002E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['novhclXX']  = ( df.filter(regex='002E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10,000. Since it has a tract number, it was added to the CSA csv file and the code calculated its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        "  \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ev8M2v0kxz7"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create hhs\n",
        "\n",
        "#Table ID - B11005\n",
        "#Table Name - Household by Presence of People under 18 years by Household Type\n",
        "#Indicator Output - Total Number of Households\n",
        "\n",
        "def hhs( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)       #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['hhsXX']  =  df.filter(regex='001E').sum(axis=1)\n",
        "\n",
        "  #Baltimore city is tract 10,000. Since it has a tract number, it was added to the CSA csv file and the code calculated its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        "  \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BXvocCIkxvk"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create fam\n",
        "\n",
        "#Table ID - B11005\n",
        "#Table Name - Household by Presence of People under 18 years by Household Type\n",
        "#Indicator Output - Percent of Households with Children Under 18\n",
        "\n",
        "def fam( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='002E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['famXX']  = ( df.filter(regex='002E').sum(axis=1)\n",
        ") / df.filter(regex='001E').sum(axis=1) * 100\n",
        "\n",
        "  #Baltimore city is tract 10,000. Since it has a tract number, it was added to the CSA csv file and the code calculated its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        "  \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAj9mN_ckxqk"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create femhhs\n",
        "\n",
        "#Table ID - B11005\n",
        "#Table Name - Household by Presence of People under 18 years by Household Type\n",
        "#Indicator Output - Percent of Female-Headed Households with Children Under 18\n",
        "\n",
        "def femhhs( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='007E|011E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['femhhsXX']  = ( df.filter(regex='007E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1) - (df.filter(regex='011E').sum(axis=1))) * 100\n",
        "\n",
        "  #Baltimore city is tract 10,000. Since it has a tract number, it was added to the CSA csv file and the code calculated its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        "  \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugaHJQcrlHe1"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create sclemp\n",
        "\n",
        "#Table ID: B14005\n",
        "#Table Name: Sex by School Enrollment by Educational Attainment by Employment Status for the population 16 to 19 years\n",
        "#Indicator Output: Percentage of Population aged 16-19 in School and/or Employed\n",
        "\n",
        "def sclemp( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='003E|013E|017E|027E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['sclempXX']  = ( df.filter(regex='003E|009E|013E|017E|023E|027E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVRlRTE2lKId"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create hhpov\n",
        "\n",
        "#Table ID: B17017\n",
        "#Table Name: Poverty status in the past 12 months by household type by age of householder\n",
        "#Indicator Output: Percent of Family Households Living Below the Poverty Line\n",
        "\n",
        "def hhpov( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='003E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                 #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['hhpovXX']  = ( df.filter(regex='003E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1) - (df.filter(regex='020E').sum(axis=1)) - (df.filter(regex='049E').sum(axis=1))  #substract non-family households from the total\n",
        ") * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSfXUl9qlNmL"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create hhchpov\n",
        "\n",
        "#Table ID: B17001\n",
        "#Table Name: Poverty status in the past 12 months by sex by age\n",
        "#Indicator Output: Percent of Children Living Below the Poverty Line\n",
        "\n",
        "def hhchpov( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='004E|005E|006E|007E|008E|009E|018E|019E|020E|021E|022E|023E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                                              #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['hhchpovXX']  = ( df.filter(regex='004E|005E|006E|007E|008E|009E|018E|019E|020E|021E|022E|023E').sum(axis=1)\n",
        ") / ( df.filter(regex='004E|005E|006E|007E|008E|009E|018E|019E|020E|021E|022E|023E|033E|034E|035E|036E|037E|038E|047E|048E|049E|050E|051E|052E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZDy4uONlRIo"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create mhhi\n",
        "\n",
        "#Table ID: B19001\n",
        "#Table Name: Household income in the past 12 months\n",
        "#Indicator Output: Median Household Income\n",
        "\n",
        "def mhhi( df, columnsToInclude = [] ):\n",
        "  info = pd.DataFrame(\n",
        "      [\n",
        "          ['B19001_002E', 0, 10000],\n",
        "          ['B19001_003E', 10000, 4999 ],\n",
        "          ['B19001_004E', 15000, 4999 ],\n",
        "          ['B19001_005E', 20000, 4999 ],\n",
        "          ['B19001_006E', 25000, 4999 ],\n",
        "          ['B19001_007E', 30000, 4999],\n",
        "          ['B19001_008E', 35000, 4999 ],\n",
        "          ['B19001_009E', 40000, 4999 ],\n",
        "          ['B19001_010E', 45000, 4999 ],\n",
        "          ['B19001_011E', 50000, 9999 ],\n",
        "          ['B19001_012E', 60000, 14999],\n",
        "          ['B19001_013E', 75000, 24999 ],\n",
        "          ['B19001_014E', 100000, 24999 ],\n",
        "          ['B19001_015E', 125000, 24999 ],\n",
        "          ['B19001_016E', 150000, 49000 ],\n",
        "          ['B19001_017E', 200000, 1000000000000000000000000 ],\n",
        "\n",
        "      ],\n",
        "      columns=['variable', 'lower', 'range']\n",
        "  )\n",
        "\n",
        "  # Final Dataframe\n",
        "  data_table = pd.DataFrame()\n",
        "  for index, row in info.iterrows():\n",
        "      data_table = addKey(df, data_table, row['variable'])\n",
        "\n",
        "  # Accumulate totals accross the columns.\n",
        "  # Midpoint: Divide column index 16 (the last column) of the cumulative totals\n",
        "  temp_table = data_table.cumsum(axis=1)\n",
        "  temp_table['midpoint'] = (temp_table.iloc[ : , -1 :] /2) # V3\n",
        "  temp_table['midpoint_index'] = False\n",
        "  temp_table['midpoint_index_value'] = False # Z3\n",
        "  temp_table['midpoint_index_lower'] = False # W3\n",
        "  temp_table['midpoint_index_range'] = False # X3\n",
        "  temp_table['midpoint_index_minus_one_cumulative_sum'] = False #Y3\n",
        "  # step 3 - csa_agg3: get the midpoint index by \"when midpoint > agg[1] and midpoint <= agg[2] then 2\"\n",
        "\n",
        "  # Get CSA Midpoint Index using the breakpoints in our info table.\n",
        "  for index, row in temp_table.iterrows():\n",
        "      # Get the index of the first column where our midpoint is greater than the columns value.\n",
        "      midpoint = row['midpoint']\n",
        "      midpoint_index = 0\n",
        "      # For each column (except the 6 columns we just created)\n",
        "\n",
        "      # The tracts midpoint was < than the first tracts value at column 'B19001_002E_Total_Less_than_$10,000'\n",
        "      if( midpoint < int(row[0]) or row[-6] == False ):\n",
        "        temp_table.loc[ index, 'midpoint_index' ] = 0\n",
        "      else:\n",
        "        for column in row.iloc[:-6]:\n",
        "            # set midpoint index to the column with the highest value possible that is under midpoint\n",
        "            if( midpoint >= int(column) ):\n",
        "                if midpoint==False: print (str(column) + ' - ' + str(midpoint))\n",
        "                temp_table.loc[ index, 'midpoint_index' ] = midpoint_index +1\n",
        "            midpoint_index += 1\n",
        "\n",
        "  # temp_table = temp_table.drop('Unassigned--Jail')\n",
        "  for index, row in temp_table.iterrows():\n",
        "    temp_table.loc[ index, 'midpoint_index_value' ] = data_table.loc[ index, data_table.columns[row['midpoint_index']] ]\n",
        "    temp_table.loc[ index, 'midpoint_index_lower' ] = info.loc[ row['midpoint_index'] ]['lower']\n",
        "    temp_table.loc[ index, 'midpoint_index_range' ] = info.loc[ row['midpoint_index'] ]['range']\n",
        "    temp_table.loc[ index, 'midpoint_index_minus_one_cumulative_sum'] = row[ row['midpoint_index']-1 ]\n",
        "\n",
        "  # This is our denominator, which cant be negative.\n",
        "  for index, row in temp_table.iterrows():\n",
        "    if row['midpoint_index_value']==False:\n",
        "      temp_table.at[index, 'midpoint_index_value']=1;\n",
        "\n",
        "  #~~~~~~~~~~~~~~~\n",
        "  # Step 3)\n",
        "  # Run the Calculation\n",
        "  # Calculation = (midpoint_lower::numeric + (midpoint_range::numeric * ( (midpoint - midpoint_upto_agg) / nullif(midpoint_total,0)\n",
        "  # Calculation = W3+X3*((V3-Y3)/Z3)\n",
        "\n",
        "  # v3 -> 1 - midpoint of households  == sum / 2\n",
        "  # w3 -> 2 - lower limit of the income range containing the midpoint of the housing total == row[lower]\n",
        "  # x3 -> width of the interval containing the medium == row[range]\n",
        "  # z3 -> number of hhs within the interval containing the median == row[total]\n",
        "  # y3 -> 4 - cumulative frequency up to, but no==NOT including the median interval\n",
        "  #~~~~~~~~~~~~~~~\n",
        "\n",
        "  def finalCalc(x):\n",
        "    return ( x['midpoint_index_lower']+ x['midpoint_index_range']*(\n",
        "      ( x['midpoint']-x['midpoint_index_minus_one_cumulative_sum'])/ x['midpoint_index_value'] )\n",
        "    )\n",
        "\n",
        "  temp_table['mhhi'] = temp_table.apply(lambda x: finalCalc(x), axis=1)\n",
        "\n",
        "  temp_table[columnsToInclude] = df[columnsToInclude]\n",
        "\n",
        "  #Delete \"Unassigned--Jail\" row -> remove row where final is equal to zero\n",
        "  temp_table = temp_table[temp_table.mhhi != 0]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = temp_table.loc['Baltimore City'] #save Baltimore City row\n",
        "  temp_table = temp_table.drop(temp_table.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  temp_table.loc['Baltimore City'] = bc\n",
        "\n",
        "\n",
        "  return temp_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liwzwIlYlV3V"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create hh25inc\n",
        "\n",
        "#Table ID: B19001\n",
        "#Table Name: Household income in the past 12 months\n",
        "#Indicator Output: Percent of Households Earning Less than $25,000\n",
        "\n",
        "def hh25inc( df, columnsToInclude ):\n",
        "  df.columns = df.columns.str.replace(r\"[$]\", \"\")   #Remove dollar sign from column names. - Columns will give an error when this line isnt here.\n",
        "\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|002E|003E|004E|005E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                                              #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['hh25incXX]  = ( df.filter(regex='002E|003E|004E|005E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_hA_l7klVyN"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create hh40inc\n",
        "\n",
        "#Table ID: B19001\n",
        "#Table Name: Household income in the past 12 months\n",
        "#Indicator Output: Percent of Households Earning $25,000 to $40,000\n",
        "\n",
        "def hh40inc( df, columnsToInclude ):\n",
        "  df.columns = df.columns.str.replace(r\"[$]\", \"\")   #Remove dollar sign from column names. - Columns will give an error when this line isnt here.\n",
        "\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|006E|007E|008E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                                              #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['hh40incXX']  = ( df.filter(regex='006E|007E|008E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsEIyT_0lVs0"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create hh60inc\n",
        "\n",
        "#Table ID: B19001\n",
        "#Table Name: Household income in the past 12 months\n",
        "#Indicator Output: Percent of Households Earning $40,000 to $60,000\n",
        "\n",
        "def hh60inc( df, columnsToInclude ):\n",
        "  df.columns = df.columns.str.replace(r\"[$]\", \"\")   #Remove dollar sign from column names. - Columns will give an error when this line isnt here.\n",
        "\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|009E|010E|011E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                                              #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['hh60incXX']  = ( df.filter(regex='009E|010E|011E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yagEb2klVmb"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create hh75inc\n",
        "\n",
        "#Table ID: B19001\n",
        "#Table Name: Household income in the past 12 months\n",
        "#Indicator Output: Percent of Households Earning $60,000 to $75,000\n",
        "\n",
        "def hh75inc( df, columnsToInclude ):\n",
        "  df.columns = df.columns.str.replace(r\"[$]\", \"\")   #Remove dollar sign from column names. - Columns will give an error when this line isnt here.\n",
        "\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|012E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                                              #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['hh75incXX']  = ( df.filter(regex='012E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOJEUun9lVex"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create hhm75inc\n",
        "\n",
        "#Table ID: B19001\n",
        "#Table Name: Household income in the past 12 months\n",
        "#Indicator Output: Percent of Households Earning More than $75,000\n",
        "\n",
        "def hhm75inc( df, columnsToInclude ):\n",
        "  df.columns = df.columns.str.replace(r\"[$]\", \"\")   #Remove dollar sign from column names. - Columns will give an error when this line isnt here.\n",
        "\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|013E|014E|015E|016E|017E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                                              #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['hhm75incXX']  = ( df.filter(regex='013E|014E|015E|016E|017E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2b1EHBullXo"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create unempr\n",
        "\n",
        "#Table ID: B23001\n",
        "#Table Name: Sex by age by employment status for the population 16 years and over\n",
        "#Indicator Output: Unemployment Rate\n",
        "\n",
        "def unempr( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='006E|013E|020E|027E|034E|041E|048E|055E|062E|069E|092E|099E|106E|113E|120E|127E|134E|141E|148E|155E|008E|015E|022E|029E|036E|043E|050E|057E|064E|071E|094E|101E|108E|115E|122E|129E|136E|143E|150E|157E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                                                                                                                                                                                         #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['unemprXX']  = ( df.filter(regex='008E|015E|022E|029E|036E|043E|050E|057E|064E|071E|094E|101E|108E|115E|122E|129E|136E|143E|150E|157E').sum(axis=1)\n",
        ") / ( df.filter(regex='006E|013E|020E|027E|034E|041E|048E|055E|062E|069E|092E|099E|106E|113E|120E|127E|134E|141E|148E|155E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeI9Bw5tllRq"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create empl\n",
        "\n",
        "#Table ID: B23001\n",
        "#Table Name: Sex by age by employment status for the population 16 years and over\n",
        "#Indicator Output: Percent Population 16-64 Employed\n",
        "\n",
        "def empl( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='128E|135E|142E|149E|156E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                           #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['emplXX']  = ( df.filter(regex='007E|014E|021E|028E|035E|042E|049E|056E|063E|070E|093E|100E|107E|114E|121E|128E|135E|142E|149E|156E').sum(axis=1)\n",
        ") / ( df.filter(regex='003E|010E|017E|024E|031E|038E|045E|052E|059E|066E|089E|096E|103E|110E|117E|124E|131E|138E|145E|152E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RHfNIb_llJ8"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create nilf\n",
        "\n",
        "#Table ID: B23001\n",
        "#Table Name: Sex by age by employment status for the population 16 years and over\n",
        "#Indicator Output: Percent Population 16-64 Not in Labor Force\n",
        "\n",
        "def nilf( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='009E|016E|023E|030E|037E|044E|051E|058E|065E|072E|095E|102E|109E|116E|123E|130E|137E|144E|151E|158E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                                                                                      #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['nilfXX']  = ( df.filter(regex='009E|016E|023E|030E|037E|044E|051E|058E|065E|072E|095E|102E|109E|116E|123E|130E|137E|144E|151E|158E').sum(axis=1)\n",
        ") / ( df.filter(regex='003E|010E|017E|024E|031E|038E|045E|052E|059E|066E|089E|096E|103E|110E|117E|124E|131E|138E|145E|152E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtgC4KtOllEB"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create unempl\n",
        "\n",
        "#Table ID: B23001\n",
        "#Table Name: Sex by age by employment status for the population 16 years and over\n",
        "#Indicator Output: Percent Population 16-64 Unemployed and Looking for Work\n",
        "\n",
        "def unempl( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='008E|015E|022E|029E|036E|043E|050E|057E|064E|071E|094E|101E|108E|115E|122E|129E|136E|143E|150E|157E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                                                                                      #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['unemplXX']  = ( df.filter(regex='008E|015E|022E|029E|036E|043E|050E|057E|064E|071E|094E|101E|108E|115E|122E|129E|136E|143E|150E|157E').sum(axis=1)\n",
        ") / ( df.filter(regex='003E|010E|017E|024E|031E|038E|045E|052E|059E|066E|089E|096E|103E|110E|117E|124E|131E|138E|145E|152E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBjbqzVzlwoz"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create elheat\n",
        "\n",
        "#Table ID: B25040\n",
        "#Table Name: House heating fuel\n",
        "#Indicator Output: Percent of Residences Heated by Electricity\n",
        "\n",
        "def elheat( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='004E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)            #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['elheatXX']  = ( df.filter(regex='004E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOJHiwbslwkP"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create heatgas\n",
        "\n",
        "#Table ID: B25040\n",
        "#Table Name: House heating fuel\n",
        "#Indicator Output: Percent of Residences Heated by Utility Gas\n",
        "\n",
        "def heatgas( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='002E|001E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)            #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['heatgasXX']  = ( df.filter(regex='002E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "  \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYDbBDi_l2gJ"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create affordr\n",
        "\n",
        "#Table ID: B25070\n",
        "#Table Name: Gross rent as a percentage of household income in the past 12 months\n",
        "#Indicator Output: Affordability Index - Rent\n",
        "\n",
        "def affordr( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|007E|008E|009E|010E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)            #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['affordrXX']  = ( df.filter(regex='007E|008E|009E|010E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        " \n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB-Aq0Qxl5d4"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create affordm\n",
        "\n",
        "#Table ID: B25091\n",
        "#Table Name: Mortgage status by selected monthly owner costs as a percentage of household income in the past 12 months\n",
        "#Indicator Output: Affordability Index - Mortgage\n",
        "\n",
        "def affordm( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='002E|008E|009E|010E|011E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)            #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['affordmXX']  = ( df.filter(regex='008E|009E|010E|011E').sum(axis=1)\n",
        ") / ( df.filter(regex='002E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cRLChocl-5I"
      },
      "outputs": [],
      "source": [
        "#export \n",
        "#@title Run This Cell: Create nohhint\n",
        "\n",
        "#Table ID: B28002\n",
        "#Table Name: Presence and types of internet \n",
        "#Indicator Output: Percent of Households with No Internet at Home\n",
        "\n",
        "def nohhint( df, columnsToInclude ):\n",
        "  fi = pd.DataFrame()\n",
        "\n",
        "  columns = df.filter(regex='001E|002E|003E|004E|005E|006E|007E|O13E|tract').columns.values  #These are the columns that will show up in the final table (createAcsIndicators) \n",
        "  columns = numpy.append(columns, columnsToInclude)                                          #'tract' HAS to be there\n",
        "\n",
        "  for col in columns:\n",
        "      fi = addKey(df, fi, col)\n",
        "\n",
        "  fi['nohhintXX']  = ( df.filter(regex='013E').sum(axis=1)\n",
        ") / ( df.filter(regex='001E').sum(axis=1)) * 100\n",
        "\n",
        "  #Baltimore city is tract 10000. Since it has a tract number, it was added to the CSA csv file and the code calculates its 'final' value automatically.\n",
        "  #Do not remove any row before calculating Baltimore City's 'final,' or the value will be affected.\n",
        " \n",
        "  #Delete \"Unassigned--Jail\" row -> tract 100300\n",
        "  fi = fi[fi.tract != 100300]\n",
        "\n",
        "  #Move Baltimore City row to the bottom of the list.\n",
        "  bc = fi.loc['Baltimore City'] #save Baltimore City row\n",
        "  fi = fi.drop(fi.index[1]) #Remove baltimore City row from fi based on index location - its index location is 1 for both 2010 and 2020 indicators.\n",
        "  fi.loc['Baltimore City'] = bc\n",
        "\n",
        "  return fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvd1xZhdqOhZ"
      },
      "outputs": [],
      "source": [
        "#Example\n",
        "#create age 5 indicator for 2020\n",
        "tract = '*'\n",
        "county = '510'\n",
        "state = '24'\n",
        "\n",
        "tableId = 'B01001'\n",
        "year = '20'\n",
        "\n",
        "\n",
        "mergeUrl = 'https://raw.githubusercontent.com/gparedes10/2022VitalSigns/main/CSA_2010_and_2020.csv' #With the new file, use TRACTCE for both 2010 and 2020\n",
        "\n",
        "merge_left_col = 'tract'\n",
        "merge_right_col= 'TRACTCE'  #For 2020 use 'TRACTCE', for 2010 use 'TRACTCE10'\n",
        "merge_how = 'outer'\n",
        "\n",
        "\n",
        "method = age5\n",
        "aggMethod = 'sum'\n",
        "groupBy = 'CSA2020' #For 2020 use 'CSA2020', for 2010 use 'CSA2010'\n",
        "columnsToInclude = []\n",
        "indicator2020 = createAcsIndicator(state, county, tract, year, tableId,\n",
        "                    mergeUrl, merge_left_col, merge_right_col, merge_how, groupBy,\n",
        "                    aggMethod, method, columnsToInclude, finalFileName=False) #.tail()\n",
        "\n",
        "indicator2020.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RalPdYEMsOnh"
      },
      "outputs": [],
      "source": [
        "#Example\n",
        "#create racdiv indicator for 2020\n",
        "\n",
        "tableId = 'B02001'\n",
        "method = racdiv\n",
        "\n",
        "indicator2020 = createAcsIndicator(state, county, tract, year, tableId,\n",
        "                    mergeUrl, merge_left_col, merge_right_col, merge_how, groupBy,\n",
        "                    aggMethod, method, columnsToInclude, finalFileName=False)\n",
        "\n",
        "indicator2020.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "04_Create_Acs_Indicatorsipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
