{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yehMExS0fDKN"
   },
   "outputs": [],
   "source": [
    "# default_exp dhr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jLE_5-I9HzS"
   },
   "source": [
    "# VS SNAP/ TANF Data Intake and Operations\n",
    "\n",
    "> This notebook uses data to generate a portion of BNIA's Vital Signs report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSNOAJoTlQr0"
   },
   "source": [
    "This colab and more can be found at https://github.com/BNIA/vitalsigns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukxt0JZCsaxc"
   },
   "source": [
    "## Whats Inside?: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEdBnKIqli8m"
   },
   "source": [
    "### __The Guided Walkthrough__\n",
    "\n",
    "This notebook was made to create the following Housing Vital Signs Indicators:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5fgpFCgNkVt"
   },
   "source": [
    "#### __Indicators Used__\n",
    "\n",
    "- ✅ 106 - __TANF__ -  (TANF) Percent of Families Receiving TANF \n",
    "\n",
    "- ✅ ??? - __SNAP__ -  (TANF) Percent of Families Receiving TANF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6lDtbLS0a-C"
   },
   "source": [
    "#### __Datasets Used__\n",
    "\n",
    "- ✅ TANF.TANF_201X __(106-columns)__\n",
    "\n",
    "- ✅ SNAP.SNAP_201X __(???-columns)__\n",
    "\n",
    "\n",
    "❌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaPqfCBQscqe"
   },
   "outputs": [],
   "source": [
    "year = '19'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1RKv4DiMVwo"
   },
   "source": [
    "# Guided Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8-mgsByhrxG"
   },
   "source": [
    "## SETUP Enviornment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hHCW-qPMeH6"
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUvcamATFo4G"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install -U -q PyDrive\n",
    "! pip install geopy\n",
    "! pip install geopandas\n",
    "! pip install geoplot\n",
    "! pip install dataplay\n",
    "! pip install matplotlib\n",
    "! pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0vkoXtZRdJz"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! apt-get install build-dep python-psycopg2\n",
    "! apt-get install libpq-dev\n",
    "! apt-get install libspatialindex-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZ17xjOgR8vg"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install rtree\n",
    "!pip install dexplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9Mcvm-X0gdo"
   },
   "outputs": [],
   "source": [
    "from dataplay.geoms import workWithGeometryData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNOByHFKFo4m"
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# These imports will handle everything\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import psycopg2\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "# conda install -c conda-forge proj4\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkb\n",
    "from shapely.wkt import loads\n",
    "# https://pypi.org/project/geopy/\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# In case file is KML, enable support\n",
    "import fiona\n",
    "fiona.drvsupport.supported_drivers['kml'] = 'rw'\n",
    "fiona.drvsupport.supported_drivers['KML'] = 'rw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evj9GJLdSlxF"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTcb3bD84mSA"
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8tLzJzcMh74"
   },
   "source": [
    "### Configure Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OuH4mBeYCUqU"
   },
   "outputs": [],
   "source": [
    "# This will just beautify the output\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.precision', 2)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# pd.set_option('display.expand_frame_repr', False)\n",
    "# pd.set_option('display.precision', 2)\n",
    "# pd.reset_option('max_colwidth')\n",
    "pd.set_option('max_colwidth', 20)\n",
    "# pd.reset_option('max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-eNzM614b3K"
   },
   "source": [
    "## Prep Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3QiG_W4iDl7"
   },
   "source": [
    "#### TPOP CSA and Baltimore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlQvkkbaB0ZI"
   },
   "source": [
    "Get Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xeV9WHdOhBv"
   },
   "outputs": [],
   "source": [
    "#collapse_output\n",
    "#collapse_input\n",
    "csa = pd.read_csv('Families Denominator 2010 for TANF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyBS5PlHB1db"
   },
   "source": [
    "Get CSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oH6C5OecjBsy"
   },
   "outputs": [],
   "source": [
    "csa.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLpXYhJHB_rt"
   },
   "outputs": [],
   "source": [
    "csa.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUvs1JeqfcM6"
   },
   "source": [
    "### SNAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "af1RZX0qfcM6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas \n",
    "\n",
    "original = gpd.read_file(\"SNAP20\"+year+\"_CSACity.shp\", geometry='geometry');\n",
    "original.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vpbACsCfcM7"
   },
   "outputs": [],
   "source": [
    "original.rename(columns={ 'CSA':'CSA2010', 'BaltCity':'InBaltimore'}, inplace=True)\n",
    "df = original[ original['CSA2010'].notnull() | original['InBaltimore'].notnull()  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5Q-9xtifcM7"
   },
   "outputs": [],
   "source": [
    "print('After filtering records where a CSA or Baltimore geo-code match Exists')\n",
    "print( 'All rows Before Filter: ', original.shape[0] ) # rows, columns\n",
    "print( '# w BCity.isnull: ', df.InBaltimore.isnull().sum() ); bmorow = df[ df.CSA2010.isnull()  ].shape[0]\n",
    "print( '# w CSA2010.isnull: ', bmorow ); csarow = df[ df.CSA2010.notnull()  ].shape[0] \n",
    "print( '# w CSA2010.notnull: ', csarow ); \n",
    "print( '# rows After Filter: ', df.shape[0],'==',csarow,'+',bmorow,'==', csarow + bmorow); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQ-kENh2fcM7"
   },
   "outputs": [],
   "source": [
    "# add baltimore city\n",
    "df.CSA2010 = df.CSA2010.fillna('Baltimore City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dt6kK4NfcM7"
   },
   "outputs": [],
   "source": [
    "snapdf = df.copy()\n",
    "snapdf = snapdf[['CSA2010','InBaltimore']]\n",
    "snapdf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yN6qfuBLSeu"
   },
   "source": [
    "### TANF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNRLZHHh6KHN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas \n",
    "\n",
    "original = gpd.read_file(\"TANF20\"+year+\"_CSACity.shp\", geometry='geometry');\n",
    "original.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qiw4TZ8Msppg"
   },
   "outputs": [],
   "source": [
    "original.rename(columns={ 'CSA':'CSA2010', 'BaltCity':'InBaltimore'}, inplace=True)\n",
    "df = original[ original['CSA2010'].notnull() | original['InBaltimore'].notnull()  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVYhbJ5dsq0w"
   },
   "outputs": [],
   "source": [
    "print('After filtering records where a CSA or Baltimore geo-code match Exists')\n",
    "print( 'All rows Before Filter: ', original.shape[0] ) # rows, columns\n",
    "print( '# w BCity.isnull: ', df.InBaltimore.isnull().sum() ); bmorow = df[ df.CSA2010.isnull()  ].shape[0]\n",
    "print( '# w CSA2010.isnull: ', bmorow ); csarow = df[ df.CSA2010.notnull()  ].shape[0] \n",
    "print( '# w CSA2010.notnull: ', csarow ); \n",
    "print( '# rows After Filter: ', df.shape[0],'==',csarow,'+',bmorow,'==', csarow + bmorow); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MjNhXd2sviB"
   },
   "outputs": [],
   "source": [
    "# add baltimore city\n",
    "df.CSA2010 = df.CSA2010.fillna('Baltimore City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hkvEAYFsxdQ"
   },
   "outputs": [],
   "source": [
    "tandf = df.copy()\n",
    "tandf = tandf[['CSA2010','InBaltimore']]\n",
    "tandf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkWExWnIdybg"
   },
   "source": [
    "### 106 tanf - G\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-juyhG4SV2F"
   },
   "source": [
    "https://bniajfi.org/indicators/Children%20And%20Family%20Health/tanf\n",
    "\n",
    "Temporary Assistance for Needy Families (TANF) is a federal assistance program. The Act provides temporary financial assistance while aiming to get people off of that assistance, primarily through employment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bV457txgmnQ3"
   },
   "source": [
    "Percent of Families Receiving TANF\n",
    "\n",
    "Temporary Assistance for Needy Families (TANF) is a federal assistance program. The Act provides temporary financial assistance while aiming to get people off of that assistance, primarily through employment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECwOBei5Dhs8"
   },
   "outputs": [],
   "source": [
    "WORKS BUT NEEDS TO BE DIVIDED BY ? Normalization Source\n",
    "\n",
    "Population, # Houses, Avg HH Size\n",
    "\n",
    " We need the Family Households. From 2010. Census not ACS Data.\n",
    "\n",
    "\n",
    "df1['FamHHChildrenUnder18'] = df['B11005_003E_Total_Households_with_one_or_more_people_under_18_years_Family_households']\n",
    "df1['FamHHChildrenOver18'] = df['B11005_012E_Total_Households_with_no_people_under_18_years_Family_households']\n",
    "df1['FamHH'] = df1['FamHHChildrenOver18'] + df1['FamHHChildrenUnder18']\n",
    "\n",
    "FINAL NOTE ^ EVERYTHING ABOVE WAS WRITTEN PRIOR TO THIS NOTICE:\n",
    "\n",
    "Normalization Source Location V\n",
    "\n",
    "P:\\Project Libraries\\Vital Signs\\Vital Signs 12\\5 Chapter Health\n",
    "\n",
    "Cheryl found this source after Seema and I were struggling.\n",
    "\n",
    "It appears to be coming from the 2010 data. Not the 5 yr aggregates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEU90DHmpB03"
   },
   "outputs": [],
   "source": [
    "def tanf(df, csa, yr):\n",
    " \n",
    "  # tanf.drop( columns=['geometry', 'Shape__Length','Shape__Area'], inplace=True)\n",
    "  # Baltimoire has records not in the \n",
    "  tanf.at[55,'count']=tanf['count'].sum()\n",
    "  # Perform the calculation\n",
    "  tanf['106-tanf'+year] = tanf['count'] / tanf['FamHH_2010'] * 1000 \n",
    "  \"\"\"\n",
    "  compareYears = gpd.read_file(\"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Tanf/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\");\n",
    "  prevYear = 'tanf'+ str( int(year) - 1 )\n",
    "  if prevYear in compareYears.columns:\n",
    "    tanf = tanf.merge( compareYears[['CSA2010', prevYear]], left_on='CSA2010', right_on='CSA2010', how='outer' ) \n",
    "    tanf['change'] = tanf['106-tanf'+year] - tanf[ prevYear ]\n",
    "    tanf['percentChange'] = tanf['change' ] / tanf[ prevYear ] * 100\n",
    "    tanf['change'] = tanf['change'].apply(lambda x: \"{:.2f}\".format(x) )\n",
    "  \"\"\"\n",
    "  print( 'Records Matching Query: ', tanf.size / len(tanf.columns) )\n",
    "  return tanf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGyVVpdxf8QV"
   },
   "outputs": [],
   "source": [
    "fin = tanf(tandf, csa, year)\n",
    "fin.to_csv('106-tanf'+year+'.csv', index=False)\n",
    "fin.head(60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOvFks2znDbV"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def tanf(df, csa, yr):\n",
    "\n",
    "  # Create the Numerator\n",
    "  tanf = df.copy()\n",
    "  tanf['count'] = 1\n",
    "  tanf = tanf.groupby('CSA2010').sum(numeric_only=True)\n",
    "\n",
    "  # Make sure ALL csas and BaltimoreCity are included and sorted.\n",
    "  tanf = csa.merge( tanf, left_on='CSA2010', right_on='CSA2010', how='outer' )\n",
    "  # Baltimoire may have records not in the CSA (not actually the case right now but..)\n",
    "  tanf.at[55,'count']=tanf['count'].sum()\n",
    "  # Perform the calculation\n",
    "  tanf['106-tanf'+year] = tanf['count'] / tanf['FamHH_2010'] * 100\n",
    "\n",
    "  compareYears = gpd.read_file(\"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Tanf/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\");\n",
    "  prevYear = 'tanf'+ str( int(year) - 1 )\n",
    "  if prevYear in compareYears.columns:\n",
    "    tanf = tanf.merge( compareYears[['CSA2010', prevYear]], left_on='CSA2010', right_on='CSA2010', how='outer' )\n",
    "    tanf['change'] = tanf['106-tanf'+year] - tanf[ prevYear ]\n",
    "    tanf['percentChange'] = tanf['change' ] / tanf[ prevYear ] * 100\n",
    "    tanf['change'] = tanf['change'].apply(lambda x: \"{:.2f}\".format(x) )\n",
    "  print( 'Records Matching Query: ', tanf.size / len(tanf.columns) )\n",
    "  return tanf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGEOwAO8f64l"
   },
   "outputs": [],
   "source": [
    "fin = tanf(tandf, csa, year)\n",
    "fin.to_csv('106-tanf'+year+'.csv', index=False)\n",
    "fin.head(60) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbDahDICfgfz"
   },
   "source": [
    "### ??? SNAP - G\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozVrRMpDfgf0"
   },
   "source": [
    "[DESCRIPTION](https://bniajfi.org/indicators/Children%20And%20Family%20Health/SNAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IrJuiuTrfgf0"
   },
   "outputs": [],
   "source": [
    "def snap(df, csa, yr):\n",
    "  id = '107'\n",
    "  shortname = 'snap'\n",
    "\n",
    "  df['count'] = 1\n",
    "\n",
    "  # Create the Numerator \n",
    "  numer = df.copy() \n",
    "  \n",
    "  # Group by CSA\n",
    "  numer = numer.groupby('CSA2010').sum(numeric_only=True)  \n",
    "\n",
    "  # Make sure ALL csas and BaltimoreCity are included and sorted.\n",
    "  numer = csa.merge( numer, left_on='CSA2010', right_on='CSA2010', how='outer' ) \n",
    "  numer.drop( columns=['geometry', 'Shape__Length','Shape__Area'], inplace=True)  \n",
    "  \n",
    "  # Do after sortViaCsaMerge to get index right. False records would show underneath it but still get added to the sum.\n",
    "  numer.at[55,'count']=numer['count'].sum()\n",
    "\n",
    "  # Perform the calculation\n",
    "  numer[id+'-'+shortname+year] = numer['count'] / numer['tpop10'] * 100\n",
    "  netyet = \"\"\"\n",
    "  compareYears = gpd.read_file(\"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/\"+shortname+\"/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\");\n",
    "  prevYear = shortname+ str( int(year) - 1 )\n",
    "  if prevYear in compareYears.columns:\n",
    "    numer = numer.merge( compareYears[['CSA2010', prevYear]], left_on='CSA2010', right_on='CSA2010', how='outer' ) \n",
    "    numer['change'] = numer[id+'-'+shortname+year] - numer[ prevYear ]\n",
    "    numer['percentChange'] = numer['change' ] / numer[ prevYear ] * 100\n",
    "    numer['change'] = numer['change'].apply(lambda x: \"{:.2f}\".format(x) )\n",
    "    print( 'Records Matching Query: ', numer.size / len(numer.columns) )\n",
    "  \"\"\"\n",
    "  return numer.drop(columns=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zccoG0Z7f4yt"
   },
   "outputs": [],
   "source": [
    "fin = snap(snapdf, csa, year)\n",
    "fin.to_csv('107-snap'+year+'.csv', index=False)\n",
    "fin.head(6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srxeSXfOfgf1"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def snap(df, csa, yr):\n",
    "\n",
    "  # Create the Numerator\n",
    "  snap = df.copy()\n",
    "  snap['count'] = 1\n",
    "  snap = snap.groupby('CSA2010').sum(numeric_only=True)\n",
    "\n",
    "  # Make sure ALL csas and BaltimoreCity are included and sorted.\n",
    "  snap = csa.merge( snap, left_on='CSA2010', right_on='CSA2010', how='outer' )\n",
    "  # Baltimoire may have records not in the CSA (not actually the case right now but..)\n",
    "  snap.at[55,'count']=snap['count'].sum()\n",
    "  # Perform the calculation\n",
    "  snap['???-snap'+year] = snap['count']\n",
    "\n",
    "  compareYears = gpd.read_file(\"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Snap/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\");\n",
    "  prevYear = 'snap'+ str( int(year) - 1 )\n",
    "  if prevYear in compareYears.columns:\n",
    "    snap = snap.merge( compareYears[['CSA2010', prevYear]], left_on='CSA2010', right_on='CSA2010', how='outer' )\n",
    "    snap['change'] = snap['???-snap'+year] - snap[ prevYear ]\n",
    "    snap['percentChange'] = snap['change' ] / snap[ prevYear ] * 100\n",
    "    snap['change'] = snap['change'].apply(lambda x: \"{:.2f}\".format(x) )\n",
    "  print( 'Records Matching Query: ', snap.size / len(snap.columns) )\n",
    "  return snap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asKzmIxLe3pM"
   },
   "outputs": [],
   "source": [
    "fin = snap(tandf, csa, year)\n",
    "fin.to_csv('???-snap'+year+'.csv', index=False)\n",
    "fin.head(60) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMcD07mXT5AwDGv2k59ryLm",
   "collapsed_sections": [
    "0hHCW-qPMeH6",
    "q8tLzJzcMh74",
    "_3QiG_W4iDl7",
    "aUvs1JeqfcM6",
    "1yN6qfuBLSeu"
   ],
   "name": "DHR_SNAP_TANF_Create.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
