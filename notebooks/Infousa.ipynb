{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYIZI3R2hOyF"
   },
   "outputs": [],
   "source": [
    "# default_exp infousa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jLE_5-I9HzS"
   },
   "source": [
    "# Info-USA Intake and Operations\n",
    "\n",
    "> This notebook uses Info-USA data to generate a portion of BNIA's Vital Signs report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfwOgcYTs90R"
   },
   "source": [
    "Todo:  \n",
    "- Wrap as Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo5GYquJovv-"
   },
   "source": [
    "#### __Indicators Used__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-E-ddOFfIlq"
   },
   "source": [
    "- 131\tartbusXX\tArts and Culture\n",
    "- 132\tartempXX\tArts and Culture\n",
    "- 143\tnumbusXX\tWorkforce and Economic Development\n",
    "- 144\ttotempXX\tWorkforce and Economic Development\n",
    "- 145\tsmlbusXX\tWorkforce and Economic Development\n",
    "- 150\tbiz1_XX\tWorkforce and Economic Development\n",
    "- 151\tbiz2_XX\tWorkforce and Economic Development\n",
    "- 152\tbiz4_XX\tWorkforce and Economic Development\n",
    "- 157\tneiindXX\tWorkforce and Economic Development\n",
    "- 158\tneibusXX\tWorkforce and Economic Development\n",
    "- 159\tneiempXX\tWorkforce and Economic Development\n",
    "- 201\tcebusXX\tArts and Culture\n",
    "- 202\tceempXX\tArts and Culture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSNOAJoTlQr0"
   },
   "source": [
    "This colab and more can be found at https://github.com/BNIA/vitalsigns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ps_D-IEdhrxE"
   },
   "source": [
    "In the following example pulls point geodata from a Postgres database.\n",
    "\n",
    "We will pull the postgres point data in two manners. \n",
    "- SQL query where an SQL query uses ST_Transform(the_geom,4326) to transform the_geom's CRS from a DATABASE Binary encoding into standard Lat Long's\n",
    "- Using a plan SQL query and performing the conversion using gpd.io.sql.read_postgis() to pull the data in as 2248 and convert the CRS using .to_crs(epsg=4326)\n",
    "- These examples will not work in colabs as their is no local database to connect to and has been commented out for that reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxsOcEXqPKOl"
   },
   "outputs": [],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udCY18nqqkgp"
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "# This Notebook can be downloaded to connect to a database\n",
    "conn = psycopg2.connect(host='localhost', dbname='dbname', user='jfi', password='pass', port='port')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1edYngjqn8X"
   },
   "outputs": [],
   "source": [
    "CISJFIDB.cis.ubalt.edu -> 192.168.2.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cge3kx1um2ZQ"
   },
   "outputs": [],
   "source": [
    "# DB Import Method One\n",
    "sql1 = 'SELECT the_geom, gid, geogcode, ooi, address, addrtyp, city, block, lot, desclu, existing FROM housing.mdprop_2017v2 limit 100;'\n",
    "pointData = gpd.io.sql.read_postgis(sql1, conn, geom_col='the_geom', crs=2248)\n",
    "pointData = pointData.to_crs(epsg=4326)\n",
    "\n",
    "# DB Import Method Two\n",
    "sql2 = 'SELECT ST_Transform(the_geom,4326) as the_geom, ooi, desclu, address FROM housing.mdprop_2017v2;'\n",
    "pointData = gpd.GeoDataFrame.from_postgis(sql2, conn, geom_col='the_geom', crs=4326)\n",
    "pointData.head()\n",
    "pointData.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukxt0JZCsaxc"
   },
   "source": [
    "## About this Tutorial: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9Oix1S6gvm4"
   },
   "source": [
    "### Whats Inside?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEdBnKIqli8m"
   },
   "source": [
    "#### __The Tutorial__\n",
    "\n",
    "This notebook was made to create Vital Signs Indicators from an Info-USA geographic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK4HOnSWrpy-"
   },
   "source": [
    "#### __Objectives__\n",
    "\n",
    "- Reading in data (points/ geoms) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1RKv4DiMVwo"
   },
   "source": [
    "# Guided Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8-mgsByhrxG"
   },
   "source": [
    "## SETUP:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hHCW-qPMeH6"
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "WUvcamATFo4G"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install -U -q PyDrive\n",
    "! pip install geopy\n",
    "! pip install geopandas\n",
    "! pip install geoplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "p6ueNkdkJX6B"
   },
   "outputs": [],
   "source": [
    "!apt install libspatialindex-dev\n",
    "!pip install rtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nNOByHFKFo4m"
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# These imports will handle everything\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import psycopg2\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "# conda install -c conda-forge proj4\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkb\n",
    "from shapely.wkt import loads\n",
    "# https://pypi.org/project/geopy/\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# In case file is KML, enable support\n",
    "import fiona\n",
    "fiona.drvsupport.supported_drivers['kml'] = 'rw'\n",
    "fiona.drvsupport.supported_drivers['KML'] = 'rw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "evj9GJLdSlxF"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "uTcb3bD84mSA"
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8tLzJzcMh74"
   },
   "source": [
    "### Configure Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OuH4mBeYCUqU"
   },
   "outputs": [],
   "source": [
    "# This will just beautify the output\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.precision', 2)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# pd.set_option('display.expand_frame_repr', False)\n",
    "# pd.set_option('display.precision', 2)\n",
    "# pd.reset_option('max_colwidth')\n",
    "pd.set_option('max_colwidth', 20)\n",
    "# pd.reset_option('max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHAig4kSjgi8"
   },
   "source": [
    "### (Optional) GoogleDrive Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxGAFjlFzv35"
   },
   "outputs": [],
   "source": [
    "# (Optional) Run this cell to gain access to Google Drive (Colabs only) \n",
    "from google.colab import drive\n",
    "\n",
    "# Colabs operates in a virtualized enviornment\n",
    "# Colabs default directory is at ~/content.\n",
    "# We mount Drive into a temporary folder at '~/content/drive' \n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RaP90f0NsDxW"
   },
   "outputs": [],
   "source": [
    "cd drive/'My Drive'/colabs/DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9V-9jqrMx3Gr"
   },
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1WTHLwFsbl3"
   },
   "outputs": [],
   "source": [
    "cd postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obRWRvJRxPwz"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PF7NoFzRLshU"
   },
   "source": [
    "# Permits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3QiG_W4iDl7"
   },
   "source": [
    "#### TPOP CSA and Baltimore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlQvkkbaB0ZI"
   },
   "source": [
    "Get Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xeV9WHdOhBv"
   },
   "outputs": [],
   "source": [
    "#collapse_output\n",
    "#collapse_input\n",
    "csa = \"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Tpop/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\"\n",
    "csa = gpd.read_file(csa);\n",
    "csa.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyBS5PlHB1db"
   },
   "source": [
    "Get CSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FLpVhiPUAck"
   },
   "outputs": [],
   "source": [
    "url2 = \"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Tpop/FeatureServer/1/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\"\n",
    "csa2 = gpd.read_file(url2);\n",
    "csa2['CSA2010'] = csa2['City_1'] \n",
    "csa2['OBJECTID'] = 56 \n",
    "csa2 = csa2.drop(columns=['City_1'])\n",
    "csa2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiT-Pc1jgZJI"
   },
   "source": [
    "Append do no append Bcity. We put it on the Bottom of the df because when performing the ponp it returns only the last matching columns CSA Label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWZigszHUWm5"
   },
   "outputs": [],
   "source": [
    "# csa = pd.concat([csa2, csa], ignore_index=True)\n",
    "csa = csa.append(csa2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oH6C5OecjBsy"
   },
   "outputs": [],
   "source": [
    "csa.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLpXYhJHB_rt"
   },
   "outputs": [],
   "source": [
    "csa.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpZDcRVkk9SJ"
   },
   "outputs": [],
   "source": [
    "csa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3WNvZGQOTxw"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NozF5A2AL03d"
   },
   "outputs": [],
   "source": [
    "permits = gpd.read_file(\"Permits_2018.shp\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrE9nT8qVWlW"
   },
   "outputs": [],
   "source": [
    "permits.columns\n",
    "permits.crs\n",
    "permits.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekA3msZtM9Az"
   },
   "outputs": [],
   "source": [
    "# Convert to EPSG:4326\n",
    "permits = permits.to_crs(epsg=4326)\n",
    "permits.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJlWDqDaNDja"
   },
   "outputs": [],
   "source": [
    "# Convert Geom to Coords\n",
    "permits['x'] = permits.geometry.x\n",
    "permits['y'] = permits.geometry.y\n",
    "permits.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ht5jj0laT2e3"
   },
   "outputs": [],
   "source": [
    "permits = permits[ permits.geometry.y > 38 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHYcyhxeUMDS"
   },
   "outputs": [],
   "source": [
    "# Reference: All Points\n",
    "base = csa.plot(color='white', edgecolor='black')\n",
    "permits.plot(ax=base, marker='o', color='green', markersize=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1cUfBhYVKXA"
   },
   "outputs": [],
   "source": [
    "permits.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xY1mXy0A9CA_"
   },
   "outputs": [],
   "source": [
    "# Get CSA Labels for all Points.\n",
    "permitsCsa = getPolygonOnPoints(permits, csa, 'geometry', 'geometry', 'CSA2010' )\n",
    "# permitsCsa = permitsCsa.drop('geometry',axis=1)\n",
    "permitsCsa.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6_DjC2wT4Nl"
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIOlaXsSOh78"
   },
   "source": [
    "All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwUuhSiyOj40"
   },
   "outputs": [],
   "source": [
    "permitsAll = permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muxJghsFOj5J"
   },
   "outputs": [],
   "source": [
    "# Reference: All Points\n",
    "base = csa.plot(color='white', edgecolor='black')\n",
    "permitsAll.plot(ax=base, marker='o', color='green', markersize=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dk16SK99Nqk9"
   },
   "outputs": [],
   "source": [
    "permits = permitsAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnzmHoZEOOJz"
   },
   "outputs": [],
   "source": [
    "# y < 0\n",
    "permitsLessThanZero = permits[ permits.geometry.y < 0 ]\n",
    "print('Y<0: ', permitsLessThanZero.size, '\\n')\n",
    "permitsLessThanZero.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tV9v5r63M9Av"
   },
   "outputs": [],
   "source": [
    "# y > 0\n",
    "permitsGreaterThanZero = permits[ permits.geometry.y > 0 ]\n",
    "print('Y>0: ', permitsGreaterThanZero.size, '\\n')\n",
    "permitsGreaterThanZero.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05pzlYn0ROpV"
   },
   "outputs": [],
   "source": [
    "# 0 < y < 38\n",
    "permitsOver38 = permits[ permits.geometry.y < 38 ]\n",
    "permitsOver38 = permitsOver38[ permitsOver38.geometry.y > 0 ]\n",
    "print('0 < y < 38: ', permitsOver38.size, '\\n')\n",
    "permitsOver38.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6fJQNAHRVzY"
   },
   "outputs": [],
   "source": [
    "# y > 38\n",
    "permitsUnder38 = permits[ permits.geometry.y > 38 ]\n",
    "print('Y>38 Less than Zero: ', permitsUnder38.size, '\\n')\n",
    "permitsUnder38.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvc2gVcCT8Zp"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIJkutEqLTNS"
   },
   "source": [
    "# InfoUsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnwlAxsivf3x"
   },
   "source": [
    "#### Read in Data Directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpiJEs-TrczU"
   },
   "source": [
    "If you are using Geopandas, Direct imports only work with geojson and shape files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62HfFVJwUOVs"
   },
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"InfoUSA_2018.shp\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHqlHhuntnXv"
   },
   "outputs": [],
   "source": [
    "gdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOX7hnlhsGsK"
   },
   "outputs": [],
   "source": [
    "gdf['prim_naics_short'] = gdf.prim_naics.astype(str).str[:-2].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eySDKvAzM0nH"
   },
   "outputs": [],
   "source": [
    "# All but 'geometry', prim_naics, prim_sic, 'empl_size', 'X', 'Y'\n",
    "# ['coname', 'empl_rng', 'sales_vol', 'sales_rng', 'psic_dsc', 'scnd_sic1', 'scnd_dsc1', 'scnd_sic2', 'scnd_dsc2', \n",
    "#    'cr_a_score', 'cr_n_score', 'headqtr', 'first_year', 'sq_foot', 'firm_indv', 'fleetsize', 'specialty1', \n",
    "#    'specialty2', 'pnaics_dsc', 'acct_exp', 'ad_exp', 'offsup_exp', 'pay_exp', 'rent_exp', 'tech_exp', 'tele_exp',\n",
    "#    'ins_exp', 'legal_exp', 'pckg_exp', 'pirnt_exp', 'prof_exp', 'templbrexp', 'util_exp']\"\"\"\n",
    "gdf.columns\n",
    "\"\"\"\n",
    "gdf = gdf.drop(['Status', 'Score', 'Match_type', 'Side', 'Match_addr',\n",
    "       'ARC_Street', 'recorddate', 'recordobs', 'recordobs_', 'recordobs1',\n",
    "       'source', 'address', 'city', 'state', 'zipcode', 'mc_route',\n",
    "       'md_barcode', 'loc_addr', 'loc_city', 'loc_state', 'loc_zip',\n",
    "       'locbarcode', 'loc_route', 'county', 'phn_nbr', 'web_addr', 'last_name',\n",
    "       'first_name', 'ctct_title', 'ctct_prof', 'ctct_gen',\n",
    "       'headqtr', 'ofc_size', 'sq_foot', 'pub_pvt',\n",
    "       'ind_code', 'yellowpage', 'metro_area', 'infousa_id', 'latitude',\n",
    "       'longitude', 'match_code'], axis=1)\n",
    "\"\"\"\n",
    "\n",
    "gdf = gdf.drop(['Status', 'Score', 'Match_type', 'Side', 'Match_addr',\n",
    "       'ARC_Street', 'recorddate', 'recordobs', 'recordobs_', 'recordobs1',\n",
    "       'source', 'address', 'city', 'state', 'zipcode', 'mc_route',\n",
    "       'md_barcode', 'loc_addr', 'loc_city', 'loc_state', 'loc_zip',\n",
    "       'locbarcode', 'loc_route', 'county', 'phn_nbr', 'web_addr', 'last_name',\n",
    "       'first_name', 'ctct_title', 'ctct_prof', 'ctct_gen',\n",
    "       'sales_vol', 'sales_rng',\n",
    "       'scnd_sic1', 'scnd_dsc1', 'scnd_sic2', 'scnd_dsc2', 'cr_a_score',\n",
    "       'cr_n_score', 'headqtr', 'ofc_size', 'sq_foot',\n",
    "       'firm_indv', 'pub_pvt', 'fleetsize', 'specialty1', 'specialty2',\n",
    "       'ind_code', 'yellowpage', 'metro_area', 'infousa_id', 'latitude',\n",
    "       'longitude', 'match_code', 'acct_exp',\n",
    "       'ad_exp', 'offsup_exp', 'pay_exp', 'rent_exp', 'tech_exp', 'tele_exp',\n",
    "       'ins_exp', 'legal_exp', 'pckg_exp', 'pirnt_exp', 'prof_exp',\n",
    "       'templbrexp', 'util_exp'], axis=1)\n",
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFkzHpHfwzDJ"
   },
   "outputs": [],
   "source": [
    "gdf = gdf[ gdf['Y'] > 0 ]\n",
    "gdf = gdf.drop(['X','Y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofCJbjqgjJWw"
   },
   "outputs": [],
   "source": [
    "# Convert to EPSG:4326\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nhxei8Ori7eb"
   },
   "outputs": [],
   "source": [
    "# Reference: All Points\n",
    "base = csa.plot(color='white', edgecolor='black')\n",
    "gdf.plot(ax=base, marker='o', color='green', markersize=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKmvTx-jwzDV"
   },
   "outputs": [],
   "source": [
    "# Number of Records\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uPR8hzB88kA"
   },
   "outputs": [],
   "source": [
    "# Get CSA Labels for all Points.\n",
    "infoUsaCsa = getPolygonOnPoints(gdf, csa, 'geometry', 'geometry', 'CSA2010' )\n",
    "infoUsaCsa = infoUsaCsa.drop('geometry',axis=1)\n",
    "infoUsaCsa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0U2qGSm3Icz"
   },
   "outputs": [],
   "source": [
    "# Get counts of points in polygons. This function returns CSA's with a tally of points within it. \n",
    "infoUsaCsaTotals = getPointsInPolygons(gdf, csa, 'geometry', 'geometry')\n",
    "infoUsaCsaTotals = infoUsaCsaTotals.drop('geometry',axis=1)\n",
    "infoUsaCsaTotals = infoUsaCsaTotals.append({'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'pointsinpolygon': infoUsaCsaTotals['pointsinpolygon'].sum() } , ignore_index=True)\n",
    "\n",
    "infoUsaCsaTotals['numbus'] = infoUsaCsaTotals['pointsinpolygon']\n",
    "infoUsaCsaTotals = infoUsaCsaTotals.drop('pointsinpolygon',axis=1)\n",
    "infoUsaCsaTotals.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ep8Z9oXapAq5"
   },
   "outputs": [],
   "source": [
    "infoUsaCsaTotals.to_csv('numbus18.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QttF47Zn9lSs"
   },
   "source": [
    "##### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Q7_v74Su20h"
   },
   "outputs": [],
   "source": [
    "# Convert to EPSG:2248\n",
    "gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZZ4cOm-z97O"
   },
   "outputs": [],
   "source": [
    "# This is good data\n",
    "gdfg = gdf[ gdf['Y'] > 0 ]\n",
    "gdfg.head(1)\n",
    "gdfg.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8UDA10rzsr1"
   },
   "outputs": [],
   "source": [
    "# This is missing its GIS coordinates \n",
    "gdfz = gdf[ gdf['Y'] == 0 ]\n",
    "gdfz.head(1)\n",
    "gdfz.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPjVIt7gu1DP"
   },
   "outputs": [],
   "source": [
    "# Convert to EPSG:4326\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXFxT4mVwMmS"
   },
   "outputs": [],
   "source": [
    "gdfleft = gdf[ gdf['Y'] >= 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4rUz6-gvRca"
   },
   "outputs": [],
   "source": [
    "gdfleft.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBoNNyGR3VRx"
   },
   "outputs": [],
   "source": [
    "# Number of Records\n",
    "gdfleft.size/len(gdfleft.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HPqCNop9uJc"
   },
   "source": [
    "#### Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udEDRwTDUwy6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import folium\n",
    "import numpy as np\n",
    "# from folium import plugins\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylAXPEXw74dx"
   },
   "outputs": [],
   "source": [
    "def map_points(df, lat_col='latitude', lon_col='longitude', \n",
    "               popup='latitude', zoom_start=11, plot_points=False, \n",
    "               pt_radius=15, draw_heatmap=False, heat_map_weights_col=None, \n",
    "               heat_map_weights_normalize=True, heat_map_radius=15):\n",
    "    \"\"\"Creates a map given a dataframe of points. Can also produce a heatmap overlay\n",
    "\n",
    "    Arg:\n",
    "        df: dataframe containing points to maps\n",
    "        lat_col: Column containing latitude (string)\n",
    "        lon_col: Column containing longitude (string)\n",
    "        zoom_start: Integer representing the initial zoom of the map\n",
    "        plot_points: Add points to map (boolean)\n",
    "        pt_radius: Size of each point\n",
    "        draw_heatmap: Add heatmap to map (boolean)\n",
    "        heat_map_weights_col: Column containing heatmap weights\n",
    "        heat_map_weights_normalize: Normalize heatmap weights (boolean)\n",
    "        heat_map_radius: Size of heatmap point\n",
    "\n",
    "    Returns:\n",
    "        folium map object\n",
    "    \"\"\"\n",
    "\n",
    "    ## center map in the middle of points center in\n",
    "    if (type(gdfleft) == GeoDataFrame):\n",
    "      middle_lat = df['geometry'].y.median()\n",
    "      middle_lon = df['geometry'].x.median()\n",
    "    else:\n",
    "      middle_lat = df[lat_col].median()\n",
    "      middle_lon = df[lon_col].median()\n",
    "    print(middle_lat, middle_lon)\n",
    "\n",
    "    # https://python-visualization.github.io/folium/modules.html\n",
    "    curr_map = folium.Map(location=[middle_lat, middle_lon],\n",
    "                          width=750, height=500,\n",
    "                          zoom_start=zoom_start)\n",
    "\n",
    "    # add points to map\n",
    "    if plot_points:\n",
    "        for _, row in df.iterrows():\n",
    "            if (type(gdfleft) == GeoDataFrame): \n",
    "              coords = [row['geometry'].y, row['geometry'].x]\n",
    "            else: \n",
    "              coords = [row[lat_col], row[lon_col]] \n",
    "\n",
    "            folium.CircleMarker( coords,\n",
    "              radius=pt_radius,\n",
    "              popup=row[popup],\n",
    "              fill_color=\"#3db7e4\", # divvy color\n",
    "            ).add_to(curr_map)\n",
    "\n",
    "    # add heatmap\n",
    "    if draw_heatmap:\n",
    "        # convert to (n, 2) or (n, 3) matrix format\n",
    "        if heat_map_weights_col is None:\n",
    "          cols_to_pull = [lat_col, lon_col]\n",
    "        elif heat_map_weights_normalize: # if we have to normalize\n",
    "          df[heat_map_weights_col] = \\\n",
    "            df[heat_map_weights_col] / df[heat_map_weights_col].sum()\n",
    "\n",
    "          cols_to_pull = [lat_col, lon_col, heat_map_weights_col]\n",
    "\n",
    "        if (type(gdfleft) == GeoDataFrame):\n",
    "          stations = gdfleft.head(1000)['geometry'].apply(lambda p: [p.y,p.x])\n",
    "        else:\n",
    "          stations = df[cols_to_pull].values\n",
    "        curr_map.add_children(plugins.HeatMap(stations, radius=heat_map_radius))\n",
    "\n",
    "    return curr_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_24xFWEKt_g8"
   },
   "source": [
    "###### Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UckPU3CrkUDv"
   },
   "outputs": [],
   "source": [
    "gdfleft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7saIfw65mem"
   },
   "source": [
    "https://towardsdatascience.com/interactive-controls-for-jupyter-notebooks-f5c94829aee6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tzc4RUf4b8o"
   },
   "outputs": [],
   "source": [
    "# Points\n",
    "@interact\n",
    "def show_articles_more_than(column= gdfleft.columns ):\n",
    "    return gdfleft.plot( column=column, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNJF9E4NCrUk"
   },
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "@interact\n",
    "def show_articles_more_than(column= gdfleft.columns ):\n",
    "    return map_points(gdfleft.head(500), lat_col='Y', lon_col='X', popup=column, zoom_start=11, plot_points=False, pt_radius=15, \n",
    "                      draw_heatmap=column, heat_map_weights_col=None, heat_map_weights_normalize=True, heat_map_radius=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uV2EmcYEb_Kx"
   },
   "outputs": [],
   "source": [
    "# MarkerCluster.ipynb\n",
    "# https://github.com/python-visualization/folium/blob/master/examples/MarkerCluster.ipynb\n",
    "from folium.plugins import MarkerCluster\n",
    "m = folium.Map(location=[39.28759453969165, -76.61278931706487], zoom_start=12)\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "stations = gdfleft.head(1000)['geometry'].apply(lambda p: folium.Marker( location=[p.y,p.x], popup='Add popup text here.', icon=None ).add_to(marker_cluster) )\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewu7p1Lv_Vrl"
   },
   "outputs": [],
   "source": [
    "6# Interact with specification of arguments\n",
    "@interact\n",
    "def show_articles_more_than(column = country_peripheries.columns ): # gdfleft.columns ):\n",
    "\n",
    "    return gpd.overlay(csa,  gdfleft.head(), how='difference').plot(alpha=0.5, edgecolor='k', column=column, cmap='magma', legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ_hg-Xb98mm"
   },
   "source": [
    "##### Choropleth Timeslider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSC2VGL308Ys"
   },
   "outputs": [],
   "source": [
    "first_year\n",
    "import os\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from branca.colormap import linear\n",
    "from folium.plugins import TimeSliderChoropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UtzEFBUb93q"
   },
   "outputs": [],
   "source": [
    "#TimeSliderChoropleth.ipynb\n",
    "# https://github.com/python-visualization/folium/blob/master/examples/TimeSliderChoropleth.ipynb\n",
    "gdf = csa.copy()\n",
    "%matplotlib inline\n",
    "ax = gdf.plot(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ4oWA345Mr2"
   },
   "source": [
    "To simulate that data is sampled at different times we random sample data for n_periods rows of data. __Note__ that the geodata and random sampled data is linked through the feature_id, which is the index of the GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwMqkY3b2rbU"
   },
   "outputs": [],
   "source": [
    "periods = 10\n",
    "datetime_index = pd.date_range('2010', periods=periods, freq='Y')\n",
    "dt_index_epochs = ( datetime_index.astype(int) ).astype('U10')\n",
    "datetime_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tsTlT_M5fuE"
   },
   "outputs": [],
   "source": [
    "# Style each boundry with randomness.\n",
    "for country in gdf.index:\n",
    "    df = pd.DataFrame(\n",
    "        {'color': np.random.normal(size=periods),\n",
    "         'opacity':  [1,2,3,4,5,6,7,8,9,1] },\n",
    "        index=dt_index_epochs\n",
    "    )\n",
    "    df = df.cumsum()\n",
    "    styledata[country] = df\n",
    "ax = df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0NLNCxlBgsc"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W8wjNj251X6"
   },
   "source": [
    "We see that we generated two series of data for each country; one for color and one for opacity. Let's plot them to see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdMsU-Ep2vYy"
   },
   "outputs": [],
   "source": [
    "max_color, min_color, max_opacity, min_opacity = 0, 0, 0, 0\n",
    "for country, data in styledata.items():\n",
    "    max_color = max(max_color, data['color'].max())\n",
    "    min_color = min(max_color, data['color'].min())\n",
    "    max_opacity = max(max_color, data['opacity'].max())\n",
    "    max_opacity = min(max_color, data['opacity'].max())\n",
    "linear.PuRd_09.scale(min_color, max_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr9M-4bB6CNC"
   },
   "source": [
    "We want to map the column named color to a hex color. To do this we use a normal colormap. To create the colormap, we calculate the maximum and minimum values over all the timeseries. We also need the max/min of the opacity column, so that we can map that column into a range [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUkPHjn_6D4B"
   },
   "outputs": [],
   "source": [
    "max_color, min_color, max_opacity, min_opacity = 0, 0, 0, 0\n",
    "for country, data in styledata.items():\n",
    "    max_color = max(max_color, data['color'].max())\n",
    "    min_color = min(max_color, data['color'].min())\n",
    "    max_opacity = max(max_color, data['opacity'].max())\n",
    "    max_opacity = min(max_color, data['opacity'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJ-JgfeG6Gpa"
   },
   "outputs": [],
   "source": [
    "from branca.colormap import linear\n",
    "cmap = linear.PuRd_09.scale(min_color, max_color)\n",
    "def norm(x): return (x - x.min()) / (x.max() - x.min())\n",
    "for country, data in styledata.items():\n",
    "    data['color'] = data['color'].apply(cmap)\n",
    "    data['opacity'] = norm(data['opacity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjspPfdA6Lt7"
   },
   "outputs": [],
   "source": [
    "styledata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9vDKioT6OlQ"
   },
   "source": [
    "Finally we use pd.DataFrame.to_dict() to convert each dataframe into a dictionary, and place each of these in a map from country id to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyuDTeBy6SWZ"
   },
   "outputs": [],
   "source": [
    "from folium.plugins import TimeSliderChoropleth\n",
    "m = folium.Map([39.28759453969165, -76.61278931706487], zoom_start=12)\n",
    "g = TimeSliderChoropleth(\n",
    "    gdf.to_json(),\n",
    "    styledict={\n",
    "      str(country): data.to_dict(orient='index') for\n",
    "      country, data in styledata.items()\n",
    "    }\n",
    ").add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yewjZN1NfySB"
   },
   "source": [
    "##### Points and Polygons. Difference, Intersection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KXw1pU42JbP"
   },
   "outputs": [],
   "source": [
    "csa = gpd.read_file(\"https://opendata.arcgis.com/datasets/b738a8587b6d479a8824d937892701d8_0.geojson\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nktZXF1tNGx"
   },
   "outputs": [],
   "source": [
    "from geopandas import GeoSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mv3D9a6LrZoy"
   },
   "outputs": [],
   "source": [
    "# The hard way\n",
    "points = list()\n",
    "for _, row in gdfleft.iterrows(): points.append( Point( row['geometry'].x, row['geometry'].y ) )\n",
    "points = GeoSeries( points )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCBAfE9XtSRj"
   },
   "outputs": [],
   "source": [
    "# The easy way\n",
    "circles = gdfleft.geometry.buffer(.001)\n",
    "circles.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3mQWHOlufep"
   },
   "outputs": [],
   "source": [
    "# collapse these circles into a single shapely MultiPolygon geometry withmp \n",
    "mp = circles.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWEksNmHqpyX"
   },
   "outputs": [],
   "source": [
    "csa['geometry'].intersection( mp ).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEnRAu3OuqRT"
   },
   "outputs": [],
   "source": [
    "csa['geometry'].difference( mp ).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xW6tgOuu49G"
   },
   "outputs": [],
   "source": [
    "mp.area / newcsa.geometry.area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7JsfeIo5yMb"
   },
   "source": [
    "##### Geometric Manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_j9u4slzmvE"
   },
   "outputs": [],
   "source": [
    "# Draw tool. Create and export your own boundaries\n",
    "m = folium.Map()\n",
    "draw = Draw()\n",
    "draw.add_to(m)\n",
    "m = folium.Map(location=[-27.23, -48.36], zoom_start=12)\n",
    "draw = Draw(export=True)\n",
    "draw.add_to(m)\n",
    "# m.save(os.path.join('results', 'Draw1.html'))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "de5ezfHYx6aT"
   },
   "outputs": [],
   "source": [
    "newcsa = csa.copy()\n",
    "newcsa['geometry'] = csa.boundary\n",
    "newcsa.plot(column='CSA2010' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEq01uKfyK1s"
   },
   "outputs": [],
   "source": [
    "newcsa = csa.copy()\n",
    "newcsa['geometry'] = csa.envelope\n",
    "newcsa.plot(column='CSA2010' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRspS4kMnj2N"
   },
   "outputs": [],
   "source": [
    "newcsa = csa.copy()\n",
    "newcsa['geometry'] = csa.convex_hull\n",
    "newcsa.plot(column='CSA2010' )\n",
    "# , cmap='OrRd', scheme='quantiles'\n",
    "# newcsa.boundary.plot(  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0X5mUnEyUvy"
   },
   "outputs": [],
   "source": [
    "newcsa = csa.copy()\n",
    "newcsa['geometry'] = csa.simplify(30)\n",
    "newcsa.plot(column='CSA2010' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vC4uIfFKyi5i"
   },
   "outputs": [],
   "source": [
    "newcsa = csa.copy()\n",
    "newcsa['geometry'] = csa.buffer(0.01)\n",
    "newcsa.plot(column='CSA2010' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgxZwijIywSF"
   },
   "outputs": [],
   "source": [
    "newcsa = csa.copy()\n",
    "newcsa['geometry'] = csa.rotate(30)\n",
    "newcsa.plot(column='CSA2010' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSw5jfeTyxve"
   },
   "outputs": [],
   "source": [
    "newcsa = csa.copy()\n",
    "newcsa['geometry'] = csa.scale(3, 2)\n",
    "newcsa.plot(column='CSA2010' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCumA-O-y6HO"
   },
   "outputs": [],
   "source": [
    "newcsa = csa.copy()\n",
    "newcsa['geometry'] = csa.skew(1, 10)\n",
    "newcsa.plot(column='CSA2010' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NbV6BF3xa_X"
   },
   "source": [
    "### Points in CSAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7w5mqmePLq0"
   },
   "outputs": [],
   "source": [
    "# Reference: All Points\n",
    "base = csa.plot(color='white', edgecolor='black')\n",
    "infoUsaCsa.plot(ax=base, marker='o', color='green', markersize=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLvWN6jVvGZ3"
   },
   "source": [
    "generate a GeoSeries containing points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guU5qArau_Yb"
   },
   "source": [
    "Note that this can be simplified a bit, since geometry is available as an attribute on a GeoDataFrame, and the intersection and difference methods are implemented with the “&” and “-” operators, respectively. For example, the latter could have been expressed simply as boros.geometry - mp.\n",
    "\n",
    "It’s easy to do things like calculate the fractional area in each borough that are in the holes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vPR7m96RZnv"
   },
   "outputs": [],
   "source": [
    " gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_joN9dTXlfF"
   },
   "outputs": [],
   "source": [
    "csa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVHq1QvpjBRv"
   },
   "outputs": [],
   "source": [
    "gdfleft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWAcaXgOCLU2"
   },
   "outputs": [],
   "source": [
    "gdfleft[ gdfleft.coname == 'Us Army Corps Of Engineers' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_nX_nghI2vb"
   },
   "outputs": [],
   "source": [
    "gdf = gdfleft.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKIeUbY2Il1y"
   },
   "outputs": [],
   "source": [
    "csaUrl = \"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Tpop/FeatureServer/0/query?where=1%3D1&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=none&distance=0.0&units=esriSRUnit_Meter&returnGeodetic=false&outFields=tpop10%2C+CSA2010&returnGeometry=true&returnCentroid=false&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pgeojson&token=\"\n",
    "csa = gpd.read_file(csaUrl);\n",
    "csa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9JpYDIngTfd"
   },
   "source": [
    "# Arts and **Culture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3GUKNSlH5GA"
   },
   "source": [
    "##### 131 Artbus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFNzUVb5ZV-F"
   },
   "source": [
    "The rate of businesses (both for-profit and non-profit) that are directly related to arts and culture per 1,000 residents. \n",
    "Arts-related businesses are defined as belonging to industries that allow for the consumption and enjoyment of arts and culture. \n",
    "\n",
    "The following industries are identified by their primary NAICS code:\n",
    "music, literary, and visual arts-related retail/supplies (451140, 451211, 451220); \n",
    "art dealers (453920, 453920); libraries (519120); motion picture and film (521310, 532230); art schools (611610); \n",
    "performing arts (711110, 711120, 711130, 711190); independent artists, writers, and performers (711510); \n",
    "museums (712110); historical sites (712120); and zoos, gardens and nature parks (712130, 712190).\n",
    "\n",
    "The following industries are identified by their primary SIC codes: \n",
    "designers (152106); art publishers (274101), \n",
    "music, literary, and visual arts-related retail/supplies (393101, 519202, 573608, 573609, 593201, 594201, 594205, 594501, 594520, 594601, 599965, 769969); \n",
    "art galleries, dealers, and consultants (599969, 599988, 599989); photography (722121); calligraphers (733607); embroidery (738942); theatres (783201, 792207); \n",
    "theatrical support (792211, 792212); musical and live entertainment (792903, 792905, 792906, 792908, 792917, 792918, 792927); parks (799951); \n",
    "art and music instruction (804958, 829915, 829919); libraries (823111); museums (841201); arts organizations (841202); zoos (842201); writers (899903); \n",
    "visual artists (899907, 899912); art restoring (899908); and music arrangers and composers (899921)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dB2IyUhiaR2s"
   },
   "outputs": [],
   "source": [
    "naicCodes =  [451140, 451211, 451220, 453920, 519120, 521310, 532230, 611610, 711110, 711120, \n",
    "              711130, 711190, 711510, 712110, 712120, 712130, 712190]\n",
    "\n",
    "sicCodes = [152106, 274101, 393101, 519202, 573608, 573609, 593201, 594201, 594205, 594501, \n",
    "            594520, 594601, 599965, 769969, 599969, 599988, 599989, 722121, 733607, 738942, \n",
    "            783201, 792207, 792211, 792212, 792903, 792905, 792906, 792908, 792917, 792918, \n",
    "            792927, 799951, 804958, 829915, 829919, 823111, 841201, 841202, 842201, 899903, \n",
    "            899907, 899912, 899908, 899921]\n",
    "\n",
    "artbus = infoUsaCsa[ ( infoUsaCsa['prim_naics_short'].isin( naicCodes ) ) | ( infoUsaCsa.prim_sic.isin( sicCodes ) ) ]\n",
    "\n",
    "# Aggregate Numeric Values by Sum \n",
    "artbus = artbus[ ['CSA2010'] ]\n",
    "artbus['artbusCount'] = 1\n",
    "artbus = artbus.groupby('CSA2010').sum(numeric_only=True) \n",
    "artbus = artbus.merge( csa[ ['CSA2010','tpop10'] ], left_on='CSA2010', right_on='CSA2010' ) \n",
    "artbus = artbus.append({'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'artbusCount': artbus['artbusCount'].sum() } , ignore_index=True)\n",
    "\n",
    "# Create the Indicator\n",
    "artbus['artbus'] = artbus['artbusCount'] * 1000 / artbus['tpop10']\n",
    "\n",
    "artbus.to_csv('artbus18.csv', index=False)\n",
    "\n",
    "artbus.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WR56EX8wlWDT"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def artbus(bounds, df):\n",
    "  \"\"\"\n",
    "  131 - artbus\n",
    "\n",
    "  with tbl AS (\n",
    "    select (sum(\n",
    "      case \n",
    "      when ((prim_naics::text like any (select * from vital_signs.artbus_naics_vals) \n",
    "        or prim_sic::text like any (select * from vital_signs.artbus_sic_vals)) and coname != 'Us Army Corps Of Engineers')\n",
    "      then 1\n",
    "      else 0\n",
    "      end)::numeric \n",
    "    * 1000 )/the_pop as result, csa\n",
    "    from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2016', 'gid', 'the_geom') a\n",
    "    left join economy.infousa_2016 b on a.gid = b.gid\n",
    "    group by csa, the_pop\n",
    "    )\n",
    "    update vital_signs.data\n",
    "    set artbus = result from tbl where data.csa = tbl.csa and data_year = '2016';\n",
    "  \"\"\"\n",
    "  \n",
    "  # Filter rows\n",
    "  # https://www.naics.com/code-search/?sictrms=art\n",
    "  # https://www.naics.com/code-search/?naicstrms=art\n",
    "  naicCodes =  [451140, 451211, 451220, 453920, 519120, 521310, 532230, 611610, 711110, 711120, \n",
    "                711130, 711190, 711510, 712110, 712120, 712130, 712190]\n",
    "  \n",
    "  sicCodes = [152106, 274101, 393101, 519202, 573608, 573609, 593201, 594201, 594205, 594501, \n",
    "              594520, 594601, 599965, 769969, 599969, 599988, 599989, 722121, 733607, 738942, \n",
    "              783201, 792207, 792211, 792212, 792903, 792905, 792906, 792908, 792917, 792918, \n",
    "              792927, 799951, 804958, 829915, 829919, 823111, 841201, 841202, 842201, 899903, \n",
    "              899907, 899912, 899908, 899921]\n",
    "\n",
    "  # sum rows: increment by 1 if row = () else 0\n",
    "  # (prim_naics: like any [ ] or prim_sic like any []) and coname != 'Us Army Corps Of Engineers')\n",
    "  df['prim_naics_short'] = df.prim_naics.astype(str).str[:-2].astype(np.int64)\n",
    "  # filtered_df = df[ ( df['prim_naics_short'].isin( naicCodes ) ) | ( df.prim_sic.isin( sicCodes ) ) ] #& df.coname != 'Us Army Corps Of Engineers' ]\n",
    "\n",
    "  # Point in Polygons\n",
    "  csasWithCounts = getPointsInPolygons(filtered_df, bounds, 'geometry', 'geometry')\n",
    "\n",
    "  # Aggregate by CSA\n",
    "  # Group By CSA so that they may be opperated on\n",
    "  groupedCounts = csasWithCounts.groupby('CSA2010')\n",
    "  # Aggregate Numeric Values by Sum \n",
    "  groupedCounts = groupedCounts.sum(numeric_only=True)\n",
    "  # groupedCounts = groupedCounts.merge(bounds, left_on='CSA2010', right_on='CSA2010')\n",
    "  print(groupedCounts.columns)\n",
    "  groupedCounts['numOfBusinesses'] = groupedCounts['pointsinpolygon']\n",
    "  groupedCounts = groupedCounts.drop(['pointsinpolygon'], axis=1)\n",
    "  # groupedCounts = groupedCounts.append({'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'numOfBusinesses': groupedCounts['numOfBusinesses'].sum() } , ignore_index=True)\n",
    "  print({'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'numOfBusinesses': groupedCounts['numOfBusinesses'].sum() })\n",
    "  groupedCounts['artbus'] = groupedCounts['numOfBusinesses'] * 1000 / groupedCounts['tpop10']\n",
    "  return groupedCounts\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSmwRkm2Cfzh"
   },
   "outputs": [],
   "source": [
    "artbus_vals = artbus(csaComms, gdfleft)\n",
    "artbus_vals.to_csv('artbus18.csv')\n",
    "artbus_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TS3Nquuc0ixL"
   },
   "source": [
    "##### 132 Artemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5YQ5XPmdFCB"
   },
   "outputs": [],
   "source": [
    "naicCodes =  [451140, 451211, 451220, 453920, 519120, 521310, 532230, 611610, 711110, 711120, \n",
    "              711130, 711190, 711510, 712110, 712120, 712130, 712190]\n",
    "\n",
    "sicCodes = [152106, 274101, 393101, 519202, 573608, 573609, 593201, 594201, 594205, 594501, \n",
    "            594520, 594601, 599965, 769969, 599969, 599988, 599989, 722121, 733607, 738942, \n",
    "            783201, 792207, 792211, 792212, 792903, 792905, 792906, 792908, 792917, 792918, \n",
    "            792927, 799951, 804958, 829915, 829919, 823111, 841201, 841202, 842201, 899903, \n",
    "            899907, 899912, 899908, 899921]\n",
    "\n",
    "artemp = infoUsaCsa[ ( infoUsaCsa['prim_naics_short'].isin( naicCodes ) ) | ( infoUsaCsa.prim_sic.isin( sicCodes ) ) ]\n",
    "\n",
    "# Aggregate Numeric Values by Sum \n",
    "artemp = artemp[ ['CSA2010', 'empl_size'] ]\n",
    "artemp = artemp.groupby('CSA2010').sum(numeric_only=True) \n",
    "artemp = artemp.merge( csa[ ['CSA2010','tpop10'] ], left_on='CSA2010', right_on='CSA2010' ) \n",
    "artemp = artemp.append({'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'empl_size': artemp['empl_size'].sum() } , ignore_index=True)\n",
    "\n",
    "# Create the Indicator\n",
    "artemp['artemp'] = artemp['empl_size']\n",
    "artemp = artemp.drop('empl_size', axis=1)\n",
    "\n",
    "artemp.to_csv('artemp18.csv', index=False)\n",
    "\n",
    "artemp.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2W5S-q8wHQrN"
   },
   "outputs": [],
   "source": [
    "def artemp(bounds, df, pop):\n",
    "  \"\"\"\n",
    "  132 - artemp\n",
    "\n",
    "  with tbl AS (\n",
    "    select (sum(\n",
    "        case \n",
    "        when ((prim_naics::text like any (select * from vital_signs.artbus_naics_vals) \n",
    "        or prim_sic::text like any (select * from vital_signs.artbus_sic_vals)) and coname != 'Us Army Corps Of Engineers')\n",
    "        then empl_size\n",
    "        else 0\n",
    "        end) \n",
    "      ) as result, csa\n",
    "      from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2017', 'gid', 'the_geom') a\n",
    "      left join economy.infousa_2017 b on a.gid = b.gid\n",
    "      group by csa, the_pop\n",
    "    )\n",
    "  select * from tbl where 1 = 1 ORDER BY csa ASC;\n",
    "  \"\"\"\n",
    "  # Filter rows\n",
    "  # https://www.naics.com/code-search/?sictrms=art\n",
    "  # https://www.naics.com/code-search/?naicstrms=art\n",
    "  naicCodes =  [451140, 451211, 451220, 453920, 519120, 521310, 532230, 611610, 711110, 711120, \n",
    "                711130, 711190, 711510, 712110, 712120, 712130, 712190]\n",
    "  \n",
    "  sicCodes = [152106, 274101, 393101, 519202, 573608, 573609, 593201, 594201, 594205, 594501, \n",
    "              594520, 594601, 599965, 769969, 599969, 599988, 599989, 722121, 733607, 738942, \n",
    "              783201, 792207, 792211, 792212, 792903, 792905, 792906, 792908, 792917, 792918, \n",
    "              792927, 799951, 804958, 829915, 829919, 823111, 841201, 841202, 842201, 899903, \n",
    "              899907, 899912, 899908, 899921]\n",
    "\n",
    "  # sum rows: increment by 1 if row = () else 0\n",
    "  # (prim_naics: like any [ ] or prim_sic like any []) and coname != 'Us Army Corps Of Engineers')\n",
    "  df['numOfBusinesses'] = 1\n",
    "  df['prim_naics_short'] = df.prim_naics.astype(str).str[:-2].astype(np.int64)\n",
    "  filtered_df = df[ ( df['prim_naics_short'].isin( naicCodes ) | df.prim_sic.isin( sicCodes ) ) ] #& df.coname != 'Us Army Corps Of Engineers' ]\n",
    "  filtered_df.to_csv('artbus_filtered_points.csv')\n",
    "  \n",
    "  # Point in Polygons\n",
    "  csasWithCounts = getPolygonOnPoints(filtered_df, bounds, 'geometry', 'geometry', 'CSA2010')\n",
    "\n",
    "  # Aggregate by CSA\n",
    "  # Group By CSA so that they may be opperated on\n",
    "  groupedCounts = csasWithCounts.groupby('CSA2010')\n",
    "  # Aggregate Numeric Values by Sum \n",
    "  groupedCounts = groupedCounts.sum(numeric_only=True) \n",
    "  groupedCounts = groupedCounts.merge(pop, left_on='CSA2010', right_on='CSA2010')\n",
    "  groupedCounts['artemp'] = groupedCounts['empl_size']\n",
    "  groupedCounts = groupedCounts.drop(['empl_size', 'X', 'Y'], axis=1)\n",
    "  groupedCounts.to_csv('artemp.csv')\n",
    "  return groupedCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLiQlCf8epYj"
   },
   "outputs": [],
   "source": [
    "# prim_naics\n",
    "population = pd.read_csv('population.csv')\n",
    "csaComms = csa[ ['CSA2010', 'geometry'] ].copy()\n",
    "artemp_Vals = artemp(csaComms, gdfleft, population )\n",
    "artemp_Vals.to_csv('artemp18_csasWithCountsAndTPop.csv')\n",
    "artemp_Vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWggeVTvlOPO"
   },
   "source": [
    "##### 201 CEBUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqsAEzF3Zl95"
   },
   "source": [
    "The rate of businesses (both for-profit and non-profit) that are in the creative economy per 1,000 residents. \n",
    "The creative economy is defined as industries that use and support artistic and cultural skillsets to attract and generate capital, knowledge, and information. \n",
    "Arts-based businesses are included in the creative economy. \n",
    "In addition to the industries included in the rate of arts-based businesses indictor, the following industries are identified by their primary NAICS code: \n",
    "Textiles (313220); Commercial Printing (323111, 323113); Book Printers and Publishers (323117, 511130); Print Media (451212, 511110, 511120, 511199, 519110); \n",
    "Motion Picture & Video Production (512110); Music Publishers (512230); Sound Recording (512240); Radio (515112); Architecture (541310, 541320); \n",
    "Interior Design (541410); Graphic Design (541430); Advertising (541810, 541890); and Photography (541921, 541922). \n",
    "\n",
    "In addition to the industries included in the rate of arts-based businesses indictor, \n",
    "the following industries are identified by their primary SIC code: \n",
    "Print Media (271101, 271102, 271198, 272101, 272102, 272104, 273101, 273198, 596302, 599401);Publishers (273298, 274104, 274105, 874205); \n",
    "Printers (275202, 275202, 275902, 275998); Bookbinders (278902); Radio (483201); Television (483301, 484101, 792205, 824911); Textiles (513122, 594904); \n",
    "Advertising (519917, 731101, 731115, 731305, 731999); Fashion Designers (569901, 594408); Photography (722101, 722113, 722120, 733501, 738401); \n",
    "Graphic Design (733603); Commercial Artists (733604); Website Design (737311); General Media (738301); Interior Design (738902);\n",
    "Restoration (764112); Landscape Design (781030); Motion Picture and Video Support (781205, 781211, 781901); \n",
    "Architecture (871202, 871207, 871209, 874892); and Business Writers (899902)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wf86M-4lAAZM"
   },
   "source": [
    "15 ->  empl_size integer,\n",
    "\n",
    "16 -> empl_size character varying(254),\n",
    "\n",
    "17 -> empl_size bigint,\n",
    "\n",
    "Convert Column StringToInt\n",
    "\n",
    "\n",
    "\n",
    "CREATE OR REPLACE FUNCTION pc_chartoint(chartoconvert character varying)\n",
    "  RETURNS integer AS\n",
    "$BODY$\n",
    "SELECT CASE WHEN trim($1) SIMILAR TO '[0-9]+' \n",
    "        THEN CAST(trim($1) AS integer) \n",
    "    ELSE NULL END;\n",
    "$BODY$\n",
    "  LANGUAGE 'sql' IMMUTABLE STRICT;\n",
    "\n",
    "\n",
    "ALTER TABLE economy.infousa_2016 ALTER COLUMN empl_size TYPE integer USING pc_chartoint(empl_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XITETU7NHbFL"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "clear_output(wait=True)\n",
    "def cebus(bounds, df, pop):\n",
    "  \"\"\"\n",
    "  201 - cebusXX\n",
    "\n",
    "  with tbl AS (\n",
    "   select (sum(\n",
    "      case \n",
    "      when ((prim_naics::text like any (select * from vital_signs.cebus_naics_vals) \n",
    "       or prim_sic::text like any (select * from vital_signs.cebus_sic_vals))\n",
    "       and coname != 'Us Army Corps Of Engineers')\n",
    "      then 1\n",
    "      else 0\n",
    "      end)::numeric \n",
    "    * 1000 )/the_pop as result, csa\n",
    "    from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2016', 'gid', 'the_geom') a\n",
    "    left join economy.infousa_2016 b on a.gid = b.gid\n",
    "    group by csa, the_pop\n",
    "   )\n",
    "   update vital_signs.data\n",
    "   set cebus = result from tbl where data.csa = tbl.csa and data_year = '2016';\n",
    "   \"\"\"\n",
    "  # Filter rows\n",
    "  # https://www.naics.com/code-search/?sictrms=art\n",
    "  # https://www.naics.com/code-search/?naicstrms=art\n",
    "  naicCodes = [323111, 323113, 451140, 451211, 451212, 453920, 511110, 511120, 511130, 511199, \n",
    "               512110, 519110, 519120, 541310, 541320, 541410, 541430, 541810, 541890, 541921, \n",
    "               541922, 611610, 711110, 711130, 711190, 711510, 712110, 712120, 712130, 712190, \n",
    "               313220, 323117, 511130, 512230, 512240, 515112 ]\n",
    "\n",
    "  sicCodes = [271101, 271102, 271198, 272101, 272102, 272104, 273101, 273198, 596302, 599401,\n",
    "              273298, 274104, 274105, 874205, 275202, 275902, 275998, 278902, 483201, \n",
    "              483301, 484101, 792205, 824911, 513122, 594904, 519917, 731101, 731115, 731305, \n",
    "              731999, 569901, 594408, 722101, 722113, 722120, 733501, 738401, 733603, 733604, \n",
    "              737311, 738301, 738902, 764112, 781030, 781205, 781211, 781901, 871202, 871207, \n",
    "              871209, 874892, 899902, 451220, 521310, 532230, 711120]\n",
    "\n",
    "fromArtbusNaicsNotFoundInCebusNaics = [451220, 521310, 532230, 711120]\n",
    "\n",
    "  # sum rows: increment by 1 if row = () else 0\n",
    "  # (prim_naics: like any [ ] or prim_sic like any []) and coname != 'Us Army Corps Of Engineers')\n",
    "  df['prim_naics_short'] = df.prim_naics.astype(str).str[:-2].astype(np.int64)\n",
    "  filtered_df = df[ ( df.prim_naics_short.isin( naicCodes ) | df.prim_sic.isin( sicCodes ) ) ] #& df.coname != 'Us Army Corps Of Engineers' ]\n",
    "  filtered_df.to_csv('cebus_points.csv')\n",
    "  \n",
    "  # Point in Polygons\n",
    "  csasWithCounts = getPointsInPolygons(filtered_df, bounds, 'geometry', 'geometry')\n",
    "\n",
    "  # Aggregate by CSA\n",
    "  # Group By CSA so that they may be opperated on\n",
    "  groupedCounts = csasWithCounts.groupby('CSA2010')\n",
    "  # Aggregate Numeric Values by Sum \n",
    "  groupedCounts = groupedCounts.sum(numeric_only=True) \n",
    "  groupedCounts = groupedCounts.merge(pop, left_on='CSA2010', right_on='CSA2010')\n",
    "  groupedCounts['countOfBusinesses'] = groupedCounts['number of points']\n",
    "  groupedCounts['cebus'] = groupedCounts['number of points'] * 1000 / groupedCounts['tpop10']\n",
    "  groupedCounts = groupedCounts.drop(['number of points'], axis=1)\n",
    "  groupedCounts.to_csv('cebus.csv', index=False)\n",
    "  return groupedCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RV5TBlArdzQO"
   },
   "outputs": [],
   "source": [
    "naicCodes = [323111, 323113, 451140, 451211, 451212, 453920, 511110, 511120, 511130, 511199, \n",
    "              512110, 519110, 519120, 541310, 541320, 541410, 541430, 541810, 541890, 541921, \n",
    "              541922, 611610, 711110, 711130, 711190, 711510, 712110, 712120, 712130, 712190, \n",
    "              313220, 323117, 511130, 512230, 512240, 515112 ]\n",
    "\n",
    "sicCodes = [271101, 271102, 271198, 272101, 272102, 272104, 273101, 273198, 596302, 599401,\n",
    "            273298, 274104, 274105, 874205, 275202, 275902, 275998, 278902, 483201, \n",
    "            483301, 484101, 792205, 824911, 513122, 594904, 519917, 731101, 731115, 731305, \n",
    "            731999, 569901, 594408, 722101, 722113, 722120, 733501, 738401, 733603, 733604, \n",
    "            737311, 738301, 738902, 764112, 781030, 781205, 781211, 781901, 871202, 871207, \n",
    "            871209, 874892, 899902]\n",
    "\n",
    "cebus = infoUsaCsa[ ( infoUsaCsa['prim_naics_short'].isin( naicCodes ) ) | ( infoUsaCsa.prim_sic.isin( sicCodes ) ) ]\n",
    "\n",
    "print( cebus.size / len(cebus.columns) )\n",
    "\n",
    "# Aggregate Numeric Values by Sum \n",
    "cebus = cebus[ ['CSA2010'] ]\n",
    "cebus['cebusCount'] = 1\n",
    "cebus = cebus.groupby('CSA2010').sum(numeric_only=True) \n",
    "cebus = cebus.merge( csa[ ['CSA2010','tpop10'] ], left_on='CSA2010', right_on='CSA2010' ) \n",
    "cebus = cebus.append({'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'cebusCount': cebus['cebusCount'].sum() } , ignore_index=True)\n",
    "\n",
    "# Create the Indicator\n",
    "cebus['cebus'] = cebus['cebusCount'] * 1000 / cebus['tpop10']\n",
    "\n",
    "cebus.to_csv('cebus18.csv', index=False)\n",
    "\n",
    "cebus.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJ4HxTPRX3dt"
   },
   "outputs": [],
   "source": [
    "population = pd.read_csv('population.csv')\n",
    "csaComms = csa[ ['CSA2010', 'geometry'] ].copy()\n",
    "# csaComms = csaComms.drop('tpop10', axis=1)\n",
    "cebus_vals = cebus(csaComms, gdfleft, population )\n",
    "cebus_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eivPnvf-z5vw"
   },
   "source": [
    "##### 202 CEEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9BvNIBGegNt"
   },
   "outputs": [],
   "source": [
    "naicCodes = [323111, 323113, 451140, 451211, 451212, 453920, 511110, 511120, 511130, 511199, \n",
    "              512110, 519110, 519120, 541310, 541320, 541410, 541430, 541810, 541890, 541921, \n",
    "              541922, 611610, 711110, 711130, 711190, 711510, 712110, 712120, 712130, 712190, \n",
    "              313220, 323117, 511130, 512230, 512240, 515112 ]\n",
    "\n",
    "sicCodes = [271101, 271102, 271198, 272101, 272102, 272104, 273101, 273198, 596302, 599401,\n",
    "            273298, 274104, 274105, 874205, 275202, 275902, 275998, 278902, 483201, \n",
    "            483301, 484101, 792205, 824911, 513122, 594904, 519917, 731101, 731115, 731305, \n",
    "            731999, 569901, 594408, 722101, 722113, 722120, 733501, 738401, 733603, 733604, \n",
    "            737311, 738301, 738902, 764112, 781030, 781205, 781211, 781901, 871202, 871207, \n",
    "            871209, 874892, 899902, 451220, 521310, 532230, 711120]\n",
    "\n",
    "ceemp = infoUsaCsa[ ( infoUsaCsa['prim_naics_short'].isin( naicCodes ) ) | ( infoUsaCsa.prim_sic.isin( sicCodes ) ) ]\n",
    "\n",
    "# Aggregate Numeric Values by Sum \n",
    "ceemp = ceemp[ ['CSA2010', 'empl_size'] ]\n",
    "ceemp = ceemp.groupby('CSA2010').sum(numeric_only=True) \n",
    "ceemp = ceemp.merge( csa[ ['CSA2010','tpop10'] ], left_on='CSA2010', right_on='CSA2010' ) \n",
    "ceemp = ceemp.append({'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'empl_size': ceemp['empl_size'].sum() } , ignore_index=True)\n",
    "\n",
    "# Create the Indicator\n",
    "ceemp['ceemp'] = ceemp['empl_size']\n",
    "ceemp = ceemp.drop('empl_size', axis=1)\n",
    "\n",
    "ceemp.to_csv('ceemp18.csv', index=False)\n",
    "\n",
    "ceemp.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBLci_1cYguI"
   },
   "outputs": [],
   "source": [
    "def ceemp(bounds, df, pop):\n",
    "  \"\"\"\n",
    "  202 - ceempXX\n",
    "\n",
    "  with tbl AS (\n",
    "   select (sum(\n",
    "      case \n",
    "      when ((prim_naics::text like any (select * from vital_signs.cebus_naics_vals) \n",
    "       or prim_sic::text like any (select * from vital_signs.cebus_sic_vals))\n",
    "       and coname != 'Us Army Corps Of Engineers')\n",
    "      then empl_size\n",
    "      else 0\n",
    "      end) \n",
    "    ) as result, csa\n",
    "    from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2016', 'gid', 'the_geom') a\n",
    "    left join economy.infousa_2016 b on a.gid = b.gid\n",
    "    group by csa, the_pop\n",
    "   )\n",
    "   update vital_signs.data\n",
    "   set ceemp = result from tbl where data.csa = tbl.csa and data_year = '2016';\n",
    "  \"\"\"\n",
    "  # Filter rows\n",
    "  # https://www.naics.com/code-search/?sictrms=art\n",
    "  # https://www.naics.com/code-search/?naicstrms=art\n",
    "  naicCodes = [323111, 323113, 451140, 451211, 451212, 453920, 511110, 511120, 511130, 511199, \n",
    "               512110, 519110, 519120, 541310, 541320, 541410, 541430, 541810, 541890, 541921, \n",
    "               541922, 611610, 711110, 711130, 711190, 711510, 712110, 712120, 712130, 712190, \n",
    "               313220, 323117, 511130, 512230, 512240, 515112 ]\n",
    "\n",
    "  sicCodes = [271101, 271102, 271198, 272101, 272102, 272104, 273101, 273198, 596302, 599401,\n",
    "              273298, 274104, 274105, 874205, 275202, 275902, 275998, 278902, 483201, \n",
    "              483301, 484101, 792205, 824911, 513122, 594904, 519917, 731101, 731115, 731305, \n",
    "              731999, 569901, 594408, 722101, 722113, 722120, 733501, 738401, 733603, 733604, \n",
    "              737311, 738301, 738902, 764112, 781030, 781205, 781211, 781901, 871202, 871207, \n",
    "              871209, 874892, 899902]\n",
    "\n",
    "  # sum rows: increment by 1 if row = () else 0\n",
    "  # (prim_naics: like any [ ] or prim_sic like any []) and coname != 'Us Army Corps Of Engineers')\n",
    "  df['numOfBusinesses'] = 1\n",
    "  df['prim_naics_short'] = df.prim_naics.astype(str).str[:-2].astype(np.int64)\n",
    "  filtered_df = df[ ( df.prim_naics_short.isin( naicCodes ) | df.prim_sic.isin( sicCodes ) ) ] #& df.coname != 'Us Army Corps Of Engineers' ]\n",
    "\n",
    "  # Point in Polygons\n",
    "  csasWithCounts = getPolygonOnPoints(filtered_df, bounds, 'geometry', 'geometry', 'CSA2010')\n",
    "\n",
    "  # Aggregate by CSA\n",
    "  # Group By CSA so that they may be opperated on\n",
    "  groupedCounts = csasWithCounts.groupby('CSA2010')\n",
    "  # Aggregate Numeric Values by Sum \n",
    "  groupedCounts = groupedCounts.sum(numeric_only=True) \n",
    "  groupedCounts = groupedCounts.merge(pop, left_on='CSA2010', right_on='CSA2010')\n",
    "  groupedCounts['ceemp'] = groupedCounts['empl_size']\n",
    "  # groupedCounts = groupedCounts.drop(['number of points'], axis=1)\n",
    "  groupedCounts.to_csv('ceemp.csv')\n",
    "  return groupedCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7IOEZKF9aRJ"
   },
   "outputs": [],
   "source": [
    "population = pd.read_csv('population.csv')\n",
    "csaComms = csa[ ['CSA2010', 'geometry'] ].copy()\n",
    "ceemp_vals = ceemp(csaComms, gdfleft, population )\n",
    "ceemp_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtgGJPTkgmxR"
   },
   "source": [
    "# Workforce and Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1ppwYc4WyHW"
   },
   "source": [
    "##### 143 numbus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXrjHYPlgHC3"
   },
   "outputs": [],
   "source": [
    "# https://bniajfi.org/indicators/Workforce%20and%20Economic%20Development/numbus/2017\n",
    "original_SQL_Query = \"\"\"\n",
    "143 - numbusXX\n",
    "\n",
    "WITH tbl AS ( \n",
    "  SELECT ( SUM( case WHEN csa_present THEN 1 ELSE 0 END )::numeric ) AS result, a.csa \n",
    "    FROM vital_signs.match_csas_and_bc_by_geom(' economy.infousa_2017', 'gid', 'the_geom') a \n",
    "      LEFT JOIN economy.infousa_2017 b \n",
    "        ON a.gid = b.gid \n",
    "          GROUP BY a.csa, the_pop \n",
    ") \n",
    "update vital_signs.data SET numbus = result FROM tbl WHERE data.csa = tbl.csa AND data_year = '2017';\n",
    "\"\"\"\n",
    "\n",
    "Translation = \"\"\"\n",
    "For Each Community\n",
    "  Count number of points\n",
    "Show in a table with the_pop\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCcGuXn3T_CG"
   },
   "outputs": [],
   "source": [
    "# 143 - numbusXX\n",
    "\n",
    "infoUsaCsaTotals.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WD2Yh-0aXJfO"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "infoUsaCsaTotals.to_csv('numbus18.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62J03x75W04M"
   },
   "source": [
    "##### 144 totemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltLYchytgeka"
   },
   "outputs": [],
   "source": [
    "DO_NOT_PROCESS_SQL = \"\"\"144 - totempXX\n",
    "\n",
    "SELECT bAll.csa AS Bound, SUM(bQuery.totemp17) AS totemp17 \n",
    "  FROM boundaries.csa2010 bAll \n",
    "    LEFT JOIN ( \n",
    "      SELECT bounds.csa AS Boundary, ( SUM(Tables.empl_size ::numeric(20,4))::numeric(20,2)) AS totemp17 \n",
    "        FROM economy.infousa_2017 AS Tables \n",
    "          JOIN boundaries.csa2010 AS bounds \n",
    "            ON st_contains ( bounds.the_geom,Tables.the_geom ) \n",
    "              GROUP BY bounds.csa \n",
    "                ORDER BY bounds.csa \n",
    ") \n",
    "bQuery ON bAll.csa = bQuery.Boundary GROUP BY Bound ORDER BY Bound;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtTdn-qSKhyV"
   },
   "outputs": [],
   "source": [
    "infoUsaCsa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--sPFQQ0KwGc"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Aggregate Numeric Values by Sum\n",
    "totemp = infoUsaCsa.groupby('CSA2010')[ ['CSA2010','empl_size'] ].sum(numeric_only=True)\n",
    "totemp = totemp.merge( csa[ ['CSA2010','tpop10'] ], left_on='CSA2010', right_on='CSA2010' )\n",
    "totemp = totemp.append( {'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'empl_size': totemp['empl_size'].sum() }, ignore_index=True)\n",
    "totemp['totemp'] = totemp['empl_size']\n",
    "totemp = totemp.drop('empl_size', axis=1)\n",
    "totemp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNJZv33GLRQT"
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "totemp.to_csv('totemp18.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_K5G9mTpG5qc"
   },
   "source": [
    "##### 145 smlbus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AA6EIb_NggMi"
   },
   "outputs": [],
   "source": [
    "# https://bniajfi.org/indicators/Workforce%20and%20Economic%20Development/smlbus/2017\n",
    "\n",
    "smlbus_SQL = \"\"\" 145 - smlbusXX\n",
    "\n",
    "WITH tbl AS ( \n",
    "  SELECT( SUM( case WHEN \n",
    "    empl_rng = '1 to 4' \n",
    "    OR  empl_rng = '5 to 9' \n",
    "    OR  empl_rng = '10 to 19' \n",
    "    OR  empl_rng = '20 to 49' \n",
    "      THEN 1 ELSE 0 END\n",
    "  )::numeric ) AS result, a.csa \n",
    "    FROM vital_signs.match_csas_and_bc_by_geom(' economy.infousa_2017', 'gid', 'the_geom') a \n",
    "      LEFT JOIN  economy.infousa_2017 b \n",
    "        ON a.gid = b.gid \n",
    "          GROUP BY a.csa, the_pop\n",
    "            ORDER BY a.csa\n",
    ")\n",
    "UPDATE vital_signs.data SET smlbus = result FROM tbl WHERE data.csa = tbl.csa AND data_year = '2017'; \n",
    "Screen reader support enabled.\n",
    "\"\"\"\n",
    "\n",
    "Translation = \"\"\"\n",
    "CSA Points in Polygons.\n",
    "\n",
    "For Each Community\n",
    "  For Each Point\n",
    "    if Point in Community \n",
    "      if empl_rng = '1 to 4'\n",
    "        OR  empl_rng = '5 to 9' \n",
    "        OR  empl_rng = '10 to 19' \n",
    "        OR  empl_rng = '20 to 49' \n",
    "          tally one to communityCount\n",
    "Show in a table with the_pop\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxXvVai2YU8E"
   },
   "outputs": [],
   "source": [
    "# 145 - smlbusXX\n",
    "\n",
    "infoUsaCsa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UcckI4PE1mK"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "sml = infoUsaCsa.copy()\n",
    "smlbus = sml[ ( sml['empl_rng'].isin(['1 to 4']) ) ]\n",
    "smlbus.to_csv('smlbus_empl_rng1 to 4.csv')\n",
    "print('empl_rng 1 to 4: ', smlbus.size / len(smlbus.columns) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIk9sd1kE05z"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "smlbus = sml[ ( sml['empl_rng'].isin(['5 to 9']) ) ]\n",
    "smlbus.to_csv('smlbus_empl_rng5 to 9.csv')\n",
    "print('empl_rng 5 to 9: ', smlbus.size / len(smlbus.columns) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6PDASecE0cn"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "smlbus = sml[ ( sml['empl_rng'].isin(['10 to 19']) ) ]\n",
    "smlbus.to_csv('smlbus_empl_rng10 to 19.csv')\n",
    "print('empl_rng 10 to 19: ', smlbus.size / len(smlbus.columns) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRnDlNHZDIT-"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "smlbus = sml[ ( sml['empl_rng'].isin(['20 to 49']) ) ]\n",
    "smlbus.to_csv('smlbus_empl_rng20 to 49.csv')\n",
    "print('empl_rng 20 to 49: ', smlbus.size / len(smlbus.columns) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77zA9BCHYWgm"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Filter for small businesses\n",
    "smlbus = sml[ ( sml['empl_rng'].isin(['1 to 4', '5 to 9',  '10 to 19', '20 to 49']) ) ]\n",
    "smlbus.to_csv('smlbus18_filtered_points.csv')\n",
    "print('empl_rng 1 to 49: ', smlbus.size / len(smlbus.columns) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMO_c1gphnkd"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Aggregate Numeric Values by Sum\n",
    "smlbus['smlbus'] = 1\n",
    "smlbus = smlbus.groupby('CSA2010')[ ['CSA2010','smlbus'] ].sum(numeric_only=True)\n",
    "smlbus = smlbus.merge( csa[ ['CSA2010','tpop10'] ], left_on='CSA2010', right_on='CSA2010' )\n",
    "smlbus = smlbus.append( {'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'smlbus': gdf2['smlbus'].sum() }, ignore_index=True)\n",
    "smlbus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuCnDAyj2ego"
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "smlbus.to_csv('smlbus18.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQET9YvkF2cl"
   },
   "source": [
    "##### 150 biz1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpa_NSlGghK7"
   },
   "outputs": [],
   "source": [
    "# https://bniajfi.org/indicators/Workforce%20and%20Economic%20Development/biz1/2017\n",
    "\n",
    "biz1_SQL = \"\"\"150 - biz1_XX\n",
    "with numerator as (\n",
    "  select sum( case when first_year LIKE '2016' then 1 else 0 end)::numeric as result, csa\n",
    "  from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2017', 'gid', 'the_geom') a\n",
    "  left join economy.infousa_2017 b on a.gid = b.gid\n",
    "  group by csa\n",
    "),\n",
    "denominator AS (\n",
    "  select (sum( case  when csa_present then 1 else NULL end)::numeric ) as result, csa\n",
    "  from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2017', 'gid', 'the_geom') a\n",
    "  left join economy.infousa_2016 b on a.gid = b.gid\n",
    "  group by csa\n",
    "),\n",
    "tbl AS (\n",
    "  select vital_signs.div_zero (numerator.result, denominator.result)*(100::numeric) as result, numerator.csa\n",
    "  from numerator left join denominator on numerator.csa = denominator.csa\n",
    ")\n",
    "update vital_signs.data\n",
    "set biz1_ = result from tbl where data.csa = tbl.csa and data_year = '2017'; \n",
    "Screen reader support enabled.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Translation = \"\"\"\n",
    "CSA Points in Polygons.\n",
    "\n",
    "Numerator = 0\n",
    "For Each Community\n",
    "  For Each Point\n",
    "    if Point in Community and first_year LIKE '2017'\n",
    "      tally one to Numerator.csa\n",
    "\n",
    "Denominator = 0\n",
    "For Each Community\n",
    "  For Each Point\n",
    "    if Point in Community \n",
    "      tally one to Denominator.csa\n",
    "\n",
    "biz1 = (Numerator / Denominator) * 100\n",
    "\n",
    "Show in a table with the_pop\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uIdefEYM35G"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# 145 -biz1XX\n",
    "\n",
    "# Filter for small businesses\n",
    "biz1 = infoUsaCsa[ ( infoUsaCsa['first_year'].isin( ['2018'] ) ) ]\n",
    "print('Count: first_year == 2018: ', biz1.size / len(biz1.columns) )\n",
    "biz1 = biz1[ ['CSA2010'] ]\n",
    "#numerator.to_csv('biz18_numerator_csasWithCounts.csv')\n",
    "biz1['biz1Count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNm-IpaqONcz"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Aggregate Numeric Values by Sum\n",
    "biz1 = biz1.groupby('CSA2010').sum(numeric_only=True)\n",
    "biz1 = biz1.merge( csa[ ['CSA2010','tpop10'] ], left_on='CSA2010', right_on='CSA2010' )\n",
    "biz1 = biz1.append( {'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'biz1Count': biz1['biz1Count'].mean() }, ignore_index=True)\n",
    "biz1.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IrakaDQ0WnbV"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Create the Indicator\n",
    "biz1['biz1'] = biz1['biz1Count'] / infoUsaCsaTotals['numbus']\n",
    "biz1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AGlUVO8DS87"
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "biz1.to_csv('biz1_18.csv', index=False)\n",
    "biz1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRz21_mvDTac"
   },
   "source": [
    "##### 151 biz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2az-bUksgiII"
   },
   "outputs": [],
   "source": [
    "# https://bniajfi.org/indicators/Workforce%20and%20Economic%20Development/biz2/2017\n",
    "biz4_SQL = \"\"\" 151 - biz2_XX\n",
    "with numerator as (\n",
    "   select sum(\n",
    "   case \n",
    "   when first_year LIKE '2016' OR first_year LIKE '2015' \n",
    "   then 1\n",
    "   else 0\n",
    "   end)::numeric as result, csa\n",
    "   from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2016', 'gid', 'the_geom') a\n",
    "   left join economy.infousa_2016 b on a.gid = b.gid\n",
    "   group by csa\n",
    "   ),\n",
    "   denominator AS (\n",
    "    select (sum(\n",
    "     case \n",
    "     when csa_present\n",
    "     then 1\n",
    "     else NULL\n",
    "     end)::numeric \n",
    "    ) as result, csa\n",
    "    from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2016', 'gid', 'the_geom') a\n",
    "    left join economy.infousa_2016 b on a.gid = b.gid\n",
    "    group by csa\n",
    "   ),\n",
    " tbl AS (\n",
    "                        select vital_signs.div_zero (numerator.result, denominator.result)*(100::numeric) as result, numerator.csa\n",
    "                        from numerator left join denominator on numerator.csa = denominator.csa\n",
    "                                                                )\n",
    "     update vital_signs.data\n",
    "   set biz2_ = result from tbl where data.csa = tbl.csa and data_year = '2016'; \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with numerator as (\n",
    "   select sum(\n",
    "   case \n",
    "   when first_year LIKE '2017' OR first_year LIKE '2016' OR first_year LIKE '2015' \n",
    "   then 1\n",
    "   else 0\n",
    "   end)::numeric as result, csa\n",
    "   from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2017', 'gid', 'the_geom') a\n",
    "   left join economy.infousa_2017 b on a.gid = b.gid\n",
    "   group by csa\n",
    "   ),\n",
    "   denominator AS (\n",
    "    select (sum(\n",
    "     case \n",
    "     when csa_present\n",
    "     then 1\n",
    "     else NULL\n",
    "     end)::numeric \n",
    "    ) as result, csa\n",
    "    from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2017', 'gid', 'the_geom') a\n",
    "    left join economy.infousa_2017 b on a.gid = b.gid\n",
    "    group by csa\n",
    "   ),\n",
    " tbl AS (\n",
    "                        select vital_signs.div_zero (numerator.result, denominator.result)*(100::numeric) as result, numerator.csa\n",
    "                        from numerator left join denominator on numerator.csa = denominator.csa\n",
    "                                                                )\n",
    "\n",
    "select * from tbl where 1 = 1 ORDER BY csa ASC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLoNtlJlFhl8"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# 151 - biz2XX\n",
    "\n",
    "# Filter for small businesses\n",
    "biz2 = infoUsaCsa[ ( infoUsaCsa['first_year'].isin( ['2016', '2017', '2018'] ) ) ]\n",
    "print('Count: first_year == 2018, 2017, 2016: ', biz2.size / len(biz2.columns) )\n",
    "biz2 = biz2[ ['CSA2010'] ]\n",
    "#numerator.to_csv('biz18_numerator_csasWithCounts.csv')\n",
    "biz2['biz2Count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOZPPVSMFhmT"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Aggregate Numeric Values by Sum\n",
    "biz2 = biz2.groupby('CSA2010').sum(numeric_only=True)\n",
    "biz2 = biz2.merge( csa[ ['CSA2010','tpop10'] ], left_on='CSA2010', right_on='CSA2010' )\n",
    "biz2 = biz2.append( {'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'biz2Count': biz2['biz2Count'].mean() }, ignore_index=True)\n",
    "biz2.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Czg2ykLFhmf"
   },
   "outputs": [],
   "source": [
    "# Create the Indicator\n",
    "biz2['biz2'] = biz2['biz2Count'] / infoUsaCsaTotals['numbus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InU0DsD9Fhmp"
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "biz2.to_csv('biz2_18.csv', index=False)\n",
    "biz2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqMLkwUQOSdi"
   },
   "source": [
    "##### 152 biz4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7SiDG4F_b9E"
   },
   "source": [
    "2016 -> first_year character varying(254),\n",
    "\n",
    "2017 -> first_year bigint,\n",
    "\n",
    "Convert Column StringToInt\n",
    "\n",
    "CREATE OR REPLACE FUNCTION pc_inttochar(chartoconvert bigint)\n",
    "  RETURNS character AS\n",
    "$BODY$\n",
    "SELECT CASE WHEN 1 = 1 \n",
    "        THEN CAST($1 AS character(254)) \n",
    "    ELSE NULL END;\n",
    "$BODY$\n",
    "  LANGUAGE 'sql' IMMUTABLE STRICT;\n",
    "\n",
    "\n",
    "ALTER TABLE economy.infousa_2017 ALTER COLUMN first_year TYPE character varying(254) USING pc_inttochar(first_year);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GI5fmdIpgjFk"
   },
   "outputs": [],
   "source": [
    "biz4_SQL = \"\"\" 152 - biz4_XX\n",
    "with numerator as (\n",
    "   select sum(\n",
    "   case \n",
    "   when first_year LIKE '2016' OR first_year LIKE '2015' OR first_year LIKE '2014' OR first_year LIKE '2013'\n",
    "   then 1\n",
    "   else 0\n",
    "   end)::numeric as result, csa\n",
    "   from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2016', 'gid', 'the_geom') a\n",
    "   left join economy.infousa_2016 b on a.gid = b.gid\n",
    "   group by csa\n",
    "   ),\n",
    "   denominator AS (\n",
    "    select (sum(\n",
    "     case \n",
    "     when csa_present\n",
    "     then 1\n",
    "     else NULL\n",
    "     end)::numeric \n",
    "    ) as result, csa\n",
    "    from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2016', 'gid', 'the_geom') a\n",
    "    left join economy.infousa_2016 b on a.gid = b.gid\n",
    "    group by csa\n",
    "   ),\n",
    " tbl AS (\n",
    "                        select vital_signs.div_zero (numerator.result, denominator.result)*(100::numeric) as result, numerator.csa\n",
    "                        from numerator left join denominator on numerator.csa = denominator.csa\n",
    "                                                                )\n",
    "     update vital_signs.data\n",
    "   set biz4_ = result from tbl where data.csa = tbl.csa and data_year = '2016'; \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with numerator as (\n",
    "   select sum(\n",
    "   case \n",
    "   when first_year LIKE '2017' OR first_year LIKE '2016' OR first_year LIKE '2015' OR first_year LIKE '2014' OR first_year LIKE '2013'\n",
    "   then 1\n",
    "   else 0\n",
    "   end)::numeric as result, csa\n",
    "   from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2017', 'gid', 'the_geom') a\n",
    "   left join economy.infousa_2017 b on a.gid = b.gid\n",
    "   group by csa\n",
    "   ),\n",
    "   denominator AS (\n",
    "    select (sum(\n",
    "     case \n",
    "     when csa_present\n",
    "     then 1\n",
    "     else NULL\n",
    "     end)::numeric \n",
    "    ) as result, csa\n",
    "    from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2017', 'gid', 'the_geom') a\n",
    "    left join economy.infousa_2017 b on a.gid = b.gid\n",
    "    group by csa\n",
    "  ),\n",
    " tbl AS (\n",
    "                        select vital_signs.div_zero (numerator.result, denominator.result)*(100::numeric) as result, numerator.csa\n",
    "                        from numerator left join denominator on numerator.csa = denominator.csa\n",
    "                                                                )\n",
    "\n",
    "select * from tbl where 1 = 1 ORDER BY csa ASC;\n",
    "\"\"\"\n",
    "\n",
    "Translation = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FNsuBk3Je1P"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# 152 - biz4XX\n",
    "\n",
    "# Filter for small businesses\n",
    "biz4 = infoUsaCsa[ ( infoUsaCsa['first_year'].isin( ['2015', '2016', '2017', '2018'] ) ) ]\n",
    "print('Count: first_year == 2018, 2017, 2016, 2015: ', biz2.size / len(biz2.columns) )\n",
    "biz4 = biz4[ ['CSA2010'] ]\n",
    "#numerator.to_csv('biz18_numerator_csasWithCounts.csv')\n",
    "biz4['biz4Count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fqg0mX8wJe1a"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Aggregate Numeric Values by Sum\n",
    "biz4 = biz4.groupby('CSA2010').sum(numeric_only=True)\n",
    "biz4 = biz4.merge( csa[ ['CSA2010','tpop10'] ], left_on='CSA2010', right_on='CSA2010' )\n",
    "biz4 = biz4.append( {'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'biz4Count': biz4['biz4Count'].mean() }, ignore_index=True)\n",
    "biz4.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7AEcNA1Je1d"
   },
   "outputs": [],
   "source": [
    "# Create the Indicator\n",
    "biz4['biz4'] = biz4['biz4Count'] / infoUsaCsaTotals['numbus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9pSAPVeJe1g"
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "biz4.to_csv('biz4_18.csv', index=False)\n",
    "biz4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG1X9D8kOVea"
   },
   "source": [
    "##### 157 neiind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHLjrSuC_mI7"
   },
   "source": [
    "2016 -> prim_naics character varying(254),\n",
    "\n",
    "2017 -> prim_naics bigint,\n",
    "\n",
    "Convert Column StringToInt\n",
    "\n",
    "\n",
    "\n",
    "CREATE OR REPLACE FUNCTION pc_inttochar(chartoconvert bigint)\n",
    "  RETURNS character AS\n",
    "$BODY$\n",
    "SELECT CASE WHEN 1 = 1 \n",
    "        THEN CAST($1 AS character(254)) \n",
    "    ELSE NULL END;\n",
    "$BODY$\n",
    "  LANGUAGE 'sql' IMMUTABLE STRICT;\n",
    "\n",
    "\n",
    "ALTER TABLE economy.infousa_2017 ALTER COLUMN prim_naics TYPE character varying(254) USING pc_inttochar(prim_naics);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P66Vn5FtgkHs"
   },
   "outputs": [],
   "source": [
    "# https://bniajfi.org/indicators/Workforce%20and%20Economic%20Development/neiind/2017\n",
    "neiind_SQL = \"\"\"157 - neiindXX\n",
    "\n",
    "with tbl AS (\n",
    "   select (sum(\n",
    "      case \n",
    "      when prim_naics LIKE '44%' OR prim_naics LIKE '45%' OR prim_naics LIKE '52%' OR prim_naics LIKE '54%' OR \n",
    "      prim_naics LIKE '62%' OR prim_naics LIKE '71%' OR prim_naics LIKE '72%' OR prim_naics LIKE '81%'\n",
    "      then 1\n",
    "      else 0\n",
    "      end)::numeric(20,2)\n",
    "    ) as result, csa\n",
    "    from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2016', 'gid', 'the_geom') a\n",
    "    left join economy.infousa_2016 b on a.gid = b.gid\n",
    "    group by csa, the_pop\n",
    "   )\n",
    "   update vital_signs.data\n",
    "   set neiind = result from tbl where data.csa = tbl.csa and data_year = '2016';\n",
    "\"\"\"\n",
    "Translation = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtWby2nxPtSi"
   },
   "outputs": [],
   "source": [
    "infoUsaCsa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGnHii3YP2Jv"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# 157 - neiindXX\n",
    "\n",
    "# Filter for small businesses\n",
    "neiind = infoUsaCsa.copy()\n",
    "neiind['naics_extra_short'] = neiind.prim_naics.astype(str).str[:-6].astype(np.int64)\n",
    "neiind = infoUsaCsa[ ( neiind['naics_extra_short'].isin( [44, 45, 52, 54, 62, 71, 72, 81] ) ) ]\n",
    "print('Count of Naics Starting With: 44, 45, 52, 54, 62, 71, 72, 81: ', neiind.size / len(neiind.columns) )\n",
    "neiind = neiind[ ['CSA2010'] ]\n",
    "#numerator.to_csv('biz18_numerator_csasWithCounts.csv')\n",
    "neiind['neiind'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zIB5bCnP2J2"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Aggregate Numeric Values by Sum\n",
    "neiind = neiind.groupby('CSA2010').sum(numeric_only=True)\n",
    "neiind = neiind.merge( csa[ ['CSA2010','tpop10'] ], left_on='CSA2010', right_on='CSA2010' )\n",
    "neiind = neiind.append( {'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'neiind': neiind['neiind'].sum() }, ignore_index=True)\n",
    "neiind.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9V9J2aZDP2J9"
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "neiind.to_csv('neiind18.csv', index=False)\n",
    "neiind.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5-jjxCNOYFs"
   },
   "source": [
    "##### 158 neibus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUO0PBJQ_wGM"
   },
   "source": [
    "2016 -> prim_naics character varying(254),\n",
    "\n",
    "2017 -> prim_naics bigint,\n",
    "\n",
    "Convert Column StringToInt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CREATE OR REPLACE FUNCTION pc_inttochar(chartoconvert bigint)\n",
    "  RETURNS character AS\n",
    "$BODY$\n",
    "SELECT CASE WHEN 1 = 1 \n",
    "        THEN CAST($1 AS character(254)) \n",
    "    ELSE NULL END;\n",
    "$BODY$\n",
    "  LANGUAGE 'sql' IMMUTABLE STRICT;\n",
    "\n",
    "\n",
    "ALTER TABLE economy.infousa_2017 ALTER COLUMN prim_naics TYPE character varying(254) USING pc_inttochar(prim_naics);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d15oMwUvgk8o"
   },
   "outputs": [],
   "source": [
    "# https://bniajfi.org/indicators/Workforce%20and%20Economic%20Development/neiind/2017\n",
    "neibus_SQL = \"\"\"\n",
    "158 - neibusXX\n",
    "\n",
    "with tbl AS (\n",
    "   select (sum(\n",
    "      case \n",
    "      when prim_naics LIKE '44%' OR prim_naics LIKE '45%' OR prim_naics LIKE '52%' OR prim_naics LIKE '54%' OR \n",
    "      prim_naics LIKE '62%' OR prim_naics LIKE '71%' OR prim_naics LIKE '72%' OR prim_naics LIKE '81%'\n",
    "      then 1\n",
    "      else 0\n",
    "      end)::numeric \n",
    "    *1000)/the_pop as result, csa\n",
    "    from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2016', 'gid', 'the_geom') a\n",
    "    left join economy.infousa_2016 b on a.gid = b.gid\n",
    "    group by csa, the_pop\n",
    "   )\n",
    "   update vital_signs.data\n",
    "   set neibus = result from tbl where data.csa = tbl.csa and data_year = '2016';\n",
    "\"\"\"\n",
    "Translation = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgONFX8FSwkG"
   },
   "outputs": [],
   "source": [
    "infoUsaCsa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVdNKYE4Swj5"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# 158 - neibus\n",
    "\n",
    "# Filter for small businesses\n",
    "neibus = infoUsaCsa.copy()\n",
    "neibus['naics_extra_short'] = neibus.prim_naics.astype(str).str[:-6].astype(np.int64)\n",
    "neibus = infoUsaCsa[ ( neibus['naics_extra_short'].isin( [44, 45, 52, 54, 62, 71, 72, 81] ) ) ]\n",
    "print('Count of Naics Starting With: 44, 45, 52, 54, 62, 71, 72, 81: ', neibus.size / len(neibus.columns) )\n",
    "neibus = neibus[ ['CSA2010'] ]\n",
    "#numerator.to_csv('biz18_numerator_csasWithCounts.csv')\n",
    "neibus['neibus'] = 1\n",
    "neibus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KajJbs5Swji"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Aggregate Numeric Values by Sum\n",
    "neibus = neibus.groupby('CSA2010').sum(numeric_only=True)\n",
    "neibus = neibus.merge( csa[ ['CSA2010','tpop10'] ], left_on='CSA2010', right_on='CSA2010' )\n",
    "neibus = neibus.append( {'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'neibus': neibus['neibus'].sum() }, ignore_index=True)\n",
    "neibus['neibus'] = neibus['neibus'] * 1000 / neibus['tpop10']\n",
    "neibus.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GuLNLkgSwid"
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "neibus.to_csv('neibus18.csv', index=False)\n",
    "neibus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVm5v9CWOcbS"
   },
   "source": [
    "##### 159 neiemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cad9B2Op_4r5"
   },
   "source": [
    "2016 -> prim_naics character varying(254),\n",
    "\n",
    "2017 -> prim_naics bigint,\n",
    "\n",
    "Convert Column StringToInt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CREATE OR REPLACE FUNCTION pc_inttochar(chartoconvert bigint)\n",
    "  RETURNS character AS\n",
    "$BODY$\n",
    "SELECT CASE WHEN 1 = 1 \n",
    "        THEN CAST($1 AS character(254)) \n",
    "    ELSE NULL END;\n",
    "$BODY$\n",
    "  LANGUAGE 'sql' IMMUTABLE STRICT;\n",
    "\n",
    "\n",
    "ALTER TABLE economy.infousa_2017 ALTER COLUMN prim_naics TYPE character varying(254) USING pc_inttochar(prim_naics);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXDYdF_BgluR"
   },
   "outputs": [],
   "source": [
    "# https://bniajfi.org/indicators/Workforce%20and%20Economic%20Development/neiemp/2017\n",
    "neiemp_SQL = \"\"\" 159 - neiempXX\n",
    "\n",
    "with tbl AS (\n",
    "   select (sum(\n",
    "      case \n",
    "      when prim_naics LIKE '44%' OR prim_naics LIKE '45%' OR prim_naics LIKE '52%' OR prim_naics LIKE '54%' OR \n",
    "      prim_naics LIKE '62%' OR prim_naics LIKE '71%' OR prim_naics LIKE '72%' OR prim_naics LIKE '81%'\n",
    "      then empl_size\n",
    "      else 0\n",
    "      end) \n",
    "    ) as result, csa\n",
    "    from vital_signs.match_csas_and_bc_by_geom('economy.infousa_2016', 'gid', 'the_geom') a\n",
    "    left join economy.infousa_2016 b on a.gid = b.gid\n",
    "    group by csa, the_pop\n",
    "   )\n",
    "   update vital_signs.data\n",
    "   set neiemp = result from tbl where data.csa = tbl.csa and data_year = '2016';\n",
    "\"\"\"\n",
    "Translation = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANGllJ_CWQhf"
   },
   "outputs": [],
   "source": [
    "infoUsaCsa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWS6G0SKWQh0"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# 159 - neiempXX\n",
    "\n",
    "# Filter for small businesses\n",
    "neiemp = infoUsaCsa.copy()\n",
    "neiemp['naics_extra_short'] = neiemp.prim_naics.astype(str).str[:-6].astype(np.int64)\n",
    "neiemp = infoUsaCsa[ ( neiemp['naics_extra_short'].isin( [44, 45, 52, 54, 62, 71, 72, 81] ) ) ]\n",
    "print('Count of Naics Starting With: 44, 45, 52, 54, 62, 71, 72, 81: ', neiemp.size / len(neiemp.columns) )\n",
    "#numerator.to_csv('biz18_numerator_csasWithCounts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzEuyixGWQh7"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Aggregate Numeric Values by Sum\n",
    "neiemp = neiemp.groupby('CSA2010')[ ['CSA2010','empl_size'] ].sum(numeric_only=True)\n",
    "neiemp = neiemp.merge( csa[ ['CSA2010','tpop10'] ], left_on='CSA2010', right_on='CSA2010' )\n",
    "neiemp = neiemp.append( {'CSA2010': 'Baltimore City' , 'tpop10' : 620961, 'empl_size': neiemp['empl_size'].sum() }, ignore_index=True)\n",
    "neiemp['neiemp'] = neiemp['empl_size']\n",
    "neiemp = neiemp.drop('empl_size', axis=1)\n",
    "neiemp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCQ7oQoxWQiA"
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "neiemp.to_csv('neiemp18.csv', index=False)\n",
    "neiemp.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0hHCW-qPMeH6",
    "q8tLzJzcMh74",
    "nHAig4kSjgi8",
    "_3QiG_W4iDl7",
    "P3WNvZGQOTxw",
    "J6_DjC2wT4Nl",
    "bnwlAxsivf3x",
    "QttF47Zn9lSs",
    "-HPqCNop9uJc",
    "2NbV6BF3xa_X",
    "G3GUKNSlH5GA",
    "TS3Nquuc0ixL",
    "CWggeVTvlOPO",
    "eivPnvf-z5vw",
    "I1ppwYc4WyHW",
    "62J03x75W04M",
    "_K5G9mTpG5qc",
    "XQET9YvkF2cl",
    "aRz21_mvDTac",
    "qqMLkwUQOSdi",
    "PG1X9D8kOVea",
    "u5-jjxCNOYFs",
    "rVm5v9CWOcbS"
   ],
   "name": "Infousa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
